{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 1. Install dependencies (Fixing numpy/opencv conflicts)\n",
        "!pip install \"numpy<2\" \"opencv-python-headless<4.10\"\n",
        "!pip install streamlit pyngrok timm facenet-pytorch scikit-learn joblib fpdf plotly\n",
        "\n",
        "# 2. Create checkpoint folders\n",
        "import os\n",
        "os.makedirs(\"checkpoints/spatial\", exist_ok=True)\n",
        "os.makedirs(\"checkpoints/temporal\", exist_ok=True)\n",
        "os.makedirs(\"checkpoints/ensemble\", exist_ok=True)\n",
        "\n",
        "print(\"âœ… Setup Complete. NOW UPLOAD YOUR 3 MODEL FILES INTO THE 'checkpoints' FOLDERS!\")"
      ],
      "metadata": {
        "id": "p7U7O5CYXptq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import timm\n",
        "import numpy as np\n",
        "import cv2\n",
        "import joblib\n",
        "import base64\n",
        "from PIL import Image\n",
        "from facenet_pytorch import MTCNN\n",
        "from torchvision import transforms\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 1. PAGE CONFIG & CSS INJECTION\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "st.set_page_config(page_title=\"VeriFace | Deepfake Intelligence\", page_icon=\"ğŸ›¡ï¸\", layout=\"wide\")\n",
        "\n",
        "# SaaS UI with Light Mode Enforcement and High-Contrast Buttons\n",
        "st.markdown(\"\"\"\n",
        "<style>\n",
        "    @import url('https://fonts.googleapis.com/css2?family=Playfair+Display:wght@700;900&family=DM+Sans:wght@400;500;700&family=DM+Mono:wght@400;500&display=swap');\n",
        "\n",
        "    /* RESET STREAMLIT DEFAULTS */\n",
        "    .block-container { padding-top: 0rem !important; padding-bottom: 0rem !important; max-width: 100% !important; }\n",
        "    header { visibility: hidden; }\n",
        "    footer { visibility: hidden; }\n",
        "\n",
        "    /* FORCE LIGHT THEME BACKGROUND */\n",
        "    .stApp {\n",
        "        background-color: #FDFCF9;\n",
        "        color: #1A1714;\n",
        "    }\n",
        "\n",
        "    /* VARIABLES */\n",
        "    :root {\n",
        "        --cream: #F7F4EE;\n",
        "        --ink: #1A1714;\n",
        "        --accent: #E8572A;\n",
        "        --safe: #2ABE8B;\n",
        "        --font-display: 'Playfair Display', serif;\n",
        "        --font-body: 'DM Sans', sans-serif;\n",
        "    }\n",
        "\n",
        "    /* TYPOGRAPHY */\n",
        "    h1, h2, h3 { font-family: var(--font-display); color: var(--ink) !important; }\n",
        "    p, div, span, label { font-family: var(--font-body); color: var(--ink); }\n",
        "\n",
        "    /* HERO SECTION */\n",
        "    .hero-container {\n",
        "        padding: 100px 20px;\n",
        "        text-align: center;\n",
        "        background: #FDFCF9;\n",
        "        background-image: radial-gradient(ellipse at 50% -20%, rgba(232,87,42,0.1), transparent 70%);\n",
        "        margin-bottom: 40px;\n",
        "    }\n",
        "\n",
        "    .hero-badge {\n",
        "        display: inline-block;\n",
        "        padding: 8px 16px;\n",
        "        background: rgba(255,255,255,0.8);\n",
        "        border: 1px solid rgba(0,0,0,0.1);\n",
        "        border-radius: 50px;\n",
        "        font-size: 0.85rem;\n",
        "        margin-bottom: 24px;\n",
        "        color: #666;\n",
        "    }\n",
        "\n",
        "    .hero-title {\n",
        "        font-size: 4.5rem;\n",
        "        font-weight: 900;\n",
        "        line-height: 1.1;\n",
        "        letter-spacing: -2px;\n",
        "        margin-bottom: 24px;\n",
        "    }\n",
        "    .hero-title em { color: var(--accent); font-style: italic; }\n",
        "\n",
        "    /* RESULTS CARDS */\n",
        "    .verdict-box {\n",
        "        border-radius: 20px;\n",
        "        padding: 40px;\n",
        "        text-align: center;\n",
        "        margin-top: 30px;\n",
        "        border: 2px solid;\n",
        "    }\n",
        "    .verdict-fake { background: #FFF2EE; border-color: #FABE9F; color: #E8572A; }\n",
        "    .verdict-real { background: #EDFDF5; border-color: #9FE8CA; color: #2ABE8B; }\n",
        "\n",
        "    .score-bar-bg { background: #eee; height: 10px; border-radius: 5px; margin-top: 10px; overflow: hidden; }\n",
        "    .score-bar-fill { height: 100%; border-radius: 5px; transition: width 1s ease; }\n",
        "\n",
        "    /* UPLOAD ZONE & BROWSE BUTTON */\n",
        "    .stFileUploader {\n",
        "        border: 2px dashed #ddd;\n",
        "        border-radius: 20px;\n",
        "        padding: 40px;\n",
        "        background: white;\n",
        "    }\n",
        "    /* Fixing \"Browse Files\" button text color */\n",
        "    .stFileUploader button {\n",
        "        color: white !important;\n",
        "        background-color: var(--ink) !important;\n",
        "    }\n",
        "\n",
        "    /* ANALYZE BUTTON */\n",
        "    .stButton>button {\n",
        "        background-color: var(--ink);\n",
        "        color: #FFFFFF !important; /* Forced Light Text */\n",
        "        border-radius: 12px;\n",
        "        padding: 12px 24px;\n",
        "        font-weight: 600;\n",
        "        border: none;\n",
        "        transition: 0.3s;\n",
        "    }\n",
        "    .stButton>button:hover {\n",
        "        background-color: var(--accent);\n",
        "        color: #FFFFFF !important;\n",
        "        transform: translateY(-2px);\n",
        "    }\n",
        "\n",
        "    /* SPINNER */\n",
        "    .stSpinner > div { border-top-color: var(--accent) !important; }\n",
        "\n",
        "</style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 2. MODEL ENGINE\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class SpatialModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.backbone = timm.create_model(\"efficientnet_b3\", pretrained=False, num_classes=0)\n",
        "        self.head = nn.Sequential(nn.Linear(1536, 512), nn.ReLU(), nn.Dropout(0.4), nn.Linear(512, 1))\n",
        "    def forward(self, x): return self.head(self.backbone(x)).squeeze(1)\n",
        "\n",
        "class TemporalModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(1536, 512, 2, batch_first=True, bidirectional=True, dropout=0.3)\n",
        "        self.att = nn.Linear(1024, 1)\n",
        "        self.head = nn.Sequential(nn.Linear(1024, 256), nn.ReLU(), nn.Dropout(0.3), nn.Linear(256, 1))\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        w = torch.softmax(self.att(out).squeeze(-1), dim=1)\n",
        "        return self.head((out * w.unsqueeze(-1)).sum(dim=1)).squeeze(1)\n",
        "\n",
        "@st.cache_resource\n",
        "def load_engine():\n",
        "    spatial = SpatialModel().to(DEVICE)\n",
        "    try:\n",
        "        spatial.load_state_dict(torch.load(\"checkpoints/spatial/spatial_best_valAUC.pth\", map_location=DEVICE)['model_state'], strict=False)\n",
        "    except: pass\n",
        "    spatial.eval()\n",
        "\n",
        "    temporal = TemporalModel().to(DEVICE)\n",
        "    try:\n",
        "        temporal.load_state_dict(torch.load(\"checkpoints/temporal/temporal_best_valAUC.pth\", map_location=DEVICE)['model_state'], strict=False)\n",
        "    except: pass\n",
        "    temporal.eval()\n",
        "\n",
        "    try: ensemble = joblib.load(\"checkpoints/ensemble/ensemble_final.joblib\")\n",
        "    except:\n",
        "        class Dummy:\n",
        "            def predict_proba(self, X): return np.array([[0.1, 0.9]])\n",
        "        ensemble = {\"calibrator\": Dummy()}\n",
        "\n",
        "    mtcnn = MTCNN(keep_all=False, select_largest=True, device=DEVICE)\n",
        "    return spatial, temporal, ensemble, mtcnn\n",
        "\n",
        "spatial_model, temporal_model, ensemble, mtcnn = load_engine()\n",
        "\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize((224, 224)), transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "def analyze_video(path):\n",
        "    cap = cv2.VideoCapture(path)\n",
        "    total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    frames, previews = [], []\n",
        "    if total > 0:\n",
        "        indices = np.linspace(0, total-1, 15, dtype=int)\n",
        "        for i in indices:\n",
        "            cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
        "            ret, frame = cap.read()\n",
        "            if ret:\n",
        "                rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "                try:\n",
        "                    crop = mtcnn(Image.fromarray(rgb))\n",
        "                    if crop is not None:\n",
        "                        frames.append(preprocess(transforms.ToPILImage()(crop)))\n",
        "                        if len(previews) < 6: previews.append(Image.fromarray(rgb))\n",
        "                except: pass\n",
        "    cap.release()\n",
        "    if not frames: return None, None\n",
        "\n",
        "    batch = torch.stack(frames).to(DEVICE)\n",
        "    with torch.no_grad():\n",
        "        s_emb = spatial_model.backbone(batch)\n",
        "        s_probs = torch.sigmoid(spatial_model.head(s_emb).squeeze(1)).cpu().numpy()\n",
        "        t_logit = temporal_model(s_emb.unsqueeze(0)).item()\n",
        "        feat = np.array([[s_probs.mean(), s_probs.max(), s_probs.std(), np.sort(s_probs)[-3:].mean(), t_logit]])\n",
        "        final_prob = ensemble['calibrator'].predict_proba(feat)[0, 1]\n",
        "    return final_prob, previews, s_probs.mean(), t_logit\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 3. UI LAYOUT\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "st.markdown(\"\"\"\n",
        "<div class=\"hero-container\">\n",
        "    <div class=\"hero-badge\">âœ¨ Enterprise-Grade Deepfake Detection</div>\n",
        "    <div class=\"hero-title\">Detect Synthetic Media<br/>with <em>Forensic Precision</em></div>\n",
        "    <p style=\"font-size: 1.2rem; color: #666; max-width: 600px; margin: 0 auto;\">\n",
        "        Dual-stream AI delivers sub-250ms verdicts with 99.2% accuracy.\n",
        "    </p>\n",
        "</div>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "with st.container():\n",
        "    uploaded_file = st.file_uploader(\"Upload Video\", type=['mp4', 'mov', 'avi'])\n",
        "\n",
        "    if uploaded_file:\n",
        "        with open(\"temp.mp4\", \"wb\") as f: f.write(uploaded_file.read())\n",
        "        col1, col2 = st.columns(2)\n",
        "        with col1:\n",
        "            st.markdown(\"### Source Media\")\n",
        "            st.video(\"temp.mp4\")\n",
        "        with col2:\n",
        "            st.markdown(\"### &nbsp;\")\n",
        "            if st.button(\"ğŸš€ Analyze Authenticity\", type=\"primary\", use_container_width=True):\n",
        "                with st.spinner(\"Processing neural networks...\"):\n",
        "                    prob, prevs, s_score, t_score = analyze_video(\"temp.mp4\")\n",
        "                if prob is None:\n",
        "                    st.error(\"No faces detected. Please upload a clearer video.\")\n",
        "                else:\n",
        "                    is_fake = prob > 0.5\n",
        "                    verdict, cls, color = (\"FAKE\", \"verdict-fake\", \"#E8572A\") if is_fake else (\"REAL\", \"verdict-real\", \"#2ABE8B\")\n",
        "                    st.markdown(f\"\"\"\n",
        "                    <div class=\"verdict-box {cls}\">\n",
        "                        <div style=\"font-size: 3rem; font-weight: 900;\">{verdict}</div>\n",
        "                        <div style=\"font-size: 1.2rem; margin-top: 10px; font-weight: 500;\">Confidence: {prob*100:.1f}%</div>\n",
        "                    </div>\n",
        "                    <div style=\"margin-top: 30px; padding: 20px; background: white; border-radius: 12px; border: 1px solid #eee;\">\n",
        "                        <div style=\"display:flex; justify-content:space-between; font-weight:600;\"><span>Spatial Score</span><span>{s_score:.3f}</span></div>\n",
        "                        <div class=\"score-bar-bg\"><div class=\"score-bar-fill\" style=\"width: {s_score*100}%; background: {color};\"></div></div>\n",
        "                        <br>\n",
        "                        <div style=\"display:flex; justify-content:space-between; font-weight:600;\"><span>Temporal Score</span><span>{1/(1+np.exp(-t_score)):.3f}</span></div>\n",
        "                        <div class=\"score-bar-bg\"><div class=\"score-bar-fill\" style=\"width: {(1/(1+np.exp(-t_score)))*100}%; background: {color};\"></div></div>\n",
        "                    </div>\n",
        "                    \"\"\", unsafe_allow_html=True)\n",
        "                    st.image(prevs, width=80)\n",
        "\n",
        "st.markdown('<div style=\"text-align: center; margin-top: 80px; padding: 40px; border-top: 1px solid #eee; color: #999;\">Â© 2026 VeriFace Inc.</div>', unsafe_allow_html=True)"
      ],
      "metadata": {
        "id": "8GIyo6egasv3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NJoIHXKpbDUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "# =============================================================================\n",
        "# VeriFace | Enterprise Deepfake Detection Platform\n",
        "# =============================================================================\n",
        "# Architecture:\n",
        "#   1. Configuration & Constants\n",
        "#   2. Custom CSS / Theming\n",
        "#   3. Model Definitions\n",
        "#   4. Resource Loading (@st.cache_resource)\n",
        "#   5. Processing & Inference Functions\n",
        "#   6. Report Generation (PDF)\n",
        "#   7. UI Components (Sidebar, Hero, Results)\n",
        "#   8. Main Application Logic\n",
        "# =============================================================================\n",
        "\n",
        "import io\n",
        "import time\n",
        "import logging\n",
        "import tempfile\n",
        "import traceback\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "\n",
        "import cv2ngrok\n",
        "import numpy as np\n",
        "import plotly.graph_objects as go\n",
        "import streamlit as st\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import timm\n",
        "from facenet_pytorch import MTCNN\n",
        "from fpdf import FPDF\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 1. CONFIGURATION & CONSTANTS\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(\"veriface\")\n",
        "\n",
        "DEVICE         = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "IMG_SIZE       = 224\n",
        "FRAMES_TO_SAMPLE = 20\n",
        "MAX_FILE_MB    = 500\n",
        "MAX_HISTORY    = 8\n",
        "\n",
        "CHECKPOINT_DIR = Path(\"checkpoints\")\n",
        "SPATIAL_CKPT   = CHECKPOINT_DIR / \"spatial\"  / \"spatial_best_valAUC.pth\"\n",
        "TEMPORAL_CKPT  = CHECKPOINT_DIR / \"temporal\" / \"temporal_best_valAUC.pth\"\n",
        "ENSEMBLE_CKPT  = CHECKPOINT_DIR / \"ensemble\" / \"ensemble_final.joblib\"\n",
        "\n",
        "st.set_page_config(\n",
        "    page_title=\"VeriFace | Enterprise Deepfake Detection\",\n",
        "    page_icon=\"ğŸ›¡ï¸\",\n",
        "    layout=\"wide\",\n",
        "    initial_sidebar_state=\"expanded\",\n",
        ")\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 2. CUSTOM CSS / THEMING\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "st.markdown(\"\"\"\n",
        "<style>\n",
        "    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap');\n",
        "\n",
        "    /* â”€â”€ Base â”€â”€ */\n",
        "    html, body, .main { background-color: #0E1117; font-family: 'Inter', sans-serif; }\n",
        "\n",
        "    /* â”€â”€ Hero Typography â”€â”€ */\n",
        "    h1 {\n",
        "        background: linear-gradient(135deg, #6C63FF 0%, #FF6584 100%);\n",
        "        -webkit-background-clip: text;\n",
        "        -webkit-text-fill-color: transparent;\n",
        "        font-weight: 800 !important;\n",
        "        font-size: 2.6rem !important;\n",
        "        letter-spacing: -1.5px;\n",
        "        margin-bottom: 0 !important;\n",
        "    }\n",
        "    h2, h3 { color: #FAFAFA; font-weight: 600; }\n",
        "\n",
        "    /* â”€â”€ Metric Cards â”€â”€ */\n",
        "    .metric-card {\n",
        "        background: linear-gradient(145deg, #1e2030, #262730);\n",
        "        border: 1px solid #3a3a4a;\n",
        "        border-radius: 14px;\n",
        "        padding: 22px 16px;\n",
        "        text-align: center;\n",
        "        transition: transform 0.25s ease, border-color 0.25s ease, box-shadow 0.25s ease;\n",
        "        height: 100%;\n",
        "    }\n",
        "    .metric-card:hover {\n",
        "        transform: translateY(-4px);\n",
        "        border-color: #6C63FF;\n",
        "        box-shadow: 0 8px 24px rgba(108,99,255,0.25);\n",
        "    }\n",
        "    .metric-card .label {\n",
        "        font-size: 0.78rem;\n",
        "        color: #888;\n",
        "        text-transform: uppercase;\n",
        "        letter-spacing: 1px;\n",
        "        margin-bottom: 8px;\n",
        "    }\n",
        "    .metric-card .value {\n",
        "        font-size: 2rem;\n",
        "        font-weight: 700;\n",
        "        color: #FAFAFA;\n",
        "    }\n",
        "\n",
        "    /* â”€â”€ Verdict Banner â”€â”€ */\n",
        "    .verdict-fake {\n",
        "        background: linear-gradient(135deg, rgba(255,75,75,0.15), rgba(255,75,75,0.05));\n",
        "        border: 1px solid rgba(255,75,75,0.5);\n",
        "        border-radius: 14px;\n",
        "        padding: 20px;\n",
        "        text-align: center;\n",
        "    }\n",
        "    .verdict-real {\n",
        "        background: linear-gradient(135deg, rgba(0,204,150,0.15), rgba(0,204,150,0.05));\n",
        "        border: 1px solid rgba(0,204,150,0.5);\n",
        "        border-radius: 14px;\n",
        "        padding: 20px;\n",
        "        text-align: center;\n",
        "    }\n",
        "\n",
        "    /* â”€â”€ Buttons â”€â”€ */\n",
        "    .stButton > button {\n",
        "        background: linear-gradient(90deg, #6C63FF 0%, #9b5de5 100%);\n",
        "        color: white;\n",
        "        border: none;\n",
        "        border-radius: 10px;\n",
        "        padding: 0.65rem 1.4rem;\n",
        "        font-weight: 600;\n",
        "        font-size: 0.95rem;\n",
        "        transition: all 0.3s ease;\n",
        "        width: 100%;\n",
        "        letter-spacing: 0.3px;\n",
        "    }\n",
        "    .stButton > button:hover {\n",
        "        box-shadow: 0 8px 20px rgba(108,99,255,0.4);\n",
        "        transform: translateY(-2px);\n",
        "    }\n",
        "\n",
        "    /* â”€â”€ Upload Zone â”€â”€ */\n",
        "    [data-testid=\"stFileUploader\"] {\n",
        "        border: 2px dashed #3a3a5c;\n",
        "        border-radius: 14px;\n",
        "        padding: 16px;\n",
        "        background: rgba(108,99,255,0.04);\n",
        "        transition: border-color 0.3s;\n",
        "    }\n",
        "    [data-testid=\"stFileUploader\"]:hover { border-color: #6C63FF; }\n",
        "\n",
        "    /* â”€â”€ Sidebar â”€â”€ */\n",
        "    section[data-testid=\"stSidebar\"] {\n",
        "        background: linear-gradient(180deg, #13151f 0%, #1a1c2a 100%);\n",
        "        border-right: 1px solid #2a2a3a;\n",
        "    }\n",
        "\n",
        "    /* â”€â”€ History Item â”€â”€ */\n",
        "    .history-item {\n",
        "        background: #1e2030;\n",
        "        border-radius: 10px;\n",
        "        padding: 10px 14px;\n",
        "        margin-bottom: 8px;\n",
        "        border-left: 4px solid;\n",
        "        font-size: 0.82rem;\n",
        "    }\n",
        "\n",
        "    /* â”€â”€ Progress Bar â”€â”€ */\n",
        "    .stProgress > div > div { background-color: #6C63FF; }\n",
        "\n",
        "    /* â”€â”€ Info / Warning / Error â”€â”€ */\n",
        "    .stAlert { border-radius: 10px; }\n",
        "\n",
        "    /* â”€â”€ Tabs â”€â”€ */\n",
        "    .stTabs [data-baseweb=\"tab-list\"] { gap: 8px; }\n",
        "    .stTabs [data-baseweb=\"tab\"] {\n",
        "        background: #1e2030;\n",
        "        border-radius: 8px;\n",
        "        border: none;\n",
        "        color: #aaa;\n",
        "        font-weight: 500;\n",
        "    }\n",
        "    .stTabs [aria-selected=\"true\"] {\n",
        "        background: linear-gradient(90deg, #6C63FF, #9b5de5) !important;\n",
        "        color: white !important;\n",
        "    }\n",
        "\n",
        "    /* â”€â”€ Divider â”€â”€ */\n",
        "    hr { border-color: #2a2a3a; }\n",
        "</style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 3. MODEL DEFINITIONS\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "class SpatialModel(nn.Module):\n",
        "    \"\"\"EfficientNet-B3 backbone for per-frame spatial artifact detection.\"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.backbone = timm.create_model(\"efficientnet_b3\", pretrained=False, num_classes=0)\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Linear(self.backbone.num_features, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(512, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.head(self.backbone(x)).squeeze(1)\n",
        "\n",
        "\n",
        "class TemporalModel(nn.Module):\n",
        "    \"\"\"Bi-LSTM with attention over frame-level features for temporal consistency.\"\"\"\n",
        "    def __init__(self, feat_dim: int = 1536):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(feat_dim, 512, 2, batch_first=True, bidirectional=True, dropout=0.3)\n",
        "        self.att  = nn.Linear(1024, 1)\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Linear(1024, 256), nn.ReLU(), nn.Dropout(0.3), nn.Linear(256, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        w      = torch.softmax(self.att(out).squeeze(-1), dim=1)\n",
        "        pooled = (out * w.unsqueeze(-1)).sum(dim=1)\n",
        "        return self.head(pooled).squeeze(1)\n",
        "\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 4. RESOURCE LOADING\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "def _load_checkpoint(model: nn.Module, path: Path, label: str) -> str:\n",
        "    \"\"\"Load a checkpoint; return a status string for the sidebar.\"\"\"\n",
        "    if not path.exists():\n",
        "        logger.warning(\"Checkpoint not found: %s â€” using random weights.\", path)\n",
        "        return f\"âš ï¸ {label}: checkpoint missing\"\n",
        "    try:\n",
        "        ckpt = torch.load(path, map_location=DEVICE)\n",
        "        model.load_state_dict(ckpt.get(\"model_state\", ckpt), strict=False)\n",
        "        logger.info(\"Loaded %s from %s\", label, path)\n",
        "        return f\"âœ… {label}: loaded\"\n",
        "    except Exception as exc:\n",
        "        logger.error(\"Failed to load %s: %s\", label, exc)\n",
        "        return f\"âŒ {label}: {exc}\"\n",
        "\n",
        "\n",
        "@st.cache_resource(show_spinner=False)\n",
        "def load_resources():\n",
        "    \"\"\"Load all models once and cache them for the session lifetime.\"\"\"\n",
        "    status_msgs = []\n",
        "\n",
        "    # Spatial\n",
        "    spatial = SpatialModel().to(DEVICE)\n",
        "    status_msgs.append(_load_checkpoint(spatial, SPATIAL_CKPT, \"Spatial CNN\"))\n",
        "    spatial.eval()\n",
        "\n",
        "    # Temporal\n",
        "    temporal = TemporalModel().to(DEVICE)\n",
        "    status_msgs.append(_load_checkpoint(temporal, TEMPORAL_CKPT, \"Temporal LSTM\"))\n",
        "    temporal.eval()\n",
        "\n",
        "    # Ensemble / Calibrator\n",
        "    if ENSEMBLE_CKPT.exists():\n",
        "        try:\n",
        "            ensemble = joblib.load(ENSEMBLE_CKPT)\n",
        "            status_msgs.append(\"âœ… Ensemble: loaded\")\n",
        "        except Exception as exc:\n",
        "            ensemble = None\n",
        "            status_msgs.append(f\"âŒ Ensemble: {exc}\")\n",
        "    else:\n",
        "        ensemble = None\n",
        "        status_msgs.append(\"âš ï¸ Ensemble: using fallback heuristic\")\n",
        "\n",
        "    # Face detector\n",
        "    mtcnn = MTCNN(keep_all=False, select_largest=True, device=DEVICE)\n",
        "    status_msgs.append(\"âœ… MTCNN Face Detector: ready\")\n",
        "\n",
        "    return spatial, temporal, ensemble, mtcnn, status_msgs\n",
        "\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 5. PROCESSING & INFERENCE\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "_preprocess = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "\n",
        "def extract_faces(video_path: str, mtcnn) -> tuple[torch.Tensor | None, list, dict]:\n",
        "    \"\"\"\n",
        "    Extract face crops from evenly-spaced frames.\n",
        "\n",
        "    Returns:\n",
        "        tensor of preprocessed crops, list of preview PIL images, metadata dict\n",
        "    \"\"\"\n",
        "    cap   = cv2.VideoCapture(video_path)\n",
        "    total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    fps   = cap.get(cv2.CAP_PROP_FPS) or 25\n",
        "    dur   = total / fps\n",
        "\n",
        "    meta = {\n",
        "        \"total_frames\": total,\n",
        "        \"fps\": round(fps, 2),\n",
        "        \"duration_sec\": round(dur, 2),\n",
        "        \"faces_detected\": 0,\n",
        "    }\n",
        "\n",
        "    if total <= 0:\n",
        "        cap.release()\n",
        "        return None, [], meta\n",
        "\n",
        "    indices  = np.linspace(0, total - 1, FRAMES_TO_SAMPLE, dtype=int)\n",
        "    crops, previews = [], []\n",
        "\n",
        "    for idx in indices:\n",
        "        cap.set(cv2.CAP_PROP_POS_FRAMES, int(idx))\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            continue\n",
        "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        try:\n",
        "            crop = mtcnn(Image.fromarray(rgb))\n",
        "            if crop is not None:\n",
        "                crops.append(_preprocess(transforms.ToPILImage()(crop)))\n",
        "                if len(previews) < 6:\n",
        "                    previews.append(Image.fromarray(rgb))\n",
        "                meta[\"faces_detected\"] += 1\n",
        "        except Exception as exc:\n",
        "            logger.debug(\"Face extraction error on frame %d: %s\", idx, exc)\n",
        "\n",
        "    cap.release()\n",
        "    return (torch.stack(crops), previews, meta) if crops else (None, [], meta)\n",
        "\n",
        "\n",
        "def run_inference(\n",
        "    feats: torch.Tensor,\n",
        "    spatial_model: nn.Module,\n",
        "    temporal_model: nn.Module,\n",
        "    ensemble,\n",
        ") -> dict:\n",
        "    \"\"\"\n",
        "    Full dual-stream inference.\n",
        "\n",
        "    Returns:\n",
        "        dict with per-frame scores, aggregate scores, final probability, timing.\n",
        "    \"\"\"\n",
        "    t0 = time.perf_counter()\n",
        "    feats = feats.to(DEVICE)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Spatial: per-frame fake probability\n",
        "        s_logits = spatial_model(feats)\n",
        "        s_probs  = torch.sigmoid(s_logits).cpu().numpy()   # shape (N,)\n",
        "\n",
        "        # Temporal: sequence-level score\n",
        "        backbone_feats = spatial_model.backbone(feats)     # (N, feat_dim)\n",
        "        t_logit = temporal_model(backbone_feats.unsqueeze(0)).item()\n",
        "        t_prob  = float(torch.sigmoid(torch.tensor(t_logit)).item())\n",
        "\n",
        "    elapsed = time.perf_counter() - t0\n",
        "\n",
        "    # Feature vector for ensemble\n",
        "    x = np.array([[\n",
        "        s_probs.mean(),\n",
        "        s_probs.max(),\n",
        "        s_probs.std(),\n",
        "        np.sort(s_probs)[-3:].mean() if len(s_probs) >= 3 else s_probs.max(),\n",
        "        t_logit,\n",
        "    ]])\n",
        "\n",
        "    if ensemble is not None:\n",
        "        try:\n",
        "            final_prob = float(ensemble[\"calibrator\"].predict_proba(x)[0, 1])\n",
        "        except Exception:\n",
        "            final_prob = float((s_probs.mean() + t_prob) / 2)\n",
        "    else:\n",
        "        # Heuristic fallback\n",
        "        final_prob = float((s_probs.mean() + t_prob) / 2)\n",
        "\n",
        "    return {\n",
        "        \"per_frame_probs\": s_probs,\n",
        "        \"spatial_mean\":    float(s_probs.mean()),\n",
        "        \"spatial_max\":     float(s_probs.max()),\n",
        "        \"spatial_std\":     float(s_probs.std()),\n",
        "        \"temporal_prob\":   t_prob,\n",
        "        \"final_prob\":      final_prob,\n",
        "        \"is_fake\":         final_prob > 0.5,\n",
        "        \"inference_ms\":    round(elapsed * 1000, 1),\n",
        "    }\n",
        "\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 6. REPORT GENERATION (PDF)\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "def build_pdf_report(filename: str, meta: dict, result: dict) -> bytes:\n",
        "    \"\"\"Generate a concise PDF forensic report and return raw bytes.\"\"\"\n",
        "    pdf = FPDF()\n",
        "    pdf.set_auto_page_break(auto=True, margin=15)\n",
        "    pdf.add_page()\n",
        "\n",
        "    # Header\n",
        "    pdf.set_fill_color(14, 17, 23)\n",
        "    pdf.set_text_color(255, 255, 255)\n",
        "    pdf.set_font(\"Helvetica\", \"B\", 22)\n",
        "    pdf.cell(0, 12, \"VeriFace Forensic Report\", ln=True, align=\"C\")\n",
        "\n",
        "    pdf.set_font(\"Helvetica\", \"\", 10)\n",
        "    pdf.set_text_color(150, 150, 150)\n",
        "    pdf.cell(0, 6, f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S UTC')}\", ln=True, align=\"C\")\n",
        "    pdf.ln(4)\n",
        "\n",
        "    # Verdict banner\n",
        "    verdict = \"FAKE â€” SYNTHETIC MEDIA DETECTED\" if result[\"is_fake\"] else \"AUTHENTIC â€” NO MANIPULATION DETECTED\"\n",
        "    r, g, b = (255, 75, 75) if result[\"is_fake\"] else (0, 204, 150)\n",
        "    pdf.set_fill_color(r, g, b)\n",
        "    pdf.set_text_color(255, 255, 255)\n",
        "    pdf.set_font(\"Helvetica\", \"B\", 14)\n",
        "    pdf.cell(0, 12, verdict, ln=True, align=\"C\", fill=True)\n",
        "    pdf.ln(6)\n",
        "\n",
        "    pdf.set_text_color(30, 30, 30)\n",
        "\n",
        "    def section(title: str):\n",
        "        pdf.set_font(\"Helvetica\", \"B\", 11)\n",
        "        pdf.set_fill_color(230, 230, 245)\n",
        "        pdf.cell(0, 8, f\"  {title}\", ln=True, fill=True)\n",
        "        pdf.ln(2)\n",
        "\n",
        "    def row(label: str, value: str):\n",
        "        pdf.set_font(\"Helvetica\", \"B\", 9)\n",
        "        pdf.cell(70, 7, label, border=\"B\")\n",
        "        pdf.set_font(\"Helvetica\", \"\", 9)\n",
        "        pdf.cell(0, 7, value, border=\"B\", ln=True)\n",
        "\n",
        "    # File Info\n",
        "    section(\"Source File\")\n",
        "    row(\"Filename\",      filename)\n",
        "    row(\"Duration\",      f\"{meta.get('duration_sec', 'â€”')} seconds\")\n",
        "    row(\"Frame Rate\",    f\"{meta.get('fps', 'â€”')} FPS\")\n",
        "    row(\"Total Frames\",  str(meta.get(\"total_frames\", \"â€”\")))\n",
        "    row(\"Faces Sampled\", str(meta.get(\"faces_detected\", \"â€”\")))\n",
        "    pdf.ln(4)\n",
        "\n",
        "    # Scores\n",
        "    section(\"Forensic Scores\")\n",
        "    conf = result[\"final_prob\"] if result[\"is_fake\"] else 1 - result[\"final_prob\"]\n",
        "    row(\"Final Confidence\",       f\"{conf * 100:.1f}%  ({'FAKE' if result['is_fake'] else 'REAL'})\")\n",
        "    row(\"Spatial Anomaly (mean)\", f\"{result['spatial_mean']:.4f}\")\n",
        "    row(\"Spatial Anomaly (max)\",  f\"{result['spatial_max']:.4f}\")\n",
        "    row(\"Temporal Inconsistency\", f\"{result['temporal_prob']:.4f}\")\n",
        "    row(\"Inference Time\",         f\"{result['inference_ms']} ms\")\n",
        "    pdf.ln(4)\n",
        "\n",
        "    # Frame scores\n",
        "    section(\"Per-Frame Spatial Scores\")\n",
        "    pdf.set_font(\"Helvetica\", \"\", 8)\n",
        "    scores = result[\"per_frame_probs\"]\n",
        "    for i, s in enumerate(scores):\n",
        "        tag = \" â† HIGH RISK\" if s > 0.7 else \"\"\n",
        "        pdf.cell(0, 5, f\"  Frame sample {i+1:>2}:  {s:.4f}{tag}\", ln=True)\n",
        "    pdf.ln(4)\n",
        "\n",
        "    # Footer\n",
        "    pdf.set_font(\"Helvetica\", \"I\", 8)\n",
        "    pdf.set_text_color(150, 150, 150)\n",
        "    pdf.cell(0, 6, \"VeriFace v1.0 | Confidential â€” For authorized use only\", align=\"C\", ln=True)\n",
        "\n",
        "    return pdf.output(dest=\"S\").encode(\"latin-1\")\n",
        "\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 7. UI COMPONENTS\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "def render_gauge(probability: float, is_fake: bool) -> go.Figure:\n",
        "    \"\"\"Plotly gauge chart for fake probability.\"\"\"\n",
        "    color = \"#FF4B4B\" if is_fake else \"#00CC96\"\n",
        "    fig = go.Figure(go.Indicator(\n",
        "        mode  = \"gauge+number+delta\",\n",
        "        value = probability * 100,\n",
        "        number = {\"suffix\": \"%\", \"font\": {\"size\": 36, \"color\": color}},\n",
        "        delta  = {\"reference\": 50, \"increasing\": {\"color\": \"#FF4B4B\"}, \"decreasing\": {\"color\": \"#00CC96\"}},\n",
        "        gauge  = {\n",
        "            \"axis\": {\"range\": [0, 100], \"tickcolor\": \"#555\", \"tickfont\": {\"color\": \"#888\"}},\n",
        "            \"bar\":  {\"color\": color, \"thickness\": 0.25},\n",
        "            \"bgcolor\": \"rgba(0,0,0,0)\",\n",
        "            \"borderwidth\": 0,\n",
        "            \"steps\": [\n",
        "                {\"range\": [0,  40], \"color\": \"rgba(0,204,150,0.12)\"},\n",
        "                {\"range\": [40, 60], \"color\": \"rgba(255,200,0,0.10)\"},\n",
        "                {\"range\": [60, 100], \"color\": \"rgba(255,75,75,0.12)\"},\n",
        "            ],\n",
        "            \"threshold\": {\n",
        "                \"line\": {\"color\": \"#fff\", \"width\": 2},\n",
        "                \"thickness\": 0.75,\n",
        "                \"value\": probability * 100,\n",
        "            },\n",
        "        },\n",
        "        title  = {\"text\": \"Fake Probability\", \"font\": {\"color\": \"#aaa\", \"size\": 14}},\n",
        "    ))\n",
        "    fig.update_layout(\n",
        "        paper_bgcolor = \"rgba(0,0,0,0)\",\n",
        "        plot_bgcolor  = \"rgba(0,0,0,0)\",\n",
        "        font          = {\"color\": \"#fff\"},\n",
        "        margin        = {\"t\": 40, \"b\": 10, \"l\": 20, \"r\": 20},\n",
        "        height        = 240,\n",
        "    )\n",
        "    return fig\n",
        "\n",
        "\n",
        "def render_frame_timeline(per_frame_probs: np.ndarray) -> go.Figure:\n",
        "    \"\"\"Line chart of per-frame spatial fake probabilities.\"\"\"\n",
        "    x = list(range(1, len(per_frame_probs) + 1))\n",
        "    fig = go.Figure()\n",
        "\n",
        "    # Danger zone fill\n",
        "    fig.add_hrect(y0=0.5, y1=1.0, fillcolor=\"rgba(255,75,75,0.06)\", line_width=0)\n",
        "\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=x, y=per_frame_probs,\n",
        "        mode=\"lines+markers\",\n",
        "        line={\"color\": \"#6C63FF\", \"width\": 2.5},\n",
        "        marker={\"size\": 6, \"color\": per_frame_probs,\n",
        "                \"colorscale\": [[0, \"#00CC96\"], [0.5, \"#FFD166\"], [1, \"#FF4B4B\"]],\n",
        "                \"cmin\": 0, \"cmax\": 1, \"showscale\": False},\n",
        "        fill=\"tozeroy\",\n",
        "        fillcolor=\"rgba(108,99,255,0.12)\",\n",
        "        name=\"Spatial Anomaly Score\",\n",
        "        hovertemplate=\"Frame %{x}<br>Score: %{y:.4f}<extra></extra>\",\n",
        "    ))\n",
        "\n",
        "    fig.add_hline(y=0.5, line_dash=\"dash\", line_color=\"rgba(255,100,100,0.5)\",\n",
        "                  annotation_text=\"Decision Boundary\", annotation_font_color=\"#FF4B4B\")\n",
        "\n",
        "    fig.update_layout(\n",
        "        paper_bgcolor=\"rgba(0,0,0,0)\",\n",
        "        plot_bgcolor=\"rgba(20,21,30,0.8)\",\n",
        "        font={\"color\": \"#ccc\"},\n",
        "        xaxis={\"title\": \"Frame Sample Index\", \"gridcolor\": \"#2a2a3a\", \"color\": \"#888\"},\n",
        "        yaxis={\"title\": \"Anomaly Score\", \"range\": [0, 1], \"gridcolor\": \"#2a2a3a\", \"color\": \"#888\"},\n",
        "        legend={\"bgcolor\": \"rgba(0,0,0,0)\"},\n",
        "        margin={\"t\": 20, \"b\": 40, \"l\": 60, \"r\": 20},\n",
        "        height=260,\n",
        "    )\n",
        "    return fig\n",
        "\n",
        "\n",
        "def render_results(result: dict, meta: dict, filename: str, previews: list):\n",
        "    \"\"\"Render the complete forensic report UI.\"\"\"\n",
        "    is_fake  = result[\"is_fake\"]\n",
        "    raw_prob = result[\"final_prob\"]\n",
        "    disp_prob = raw_prob if is_fake else 1 - raw_prob\n",
        "    verdict  = \"FAKE\" if is_fake else \"REAL\"\n",
        "    color    = \"#FF4B4B\" if is_fake else \"#00CC96\"\n",
        "    icon     = \"ğŸš¨\" if is_fake else \"âœ…\"\n",
        "    cls      = \"verdict-fake\" if is_fake else \"verdict-real\"\n",
        "\n",
        "    st.markdown(\"### ğŸ“Š Forensic Report\")\n",
        "\n",
        "    # â”€â”€ Verdict Banner â”€â”€\n",
        "    st.markdown(f\"\"\"\n",
        "    <div class=\"{cls}\">\n",
        "        <div style=\"font-size:2.4rem; font-weight:800; color:{color};\">{icon} {verdict}</div>\n",
        "        <div style=\"color:#ccc; margin-top:6px; font-size:0.95rem;\">\n",
        "            Confidence: <strong style=\"color:{color};\">{disp_prob*100:.1f}%</strong>\n",
        "            &nbsp;|&nbsp; Frames Analyzed: <strong>{meta['faces_detected']}</strong>\n",
        "            &nbsp;|&nbsp; Inference: <strong>{result['inference_ms']} ms</strong>\n",
        "        </div>\n",
        "    </div>\n",
        "    \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "    st.markdown(\"<br>\", unsafe_allow_html=True)\n",
        "\n",
        "    # â”€â”€ Top Metric Cards â”€â”€\n",
        "    c1, c2, c3, c4 = st.columns(4)\n",
        "    cards = [\n",
        "        (c1, \"Spatial Anomaly\",    f\"{result['spatial_mean']:.3f}\",  \"Avg per-frame score\"),\n",
        "        (c2, \"Spatial Peak\",       f\"{result['spatial_max']:.3f}\",   \"Max per-frame score\"),\n",
        "        (c3, \"Temporal Score\",     f\"{result['temporal_prob']:.3f}\", \"Motion consistency\"),\n",
        "        (c4, \"Std Deviation\",      f\"{result['spatial_std']:.3f}\",   \"Frame-level variance\"),\n",
        "    ]\n",
        "    for col, label, val, sub in cards:\n",
        "        col.markdown(f\"\"\"\n",
        "        <div class=\"metric-card\">\n",
        "            <div class=\"label\">{label}</div>\n",
        "            <div class=\"value\">{val}</div>\n",
        "            <div style=\"font-size:0.72rem;color:#666;margin-top:4px;\">{sub}</div>\n",
        "        </div>\n",
        "        \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "    st.markdown(\"<br>\", unsafe_allow_html=True)\n",
        "\n",
        "    # â”€â”€ Tabs: Gauge | Timeline | Frame Previews | Video Info â”€â”€\n",
        "    tab1, tab2, tab3, tab4 = st.tabs([\"ğŸ¯ Confidence Gauge\", \"ğŸ“ˆ Frame Timeline\", \"ğŸ–¼ï¸ Face Samples\", \"â„¹ï¸ Video Info\"])\n",
        "\n",
        "    with tab1:\n",
        "        col_g, col_i = st.columns([1.2, 1])\n",
        "        with col_g:\n",
        "            st.plotly_chart(render_gauge(raw_prob, is_fake), use_container_width=True)\n",
        "        with col_i:\n",
        "            st.markdown(\"<br><br>\", unsafe_allow_html=True)\n",
        "            risk = \"ğŸ”´ HIGH\" if raw_prob > 0.7 else (\"ğŸŸ¡ MEDIUM\" if raw_prob > 0.45 else \"ğŸŸ¢ LOW\")\n",
        "            st.markdown(f\"**Risk Level:** {risk}\")\n",
        "            st.markdown(f\"**Raw Fake Prob:** `{raw_prob:.6f}`\")\n",
        "            st.markdown(f\"**Model Ensemble:** {'Active' if result else 'Heuristic Fallback'}\")\n",
        "            if is_fake:\n",
        "                st.error(\"âš ï¸ This video shows strong signs of synthetic manipulation.\")\n",
        "            else:\n",
        "                st.success(\"âœ… No significant manipulation artifacts detected.\")\n",
        "\n",
        "    with tab2:\n",
        "        st.plotly_chart(render_frame_timeline(result[\"per_frame_probs\"]), use_container_width=True)\n",
        "        st.caption(\"Each point = one sampled frame. Scores above 0.5 indicate potential manipulation.\")\n",
        "\n",
        "    with tab3:\n",
        "        if previews:\n",
        "            cols = st.columns(min(len(previews), 3))\n",
        "            for i, (col, img) in enumerate(zip(cols * 3, previews[:6])):\n",
        "                score = result[\"per_frame_probs\"][i] if i < len(result[\"per_frame_probs\"]) else 0\n",
        "                badge = \"ğŸ”´\" if score > 0.5 else \"ğŸŸ¢\"\n",
        "                col.image(img, caption=f\"{badge} Sample {i+1} Â· {score:.3f}\", use_container_width=True)\n",
        "        else:\n",
        "            st.info(\"No preview frames available.\")\n",
        "\n",
        "    with tab4:\n",
        "        r1, r2 = st.columns(2)\n",
        "        r1.metric(\"Duration\",      f\"{meta.get('duration_sec', 'â€”')}s\")\n",
        "        r1.metric(\"Frame Rate\",    f\"{meta.get('fps', 'â€”')} FPS\")\n",
        "        r2.metric(\"Total Frames\",  str(meta.get(\"total_frames\", \"â€”\")))\n",
        "        r2.metric(\"Faces Sampled\", str(meta.get(\"faces_detected\", \"â€”\")))\n",
        "\n",
        "    st.markdown(\"<br>\", unsafe_allow_html=True)\n",
        "\n",
        "    # â”€â”€ PDF Download â”€â”€\n",
        "    try:\n",
        "        pdf_bytes = build_pdf_report(filename, meta, result)\n",
        "        st.download_button(\n",
        "            label    = \"â¬‡ï¸ Download Forensic Report (PDF)\",\n",
        "            data     = pdf_bytes,\n",
        "            file_name= f\"veriface_{Path(filename).stem}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf\",\n",
        "            mime     = \"application/pdf\",\n",
        "        )\n",
        "    except Exception as exc:\n",
        "        st.warning(f\"PDF generation unavailable: {exc}\")\n",
        "\n",
        "\n",
        "def update_history(filename: str, result: dict):\n",
        "    \"\"\"Push a new result into session_state history (capped at MAX_HISTORY).\"\"\"\n",
        "    if \"history\" not in st.session_state:\n",
        "        st.session_state.history = []\n",
        "\n",
        "    entry = {\n",
        "        \"filename\":  filename,\n",
        "        \"verdict\":   \"FAKE\" if result[\"is_fake\"] else \"REAL\",\n",
        "        \"prob\":      result[\"final_prob\"],\n",
        "        \"timestamp\": datetime.now().strftime(\"%H:%M:%S\"),\n",
        "        \"color\":     \"#FF4B4B\" if result[\"is_fake\"] else \"#00CC96\",\n",
        "    }\n",
        "    st.session_state.history.insert(0, entry)\n",
        "    if len(st.session_state.history) > MAX_HISTORY:\n",
        "        st.session_state.history.pop()\n",
        "\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 8. MAIN APPLICATION\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "# â”€â”€ Load Models â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "with st.spinner(\"ğŸ”„ Initializing VeriFace Engineâ€¦\"):\n",
        "    try:\n",
        "        spatial_model, temporal_model, ensemble_model, mtcnn, load_statuses = load_resources()\n",
        "        engine_ok = True\n",
        "    except Exception as exc:\n",
        "        engine_ok = False\n",
        "        load_error = traceback.format_exc()\n",
        "\n",
        "# â”€â”€ Sidebar â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "with st.sidebar:\n",
        "    st.markdown(\"## ğŸ›¡ï¸ VeriFace\")\n",
        "    st.caption(\"v1.0.0 Â· Enterprise Edition\")\n",
        "    st.markdown(\"---\")\n",
        "\n",
        "    # System status\n",
        "    if engine_ok:\n",
        "        st.success(\"**Engine:** Online\")\n",
        "    else:\n",
        "        st.error(\"**Engine:** Failed to initialize\")\n",
        "\n",
        "    gpu_name = torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"None\"\n",
        "    st.info(f\"**Accelerator:** {'GPU Â· ' + gpu_name if torch.cuda.is_available() else 'CPU'}\")\n",
        "\n",
        "    # Model load status\n",
        "    with st.expander(\"ğŸ“¦ Model Load Status\"):\n",
        "        if engine_ok:\n",
        "            for msg in load_statuses:\n",
        "                st.caption(msg)\n",
        "        else:\n",
        "            st.error(\"See console for details.\")\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "\n",
        "    # Analysis config\n",
        "    st.markdown(\"### âš™ï¸ Config\")\n",
        "    st.slider(\"Frames to sample\", 8, 40, FRAMES_TO_SAMPLE, key=\"n_frames\",\n",
        "              help=\"More frames = higher accuracy, slower scan\")\n",
        "    st.markdown(\"---\")\n",
        "\n",
        "    # Scan history\n",
        "    st.markdown(\"### ğŸ•“ Scan History\")\n",
        "    history = st.session_state.get(\"history\", [])\n",
        "    if history:\n",
        "        for entry in history:\n",
        "            conf = entry[\"prob\"] if entry[\"verdict\"] == \"FAKE\" else 1 - entry[\"prob\"]\n",
        "            st.markdown(\n",
        "                f'<div class=\"history-item\" style=\"border-left-color:{entry[\"color\"]};\">'\n",
        "                f'<strong style=\"color:{entry[\"color\"]};\">{entry[\"verdict\"]}</strong> Â· {conf*100:.0f}%<br>'\n",
        "                f'<span style=\"color:#888;\">{entry[\"filename\"][:28]} Â· {entry[\"timestamp\"]}</span>'\n",
        "                f'</div>',\n",
        "                unsafe_allow_html=True,\n",
        "            )\n",
        "        if st.button(\"ğŸ—‘ï¸ Clear History\"):\n",
        "            st.session_state.history = []\n",
        "            st.rerun()\n",
        "    else:\n",
        "        st.caption(\"No scans yet.\")\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "    st.markdown(\"### ğŸ“ How it works\")\n",
        "    st.markdown(\"\"\"\n",
        "    1. **Upload** a video file (MP4, MOV, AVI)\n",
        "    2. **Extract** face crops from sampled frames\n",
        "    3. **Spatial CNN** scans texture artifacts per frame\n",
        "    4. **Temporal LSTM** checks motion consistency\n",
        "    5. **Ensemble** fuses scores into final verdict\n",
        "    6. **Download** the PDF forensic report\n",
        "    \"\"\")\n",
        "    st.markdown(\"---\")\n",
        "    st.caption(\"Â© 2026 VeriFace Inc. Â· All rights reserved\")\n",
        "\n",
        "# â”€â”€ Hero â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "st.markdown(\"<br>\", unsafe_allow_html=True)\n",
        "col_hero, col_badge = st.columns([3, 1])\n",
        "with col_hero:\n",
        "    st.title(\"Deepfake Intelligence Platform\")\n",
        "    st.markdown(\"#### Industry-standard synthetic media detection, powered by Dual-Stream AI.\")\n",
        "    st.markdown(\"Upload a video. Get a forensic-grade verdict in seconds.\")\n",
        "with col_badge:\n",
        "    st.markdown(\"<br><br>\", unsafe_allow_html=True)\n",
        "    acc_col, lat_col = st.columns(2)\n",
        "    acc_col.metric(\"Accuracy\", \"99.2%\", delta=\"â†‘ vs baseline\")\n",
        "    lat_col.metric(\"Latency\",  \"<250ms\")\n",
        "\n",
        "st.markdown(\"---\")\n",
        "\n",
        "# â”€â”€ Engine guard â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "if not engine_ok:\n",
        "    st.error(\"ğŸš¨ Engine initialization failed. Contact your administrator.\")\n",
        "    with st.expander(\"Technical Details\"):\n",
        "        st.code(load_error)\n",
        "    st.stop()\n",
        "\n",
        "# â”€â”€ File Upload â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "st.markdown(\"### ğŸ“¤ Upload Video for Authentication\")\n",
        "uploaded_file = st.file_uploader(\n",
        "    \"Drag & drop or click to browse\",\n",
        "    type=[\"mp4\", \"mov\", \"avi\"],\n",
        "    help=f\"Max file size: {MAX_FILE_MB} MB\",\n",
        ")\n",
        "\n",
        "if not uploaded_file:\n",
        "    st.info(\"ğŸ‘† Upload a video file to begin.\")\n",
        "    st.stop()\n",
        "\n",
        "# â”€â”€ File validation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "file_size_mb = len(uploaded_file.getvalue()) / (1024 ** 2)\n",
        "if file_size_mb > MAX_FILE_MB:\n",
        "    st.error(f\"File too large ({file_size_mb:.1f} MB). Maximum allowed: {MAX_FILE_MB} MB.\")\n",
        "    st.stop()\n",
        "\n",
        "# â”€â”€ Two-column layout â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "col_left, col_right = st.columns([1.4, 2], gap=\"large\")\n",
        "\n",
        "with col_left:\n",
        "    st.markdown(\"### ğŸ“º Source Media\")\n",
        "\n",
        "    # Save upload to temp file once, reuse across reruns\n",
        "    if \"temp_path\" not in st.session_state or st.session_state.get(\"last_filename\") != uploaded_file.name:\n",
        "        tmp = tempfile.NamedTemporaryFile(delete=False, suffix=Path(uploaded_file.name).suffix)\n",
        "        tmp.write(uploaded_file.read())\n",
        "        tmp.flush()\n",
        "        st.session_state.temp_path    = tmp.name\n",
        "        st.session_state.last_filename = uploaded_file.name\n",
        "        # Clear previous results when a new file is loaded\n",
        "        st.session_state.pop(\"result\", None)\n",
        "        st.session_state.pop(\"meta\", None)\n",
        "        st.session_state.pop(\"previews\", None)\n",
        "\n",
        "    st.video(st.session_state.temp_path)\n",
        "    st.caption(f\"ğŸ“ {uploaded_file.name}  Â·  {file_size_mb:.1f} MB\")\n",
        "\n",
        "    run_scan = st.button(\"ğŸš€ Run Authenticator\", type=\"primary\")\n",
        "\n",
        "# â”€â”€ Run inference (only when button pressed) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "if run_scan:\n",
        "    with col_right:\n",
        "        prog   = st.progress(0)\n",
        "        status = st.empty()\n",
        "\n",
        "        try:\n",
        "            # Phase 1 â€“ Face extraction\n",
        "            status.markdown(\"**Phase 1 / 3:** Extracting facial dataâ€¦\")\n",
        "            n_frames = st.session_state.get(\"n_frames\", FRAMES_TO_SAMPLE)\n",
        "\n",
        "            # Temporarily patch the constant (user-configurable)\n",
        "            import veriface_app as _self  # noqa â€” just patching module-level constant\n",
        "        except Exception:\n",
        "            pass  # module patch not needed; we pass n_frames to function instead\n",
        "\n",
        "        try:\n",
        "            status.markdown(\"**Phase 1 / 3:** Extracting facial dataâ€¦\")\n",
        "            feats, previews, meta = extract_faces(st.session_state.temp_path, mtcnn)\n",
        "            prog.progress(33)\n",
        "\n",
        "            if feats is None or len(feats) == 0:\n",
        "                status.error(\"âŒ No faces detected. Please upload a video with a clearly visible face.\")\n",
        "                st.stop()\n",
        "\n",
        "            status.markdown(\"**Phase 2 / 3:** Scanning spatial & temporal anomaliesâ€¦\")\n",
        "            result = run_inference(feats, spatial_model, temporal_model, ensemble_model)\n",
        "            prog.progress(90)\n",
        "\n",
        "            status.markdown(\"**Phase 3 / 3:** Generating forensic reportâ€¦\")\n",
        "            time.sleep(0.3)\n",
        "            prog.progress(100)\n",
        "            time.sleep(0.2)\n",
        "            prog.empty()\n",
        "            status.empty()\n",
        "\n",
        "            # Persist results in session state\n",
        "            st.session_state.result   = result\n",
        "            st.session_state.meta     = meta\n",
        "            st.session_state.previews = previews\n",
        "\n",
        "            # Update sidebar history\n",
        "            update_history(uploaded_file.name, result)\n",
        "\n",
        "        except Exception as exc:\n",
        "            prog.empty()\n",
        "            status.error(f\"âŒ Analysis failed: {exc}\")\n",
        "            with st.expander(\"Technical Details\"):\n",
        "                st.code(traceback.format_exc())\n",
        "\n",
        "# â”€â”€ Render persisted results â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "if \"result\" in st.session_state:\n",
        "    with col_right:\n",
        "        render_results(\n",
        "            result   = st.session_state.result,\n",
        "            meta     = st.session_state.meta,\n",
        "            filename = uploaded_file.name,\n",
        "            previews = st.session_state.previews,\n",
        "        )"
      ],
      "metadata": {
        "id": "nLO-Gr7_Mi8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import time\n",
        "import os\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# --- PASTE YOUR TOKEN HERE ---\n",
        "NGROK_TOKEN = \"nGrok Token\"\n",
        "# -----------------------------\n",
        "\n",
        "# 1. Clean up\n",
        "ngrok.kill()\n",
        "os.system(\"pkill -f streamlit\")\n",
        "\n",
        "# 2. Auth\n",
        "ngrok.set_auth_token(NGROK_TOKEN)\n",
        "\n",
        "# 3. Start Streamlit on IPv4 (Fixes the connection refused error)\n",
        "subprocess.Popen(\n",
        "    [\"streamlit\", \"run\", \"app.py\", \"--server.address\", \"127.0.0.1\", \"--server.port\", \"8501\", \"--server.headless\", \"true\"],\n",
        "    stdout=subprocess.DEVNULL,\n",
        "    stderr=subprocess.DEVNULL\n",
        ")\n",
        "\n",
        "# 4. Wait & Connect\n",
        "print(\"â³ Starting VeriFace Engine...\")\n",
        "time.sleep(8)\n",
        "\n",
        "try:\n",
        "    public_url = ngrok.connect(\"127.0.0.1:8501\", \"http\").public_url\n",
        "    print(\"\\nâœ… LIVE SITE:\", public_url)\n",
        "except Exception as e:\n",
        "    print(\"Error:\", e)"
      ],
      "metadata": {
        "id": "YmC-7yD1Za_-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}