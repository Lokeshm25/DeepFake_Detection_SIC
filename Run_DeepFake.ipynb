{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79fdf475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy<2 in c:\\users\\lkmah\\appdata\\local\\programs\\anaconda3\\envs\\aiml\\lib\\site-packages (1.26.4)\n",
      "Collecting opencv-python-headless<4.10\n",
      "  Downloading opencv_python_headless-4.9.0.80-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Downloading opencv_python_headless-4.9.0.80-cp37-abi3-win_amd64.whl (38.5 MB)\n",
      "   ---------------------------------------- 0.0/38.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/38.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/38.5 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.5/38.5 MB 2.1 MB/s eta 0:00:19\n",
      "    --------------------------------------- 0.8/38.5 MB 1.7 MB/s eta 0:00:23\n",
      "   - -------------------------------------- 1.0/38.5 MB 1.7 MB/s eta 0:00:23\n",
      "   - -------------------------------------- 1.3/38.5 MB 1.4 MB/s eta 0:00:27\n",
      "   - -------------------------------------- 1.8/38.5 MB 1.5 MB/s eta 0:00:24\n",
      "   -- ------------------------------------- 2.1/38.5 MB 1.6 MB/s eta 0:00:23\n",
      "   -- ------------------------------------- 2.4/38.5 MB 1.6 MB/s eta 0:00:23\n",
      "   -- ------------------------------------- 2.9/38.5 MB 1.6 MB/s eta 0:00:23\n",
      "   --- ------------------------------------ 3.4/38.5 MB 1.7 MB/s eta 0:00:21\n",
      "   --- ------------------------------------ 3.7/38.5 MB 1.7 MB/s eta 0:00:21\n",
      "   ---- ----------------------------------- 4.2/38.5 MB 1.8 MB/s eta 0:00:20\n",
      "   ---- ----------------------------------- 4.5/38.5 MB 1.8 MB/s eta 0:00:20\n",
      "   ----- ---------------------------------- 5.0/38.5 MB 1.8 MB/s eta 0:00:19\n",
      "   ----- ---------------------------------- 5.5/38.5 MB 1.9 MB/s eta 0:00:18\n",
      "   ------ --------------------------------- 6.0/38.5 MB 1.9 MB/s eta 0:00:18\n",
      "   ------- -------------------------------- 6.8/38.5 MB 2.0 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 7.1/38.5 MB 2.0 MB/s eta 0:00:17\n",
      "   ------- -------------------------------- 7.6/38.5 MB 2.0 MB/s eta 0:00:16\n",
      "   -------- ------------------------------- 8.4/38.5 MB 2.1 MB/s eta 0:00:15\n",
      "   --------- ------------------------------ 8.9/38.5 MB 2.1 MB/s eta 0:00:14\n",
      "   --------- ------------------------------ 9.4/38.5 MB 2.1 MB/s eta 0:00:14\n",
      "   ---------- ----------------------------- 10.0/38.5 MB 2.1 MB/s eta 0:00:14\n",
      "   ---------- ----------------------------- 10.5/38.5 MB 2.2 MB/s eta 0:00:13\n",
      "   ----------- ---------------------------- 11.3/38.5 MB 2.2 MB/s eta 0:00:13\n",
      "   ----------- ---------------------------- 11.5/38.5 MB 2.2 MB/s eta 0:00:13\n",
      "   ------------ --------------------------- 11.8/38.5 MB 2.2 MB/s eta 0:00:13\n",
      "   ------------ --------------------------- 12.1/38.5 MB 2.2 MB/s eta 0:00:13\n",
      "   ------------ --------------------------- 12.3/38.5 MB 2.1 MB/s eta 0:00:13\n",
      "   ------------- -------------------------- 12.8/38.5 MB 2.1 MB/s eta 0:00:13\n",
      "   ------------- -------------------------- 13.1/38.5 MB 2.1 MB/s eta 0:00:13\n",
      "   -------------- ------------------------- 13.6/38.5 MB 2.1 MB/s eta 0:00:12\n",
      "   -------------- ------------------------- 13.9/38.5 MB 2.1 MB/s eta 0:00:12\n",
      "   -------------- ------------------------- 14.4/38.5 MB 2.1 MB/s eta 0:00:12\n",
      "   --------------- ------------------------ 14.7/38.5 MB 2.1 MB/s eta 0:00:12\n",
      "   --------------- ------------------------ 15.2/38.5 MB 2.1 MB/s eta 0:00:12\n",
      "   ---------------- ----------------------- 15.5/38.5 MB 2.1 MB/s eta 0:00:12\n",
      "   ---------------- ----------------------- 16.0/38.5 MB 2.1 MB/s eta 0:00:11\n",
      "   ---------------- ----------------------- 16.3/38.5 MB 2.1 MB/s eta 0:00:11\n",
      "   ----------------- ---------------------- 16.5/38.5 MB 2.1 MB/s eta 0:00:11\n",
      "   ----------------- ---------------------- 16.8/38.5 MB 2.1 MB/s eta 0:00:11\n",
      "   ----------------- ---------------------- 17.3/38.5 MB 2.0 MB/s eta 0:00:11\n",
      "   ------------------ --------------------- 17.6/38.5 MB 2.0 MB/s eta 0:00:11\n",
      "   ------------------ --------------------- 17.8/38.5 MB 2.0 MB/s eta 0:00:11\n",
      "   ------------------- -------------------- 18.4/38.5 MB 2.0 MB/s eta 0:00:11\n",
      "   ------------------- -------------------- 18.6/38.5 MB 2.0 MB/s eta 0:00:10\n",
      "   ------------------- -------------------- 18.9/38.5 MB 2.0 MB/s eta 0:00:10\n",
      "   ------------------- -------------------- 19.1/38.5 MB 2.0 MB/s eta 0:00:10\n",
      "   -------------------- ------------------- 19.7/38.5 MB 2.0 MB/s eta 0:00:10\n",
      "   -------------------- ------------------- 19.9/38.5 MB 2.0 MB/s eta 0:00:10\n",
      "   --------------------- ------------------ 20.4/38.5 MB 2.0 MB/s eta 0:00:10\n",
      "   --------------------- ------------------ 20.7/38.5 MB 2.0 MB/s eta 0:00:10\n",
      "   ---------------------- ----------------- 21.2/38.5 MB 2.0 MB/s eta 0:00:09\n",
      "   ---------------------- ----------------- 21.5/38.5 MB 2.0 MB/s eta 0:00:09\n",
      "   ---------------------- ----------------- 21.8/38.5 MB 2.0 MB/s eta 0:00:09\n",
      "   ---------------------- ----------------- 22.0/38.5 MB 2.0 MB/s eta 0:00:09\n",
      "   ----------------------- ---------------- 22.8/38.5 MB 2.0 MB/s eta 0:00:09\n",
      "   ----------------------- ---------------- 23.1/38.5 MB 2.0 MB/s eta 0:00:08\n",
      "   ------------------------ --------------- 23.6/38.5 MB 2.0 MB/s eta 0:00:08\n",
      "   ------------------------- -------------- 24.4/38.5 MB 2.0 MB/s eta 0:00:08\n",
      "   ------------------------- -------------- 24.9/38.5 MB 2.0 MB/s eta 0:00:07\n",
      "   -------------------------- ------------- 25.4/38.5 MB 2.0 MB/s eta 0:00:07\n",
      "   -------------------------- ------------- 25.7/38.5 MB 2.0 MB/s eta 0:00:07\n",
      "   --------------------------- ------------ 26.5/38.5 MB 2.0 MB/s eta 0:00:06\n",
      "   ---------------------------- ----------- 27.0/38.5 MB 2.0 MB/s eta 0:00:06\n",
      "   ---------------------------- ----------- 27.8/38.5 MB 2.1 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 28.3/38.5 MB 2.1 MB/s eta 0:00:05\n",
      "   ----------------------------- ---------- 28.8/38.5 MB 2.1 MB/s eta 0:00:05\n",
      "   ------------------------------ --------- 29.4/38.5 MB 2.1 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 30.1/38.5 MB 2.1 MB/s eta 0:00:04\n",
      "   ------------------------------- -------- 30.7/38.5 MB 2.1 MB/s eta 0:00:04\n",
      "   -------------------------------- ------- 31.2/38.5 MB 2.1 MB/s eta 0:00:04\n",
      "   -------------------------------- ------- 31.7/38.5 MB 2.1 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 32.0/38.5 MB 2.2 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 32.8/38.5 MB 2.2 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 33.0/38.5 MB 2.2 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 33.8/38.5 MB 2.2 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 34.3/38.5 MB 2.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 34.9/38.5 MB 2.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 35.4/38.5 MB 2.2 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 35.9/38.5 MB 2.2 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 36.4/38.5 MB 2.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 37.0/38.5 MB 2.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 37.5/38.5 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  37.7/38.5 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.5/38.5 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 38.5/38.5 MB 2.2 MB/s  0:00:17\n",
      "Installing collected packages: opencv-python-headless\n",
      "Successfully installed opencv-python-headless-4.9.0.80\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting streamlit\n",
      "  Downloading streamlit-1.54.0-py3-none-any.whl.metadata (9.8 kB)\n",
      "Collecting pyngrok\n",
      "  Downloading pyngrok-7.5.0-py3-none-any.whl.metadata (8.1 kB)\n",
      "Requirement already satisfied: timm in c:\\users\\lkmah\\appdata\\local\\programs\\anaconda3\\envs\\aiml\\lib\\site-packages (1.0.24)\n",
      "Requirement already satisfied: facenet-pytorch in c:\\users\\lkmah\\appdata\\local\\programs\\anaconda3\\envs\\aiml\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\lkmah\\appdata\\local\\programs\\anaconda3\\envs\\aiml\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\lkmah\\appdata\\local\\programs\\anaconda3\\envs\\aiml\\lib\\site-packages (1.5.2)\n",
      "Collecting fpdf\n",
      "  Downloading fpdf-1.7.2.tar.gz (39 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting plotly\n",
      "  Downloading plotly-6.5.2-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting altair!=5.4.0,!=5.4.1,<7,>=4.0 (from streamlit)\n",
      "  Downloading altair-6.0.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting blinker<2,>=1.5.0 (from streamlit)\n",
      "  Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting cachetools<7,>=5.5 (from streamlit)\n",
      "  Downloading cachetools-6.2.6-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\lkmah\\appdata\\local\\programs\\anaconda3\\envs\\aiml\\lib\\site-packages (from streamlit) (8.3.1)\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
      "  Downloading gitpython-3.1.46-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in c:\\users\\lkmah\\appdata\\local\\programs\\anaconda3\\envs\\aiml\\lib\\site-packages (from streamlit) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20 in c:\\users\\lkmah\\appdata\\local\\programs\\anaconda3\\envs\\aiml\\lib\\site-packages (from streamlit) (25.0)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in c:\\users\\lkmah\\appdata\\local\\programs\\anaconda3\\envs\\aiml\\lib\\site-packages (from streamlit) (2.3.3)\n",
      "Requirement already satisfied: pillow<13,>=7.1.0 in c:\\users\\lkmah\\appdata\\local\\programs\\anaconda3\\envs\\aiml\\lib\\site-packages (from streamlit) (10.2.0)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
      "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: protobuf<7,>=3.20 in c:\\users\\lkmah\\appdata\\local\\programs\\anaconda3\\envs\\aiml\\lib\\site-packages (from streamlit) (6.32.1)\n",
      "Collecting pyarrow>=7.0 (from streamlit)\n",
      "  Downloading pyarrow-23.0.1-cp311-cp311-win_amd64.whl.metadata (3.1 kB)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\lkmah\\appdata\\local\\programs\\anaconda3\\envs\\aiml\\lib\\site-packages (from streamlit) (2.32.5)\n",
      "Collecting tenacity<10,>=8.1.0 (from streamlit)\n",
      "  Downloading tenacity-9.1.4-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting toml<2,>=0.10.1 (from streamlit)\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in c:\\users\\lkmah\\appdata\\local\\programs\\anaconda3\\envs\\aiml\\lib\\site-packages (from streamlit) (6.5.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10.0 in c:\\users\\lkmah\\appdata\\local\\programs\\anaconda3\\envs\\aiml\\lib\\site-packages (from streamlit) (4.15.0)\n",
      "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
      "  Downloading watchdog-6.0.0-py3-none-win_amd64.whl.metadata (44 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\lkmah\\appdata\\local\\programs\\anaconda3\\envs\\aiml\\lib\\site-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (3.1.6)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\lkmah\\appdata\\local\\programs\\anaconda3\\envs\\aiml\\lib\\site-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (4.25.1)\n",
      "Collecting narwhals>=1.27.1 (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit)\n",
      "  Downloading narwhals-2.17.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\lkmah\\appdata\\local\\programs\\anaconda3\\envs\\aiml\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lkmah\\appdata\\local\\programs\\anaconda3\\envs\\aiml\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lkmah\\appdata\\local\\programs\\anaconda3\\envs\\aiml\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\lkmah\\appdata\\local\\programs\\anaconda3\\envs\\aiml\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\lkmah\\appdata\\local\\programs\\anaconda3\\envs\\aiml\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lkmah\\appdata\\local\\programs\\anaconda3\\envs\\aiml\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lkmah\\appdata\\local\\programs\\anaconda3\\envs\\aiml\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lkmah\\appdata\\local\\programs\\anaconda3\\envs\\aiml\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2025.10.5)\n",
      "Requirement already satisfied: PyYAML>=5.1 in c:\\users\\lkmah\\appdata\\local\\programs\\anaconda3\\envs\\aiml\\lib\\site-packages (from pyngrok) (6.0.3)\n",
      "Requirement already satisfied: torch in c:\\users\\lkmah\\appdata\\local\\programs\\anaconda3\\envs\\aiml\\lib\\site-packages (from timm) (2.9.1+cu128)\n",
      "Requirement already satisfied: torchvision in c:\\users\\lkmah\\appdata\\local\\programs\\anaconda3\\envs\\aiml\\lib\\site-packages (from timm) (0.24.1+cu128)\n",
      "Requirement already satisfied: huggingface_hub in c:\\users\\lkmah\\appdata\\local\\programs\\anaconda3\\envs\\aiml\\lib\\site-packages (from timm) (0.36.0)\n",
      "Requirement already satisfied: safetensors in c:\\users\\lkmah\\appdata\\local\\programs\\anaconda3\\envs\\aiml\\lib\\site-packages (from timm) (0.7.0)\n",
      "Collecting torch (from timm)\n",
      "  Using cached torch-2.2.2-cp311-cp311-win_amd64.whl.metadata (26 kB)\n",
      "Collecting torchvision (from timm)\n",
      "  Using cached torchvision-0.17.2-cp311-cp311-win_amd64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.0.0 in c:\\users\\lkmah\\appdata\\local\\programs\\anaconda3\\envs\\aiml\\lib\\site-packages (from facenet-pytorch) (4.67.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\lkmah\\appdata\\local\\programs\\anaconda3\\envs\\aiml\\lib\\site-packages (from torch->timm) (3.13.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\lkmah\\appdata\\local\\programs\\anaconda3\\envs\\aiml\\lib\\site-packages (from torch->timm) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\lkmah\\appdata\\local\\programs\\anaconda3\\envs\\aiml\\lib\\site-packages (from torch->timm) (3.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\lkmah\\appdata\\local\\programs\\anaconda3\\envs\\aiml\\lib\\site-packages (from torch->timm) (2024.6.1)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\lkmah\\appdata\\local\\programs\\anaconda3\\envs\\aiml\\lib\\site-packages (from scikit-learn) (1.16.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\lkmah\\appdata\\local\\programs\\anaconda3\\envs\\aiml\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\lkmah\\appdata\\local\\programs\\anaconda3\\envs\\aiml\\lib\\site-packages (from jinja2->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (3.0.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\lkmah\\appdata\\local\\programs\\anaconda3\\envs\\aiml\\lib\\site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\lkmah\\appdata\\local\\programs\\anaconda3\\envs\\aiml\\lib\\site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\lkmah\\appdata\\local\\programs\\anaconda3\\envs\\aiml\\lib\\site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\lkmah\\appdata\\local\\programs\\anaconda3\\envs\\aiml\\lib\\site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (0.27.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lkmah\\appdata\\local\\programs\\anaconda3\\envs\\aiml\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\lkmah\\appdata\\local\\programs\\anaconda3\\envs\\aiml\\lib\\site-packages (from sympy->torch->timm) (1.3.0)\n",
      "Downloading streamlit-1.54.0-py3-none-any.whl (9.1 MB)\n",
      "   ---------------------------------------- 0.0/9.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/9.1 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.5/9.1 MB 1.4 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 0.8/9.1 MB 1.3 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 1.0/9.1 MB 1.5 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 1.3/9.1 MB 1.5 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 1.6/9.1 MB 1.6 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 2.1/9.1 MB 1.6 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 2.4/9.1 MB 1.6 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 2.6/9.1 MB 1.6 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 2.9/9.1 MB 1.6 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 3.4/9.1 MB 1.6 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 3.7/9.1 MB 1.6 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 3.9/9.1 MB 1.5 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 4.2/9.1 MB 1.6 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 4.7/9.1 MB 1.6 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 5.0/9.1 MB 1.6 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 5.5/9.1 MB 1.6 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 5.8/9.1 MB 1.6 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 6.3/9.1 MB 1.7 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 6.6/9.1 MB 1.7 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 6.8/9.1 MB 1.6 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 7.1/9.1 MB 1.6 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 7.3/9.1 MB 1.6 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 7.6/9.1 MB 1.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 8.1/9.1 MB 1.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.4/9.1 MB 1.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 8.7/9.1 MB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.1/9.1 MB 1.6 MB/s  0:00:05\n",
      "Downloading altair-6.0.0-py3-none-any.whl (795 kB)\n",
      "   ---------------------------------------- 0.0/795.4 kB ? eta -:--:--\n",
      "   ------------- -------------------------- 262.1/795.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 795.4/795.4 kB 2.1 MB/s  0:00:00\n",
      "Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Downloading cachetools-6.2.6-py3-none-any.whl (11 kB)\n",
      "Downloading gitpython-3.1.46-py3-none-any.whl (208 kB)\n",
      "Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "   ---------------------------------------- 0.0/6.9 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/6.9 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.5/6.9 MB 2.1 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 0.8/6.9 MB 1.8 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 1.0/6.9 MB 1.6 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 1.6/6.9 MB 1.7 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 2.1/6.9 MB 1.8 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 2.6/6.9 MB 2.0 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 3.1/6.9 MB 2.1 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 3.7/6.9 MB 2.2 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 4.5/6.9 MB 2.3 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 5.0/6.9 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 5.5/6.9 MB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 6.0/6.9 MB 2.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 6.3/6.9 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.9/6.9 MB 2.4 MB/s  0:00:02\n",
      "Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Downloading tenacity-9.1.4-py3-none-any.whl (28 kB)\n",
      "Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Downloading watchdog-6.0.0-py3-none-win_amd64.whl (79 kB)\n",
      "Downloading pyngrok-7.5.0-py3-none-any.whl (24 kB)\n",
      "Using cached torch-2.2.2-cp311-cp311-win_amd64.whl (198.6 MB)\n",
      "Using cached torchvision-0.17.2-cp311-cp311-win_amd64.whl (1.2 MB)\n",
      "Downloading plotly-6.5.2-py3-none-any.whl (9.9 MB)\n",
      "   ---------------------------------------- 0.0/9.9 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/9.9 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.5/9.9 MB 1.9 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 0.8/9.9 MB 1.6 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 1.3/9.9 MB 1.7 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 1.8/9.9 MB 1.8 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 2.1/9.9 MB 1.8 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 2.4/9.9 MB 1.8 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 2.9/9.9 MB 1.8 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 3.1/9.9 MB 1.8 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 3.7/9.9 MB 1.8 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 3.9/9.9 MB 1.8 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 4.5/9.9 MB 1.8 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 4.7/9.9 MB 1.8 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 5.0/9.9 MB 1.8 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 5.5/9.9 MB 1.8 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 6.0/9.9 MB 1.8 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 6.3/9.9 MB 1.9 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 6.8/9.9 MB 1.9 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 7.3/9.9 MB 1.9 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 7.9/9.9 MB 1.9 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 8.7/9.9 MB 2.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.4/9.9 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.9/9.9 MB 2.2 MB/s  0:00:04\n",
      "Downloading narwhals-2.17.0-py3-none-any.whl (444 kB)\n",
      "Downloading pyarrow-23.0.1-cp311-cp311-win_amd64.whl (27.5 MB)\n",
      "   ---------------------------------------- 0.0/27.5 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.5/27.5 MB 2.1 MB/s eta 0:00:13\n",
      "   - -------------------------------------- 1.0/27.5 MB 2.4 MB/s eta 0:00:12\n",
      "   -- ------------------------------------- 1.6/27.5 MB 2.8 MB/s eta 0:00:10\n",
      "   --- ------------------------------------ 2.4/27.5 MB 2.8 MB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 3.1/27.5 MB 3.0 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 3.7/27.5 MB 3.0 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 4.2/27.5 MB 2.9 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 4.7/27.5 MB 2.9 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 5.2/27.5 MB 2.8 MB/s eta 0:00:08\n",
      "   -------- ------------------------------- 5.8/27.5 MB 2.8 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 6.3/27.5 MB 2.8 MB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 7.1/27.5 MB 2.9 MB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 7.6/27.5 MB 2.9 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 8.1/27.5 MB 2.9 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 8.9/27.5 MB 2.9 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 9.2/27.5 MB 2.9 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 9.4/27.5 MB 2.8 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 10.5/27.5 MB 2.8 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 10.7/27.5 MB 2.8 MB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 11.5/27.5 MB 2.8 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 12.1/27.5 MB 2.8 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 12.6/27.5 MB 2.8 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 13.1/27.5 MB 2.8 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 13.6/27.5 MB 2.8 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 14.2/27.5 MB 2.8 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 14.7/27.5 MB 2.8 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 15.2/27.5 MB 2.8 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 15.7/27.5 MB 2.8 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 16.3/27.5 MB 2.8 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 16.5/27.5 MB 2.7 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 16.8/27.5 MB 2.7 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 17.3/27.5 MB 2.7 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 17.6/27.5 MB 2.6 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 18.1/27.5 MB 2.6 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 18.6/27.5 MB 2.6 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 19.1/27.5 MB 2.6 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 19.7/27.5 MB 2.6 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 20.4/27.5 MB 2.6 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 21.2/27.5 MB 2.7 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 21.5/27.5 MB 2.6 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 22.3/27.5 MB 2.7 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 23.1/27.5 MB 2.7 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 23.6/27.5 MB 2.7 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 24.4/27.5 MB 2.7 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 24.6/27.5 MB 2.7 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 25.2/27.5 MB 2.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 25.7/27.5 MB 2.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 26.5/27.5 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  27.0/27.5 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  27.3/27.5 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 27.5/27.5 MB 2.7 MB/s  0:00:10\n",
      "Building wheels for collected packages: fpdf\n",
      "  Building wheel for fpdf (setup.py): started\n",
      "  Building wheel for fpdf (setup.py): finished with status 'done'\n",
      "  Created wheel for fpdf: filename=fpdf-1.7.2-py2.py3-none-any.whl size=40769 sha256=7865aff47776fc333543125c782edd7084b9a173e3c6116c330f89f0dfb81833\n",
      "  Stored in directory: c:\\users\\lkmah\\appdata\\local\\pip\\cache\\wheels\\65\\4f\\66\\bbda9866da446a72e206d6484cd97381cbc7859a7068541c36\n",
      "Successfully built fpdf\n",
      "Installing collected packages: fpdf, watchdog, toml, tenacity, smmap, pyngrok, pyarrow, narwhals, cachetools, blinker, torch, pydeck, plotly, gitdb, torchvision, gitpython, altair, streamlit\n",
      "\n",
      "   -- -------------------------------------  1/18 [watchdog]\n",
      "   -- -------------------------------------  1/18 [watchdog]\n",
      "   -------- -------------------------------  4/18 [smmap]\n",
      "   ----------- ----------------------------  5/18 [pyngrok]\n",
      "   ------------- --------------------------  6/18 [pyarrow]\n",
      "   ------------- --------------------------  6/18 [pyarrow]\n",
      "   ------------- --------------------------  6/18 [pyarrow]\n",
      "   ------------- --------------------------  6/18 [pyarrow]\n",
      "   ------------- --------------------------  6/18 [pyarrow]\n",
      "   ------------- --------------------------  6/18 [pyarrow]\n",
      "   ------------- --------------------------  6/18 [pyarrow]\n",
      "   ------------- --------------------------  6/18 [pyarrow]\n",
      "   ------------- --------------------------  6/18 [pyarrow]\n",
      "   ------------- --------------------------  6/18 [pyarrow]\n",
      "   --------------- ------------------------  7/18 [narwhals]\n",
      "   --------------- ------------------------  7/18 [narwhals]\n",
      "   --------------- ------------------------  7/18 [narwhals]\n",
      "   --------------- ------------------------  7/18 [narwhals]\n",
      "   --------------- ------------------------  7/18 [narwhals]\n",
      "   --------------- ------------------------  7/18 [narwhals]\n",
      "   --------------- ------------------------  7/18 [narwhals]\n",
      "   ----------------- ----------------------  8/18 [cachetools]\n",
      "  Attempting uninstall: torch\n",
      "   ----------------- ----------------------  8/18 [cachetools]\n",
      "    Found existing installation: torch 2.9.1+cu128\n",
      "   ----------------- ----------------------  8/18 [cachetools]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "    Uninstalling torch-2.9.1+cu128:\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "      Successfully uninstalled torch-2.9.1+cu128\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ---------------------- ----------------- 10/18 [torch]\n",
      "   ------------------------ --------------- 11/18 [pydeck]\n",
      "   ------------------------ --------------- 11/18 [pydeck]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   -------------------------- ------------- 12/18 [plotly]\n",
      "   ---------------------------- ----------- 13/18 [gitdb]\n",
      "  Attempting uninstall: torchvision\n",
      "   ---------------------------- ----------- 13/18 [gitdb]\n",
      "    Found existing installation: torchvision 0.24.1+cu128\n",
      "   ---------------------------- ----------- 13/18 [gitdb]\n",
      "    Uninstalling torchvision-0.24.1+cu128:\n",
      "   ---------------------------- ----------- 13/18 [gitdb]\n",
      "      Successfully uninstalled torchvision-0.24.1+cu128\n",
      "   ---------------------------- ----------- 13/18 [gitdb]\n",
      "   ------------------------------- -------- 14/18 [torchvision]\n",
      "   ------------------------------- -------- 14/18 [torchvision]\n",
      "   ------------------------------- -------- 14/18 [torchvision]\n",
      "   ------------------------------- -------- 14/18 [torchvision]\n",
      "   ------------------------------- -------- 14/18 [torchvision]\n",
      "   ------------------------------- -------- 14/18 [torchvision]\n",
      "   ------------------------------- -------- 14/18 [torchvision]\n",
      "   ------------------------------- -------- 14/18 [torchvision]\n",
      "   ------------------------------- -------- 14/18 [torchvision]\n",
      "   ------------------------------- -------- 14/18 [torchvision]\n",
      "   --------------------------------- ------ 15/18 [gitpython]\n",
      "   --------------------------------- ------ 15/18 [gitpython]\n",
      "   ----------------------------------- ---- 16/18 [altair]\n",
      "   ----------------------------------- ---- 16/18 [altair]\n",
      "   ----------------------------------- ---- 16/18 [altair]\n",
      "   ----------------------------------- ---- 16/18 [altair]\n",
      "   ------------------------------------- -- 17/18 [streamlit]\n",
      "   ------------------------------------- -- 17/18 [streamlit]\n",
      "   ------------------------------------- -- 17/18 [streamlit]\n",
      "   ------------------------------------- -- 17/18 [streamlit]\n",
      "   ------------------------------------- -- 17/18 [streamlit]\n",
      "   ------------------------------------- -- 17/18 [streamlit]\n",
      "   ------------------------------------- -- 17/18 [streamlit]\n",
      "   ------------------------------------- -- 17/18 [streamlit]\n",
      "   ------------------------------------- -- 17/18 [streamlit]\n",
      "   ------------------------------------- -- 17/18 [streamlit]\n",
      "   ------------------------------------- -- 17/18 [streamlit]\n",
      "   ------------------------------------- -- 17/18 [streamlit]\n",
      "   ------------------------------------- -- 17/18 [streamlit]\n",
      "   ------------------------------------- -- 17/18 [streamlit]\n",
      "   ------------------------------------- -- 17/18 [streamlit]\n",
      "   ------------------------------------- -- 17/18 [streamlit]\n",
      "   ------------------------------------- -- 17/18 [streamlit]\n",
      "   ------------------------------------- -- 17/18 [streamlit]\n",
      "   ------------------------------------- -- 17/18 [streamlit]\n",
      "   ------------------------------------- -- 17/18 [streamlit]\n",
      "   ---------------------------------------- 18/18 [streamlit]\n",
      "\n",
      "Successfully installed altair-6.0.0 blinker-1.9.0 cachetools-6.2.6 fpdf-1.7.2 gitdb-4.0.12 gitpython-3.1.46 narwhals-2.17.0 plotly-6.5.2 pyarrow-23.0.1 pydeck-0.9.1 pyngrok-7.5.0 smmap-5.0.2 streamlit-1.54.0 tenacity-9.1.4 toml-0.10.2 torch-2.2.2 torchvision-0.17.2 watchdog-6.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEPRECATION: Building 'fpdf' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'fpdf'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.9.1+cu128 requires torch==2.9.1, but you have torch 2.2.2 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "# 1. Install dependencies (Fixing numpy/opencv conflicts)\n",
    "%pip install \"numpy<2\" \"opencv-python-headless<4.10\"\n",
    "%pip install streamlit pyngrok timm facenet-pytorch scikit-learn joblib fpdf plotly\n",
    "\n",
    "# 2. Create checkpoint folders\n",
    "import os\n",
    "# os.makedirs(\"checkpoints/spatial\", exist_ok=True)\n",
    "# os.makedirs(\"checkpoints/temporal\", exist_ok=True)\n",
    "# os.makedirs(\"checkpoints/ensemble\", exist_ok=True)\n",
    "\n",
    "SPATIAL_CKPT   = \"/content/drive/MyDrive/Colab Notebooks/SIC/checkpoints/spatial/spatial_best_valAUC.pth\"\n",
    "TEMPORAL_CKPT  = \"/content/drive/MyDrive/Colab Notebooks/SIC/checkpoints/temporal/temporal_best_valAUC.pth\"\n",
    "ENSEMBLE_CKPT  = \"/content/drive/MyDrive/Colab Notebooks/SIC/checkpoints/ensemble/ensemble_final.joblib\"\n",
    "\n",
    "# print(\" Setup Complete. NOW UPLOAD YOUR 3 MODEL FILES INTO THE 'checkpoints' FOLDERS!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff96a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "# =============================================================================\n",
    "# VeriFace | Enterprise Deepfake Detection Platform\n",
    "# =============================================================================\n",
    "# Architecture:\n",
    "#   1. Configuration & Constants\n",
    "#   2. Custom CSS / Theming\n",
    "#   3. Model Definitions\n",
    "#   4. Resource Loading (@st.cache_resource)\n",
    "#   5. Processing & Inference Functions\n",
    "#   6. Report Generation (PDF)\n",
    "#   7. UI Components (Sidebar, Hero, Results)\n",
    "#   8. Main Application Logic\n",
    "# =============================================================================\n",
    "\n",
    "import io\n",
    "import time\n",
    "import logging\n",
    "import tempfile\n",
    "import traceback\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "\n",
    "import cv2\n",
    "from pyngrok import ngrok\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import streamlit as st\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "import timm\n",
    "from facenet_pytorch import MTCNN\n",
    "from fpdf import FPDF\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "# \n",
    "# 1. CONFIGURATION & CONSTANTS\n",
    "# \n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(\"veriface\")\n",
    "\n",
    "DEVICE         = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "IMG_SIZE       = 224\n",
    "FRAMES_TO_SAMPLE = 20\n",
    "MAX_FILE_MB    = 500\n",
    "MAX_HISTORY    = 8\n",
    "\n",
    "ROOT = Path.cwd()\n",
    "SPATIAL_CKPT   = ROOT / \"checkpoints\" / \"spatial\" / \"spatial_best_valAUC.pth\"\n",
    "TEMPORAL_CKPT  = ROOT / \"checkpoints\" / \"temporal\" / \"temporal_best_valAUC.pth\"\n",
    "ENSEMBLE_CKPT  = ROOT / \"checkpoints\" / \"ensemble\" / \"ensemble_final.joblib\"\n",
    "\n",
    "st.set_page_config(\n",
    "    page_title=\"VeriFace | Enterprise Deepfake Detection\",\n",
    "    page_icon=\"\",\n",
    "    layout=\"wide\",\n",
    "    initial_sidebar_state=\"expanded\",\n",
    ")\n",
    "\n",
    "# \n",
    "# 2. CUSTOM CSS / THEMING\n",
    "# \n",
    "\n",
    "st.markdown(\"\"\"\n",
    "<style>\n",
    "    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap');\n",
    "\n",
    "    /*  Base  */\n",
    "    html, body, .main { background-color: #0E1117; font-family: 'Inter', sans-serif; }\n",
    "\n",
    "    /*  Hero Typography  */\n",
    "    h1 {\n",
    "        background: linear-gradient(135deg, #6C63FF 0%, #FF6584 100%);\n",
    "        -webkit-background-clip: text;\n",
    "        -webkit-text-fill-color: transparent;\n",
    "        font-weight: 800 !important;\n",
    "        font-size: 2.6rem !important;\n",
    "        letter-spacing: -1.5px;\n",
    "        margin-bottom: 0 !important;\n",
    "    }\n",
    "    h2, h3 { color: #FAFAFA; font-weight: 600; }\n",
    "\n",
    "    /*  Metric Cards  */\n",
    "    .metric-card {\n",
    "        background: linear-gradient(145deg, #1e2030, #262730);\n",
    "        border: 1px solid #3a3a4a;\n",
    "        border-radius: 14px;\n",
    "        padding: 22px 16px;\n",
    "        text-align: center;\n",
    "        transition: transform 0.25s ease, border-color 0.25s ease, box-shadow 0.25s ease;\n",
    "        height: 100%;\n",
    "    }\n",
    "    .metric-card:hover {\n",
    "        transform: translateY(-4px);\n",
    "        border-color: #6C63FF;\n",
    "        box-shadow: 0 8px 24px rgba(108,99,255,0.25);\n",
    "    }\n",
    "    .metric-card .label {\n",
    "        font-size: 0.78rem;\n",
    "        color: #888;\n",
    "        text-transform: uppercase;\n",
    "        letter-spacing: 1px;\n",
    "        margin-bottom: 8px;\n",
    "    }\n",
    "    .metric-card .value {\n",
    "        font-size: 2rem;\n",
    "        font-weight: 700;\n",
    "        color: #FAFAFA;\n",
    "    }\n",
    "\n",
    "    /*  Verdict Banner  */\n",
    "    .verdict-fake {\n",
    "        background: linear-gradient(135deg, rgba(255,75,75,0.15), rgba(255,75,75,0.05));\n",
    "        border: 1px solid rgba(255,75,75,0.5);\n",
    "        border-radius: 14px;\n",
    "        padding: 20px;\n",
    "        text-align: center;\n",
    "    }\n",
    "    .verdict-real {\n",
    "        background: linear-gradient(135deg, rgba(0,204,150,0.15), rgba(0,204,150,0.05));\n",
    "        border: 1px solid rgba(0,204,150,0.5);\n",
    "        border-radius: 14px;\n",
    "        padding: 20px;\n",
    "        text-align: center;\n",
    "    }\n",
    "\n",
    "    /*  Buttons  */\n",
    "    .stButton > button {\n",
    "        background: linear-gradient(90deg, #6C63FF 0%, #9b5de5 100%);\n",
    "        color: white;\n",
    "        border: none;\n",
    "        border-radius: 10px;\n",
    "        padding: 0.65rem 1.4rem;\n",
    "        font-weight: 600;\n",
    "        font-size: 0.95rem;\n",
    "        transition: all 0.3s ease;\n",
    "        width: 100%;\n",
    "        letter-spacing: 0.3px;\n",
    "    }\n",
    "    .stButton > button:hover {\n",
    "        box-shadow: 0 8px 20px rgba(108,99,255,0.4);\n",
    "        transform: translateY(-2px);\n",
    "    }\n",
    "\n",
    "    /*  Upload Zone  */\n",
    "    [data-testid=\"stFileUploader\"] {\n",
    "        border: 2px dashed #3a3a5c;\n",
    "        border-radius: 14px;\n",
    "        padding: 16px;\n",
    "        background: rgba(108,99,255,0.04);\n",
    "        transition: border-color 0.3s;\n",
    "    }\n",
    "    [data-testid=\"stFileUploader\"]:hover { border-color: #6C63FF; }\n",
    "\n",
    "    /*  Sidebar  */\n",
    "    section[data-testid=\"stSidebar\"] {\n",
    "        background: linear-gradient(180deg, #13151f 0%, #1a1c2a 100%);\n",
    "        border-right: 1px solid #2a2a3a;\n",
    "    }\n",
    "\n",
    "    /*  History Item  */\n",
    "    .history-item {\n",
    "        background: #1e2030;\n",
    "        border-radius: 10px;\n",
    "        padding: 10px 14px;\n",
    "        margin-bottom: 8px;\n",
    "        border-left: 4px solid;\n",
    "        font-size: 0.82rem;\n",
    "    }\n",
    "\n",
    "    /*  Progress Bar  */\n",
    "    .stProgress > div > div { background-color: #6C63FF; }\n",
    "\n",
    "    /*  Info / Warning / Error  */\n",
    "    .stAlert { border-radius: 10px; }\n",
    "\n",
    "    /*  Tabs  */\n",
    "    .stTabs [data-baseweb=\"tab-list\"] { gap: 8px; }\n",
    "    .stTabs [data-baseweb=\"tab\"] {\n",
    "        background: #1e2030;\n",
    "        border-radius: 8px;\n",
    "        border: none;\n",
    "        color: #aaa;\n",
    "        font-weight: 500;\n",
    "    }\n",
    "    .stTabs [aria-selected=\"true\"] {\n",
    "        background: linear-gradient(90deg, #6C63FF, #9b5de5) !important;\n",
    "        color: white !important;\n",
    "    }\n",
    "\n",
    "    /*  Divider  */\n",
    "    hr { border-color: #2a2a3a; }\n",
    "</style>\n",
    "\"\"\", unsafe_allow_html=True)\n",
    "\n",
    "# \n",
    "# 3. MODEL DEFINITIONS\n",
    "# \n",
    "\n",
    "class SpatialModel(nn.Module):\n",
    "    \"\"\"EfficientNet-B3 backbone for per-frame spatial artifact detection.\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.backbone = timm.create_model(\"efficientnet_b3\", pretrained=False, num_classes=0)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(self.backbone.num_features, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(512, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.head(self.backbone(x)).squeeze(1)\n",
    "\n",
    "\n",
    "class AttentionPool(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.att = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, h, lengths=None):\n",
    "        \"\"\"\n",
    "        h: [B, T, H]\n",
    "        lengths: (optional) 1D tensor of valid lengths per batch (for masking)\n",
    "        returns: pooled [B, H], weights [B, T]\n",
    "        \"\"\"\n",
    "        B, T, _ = h.shape\n",
    "        scores = self.att(h).squeeze(-1)  # [B, T]\n",
    "\n",
    "        if lengths is not None:\n",
    "            # mask positions beyond the length\n",
    "            mask = torch.arange(T, device=h.device).unsqueeze(0) >= lengths.unsqueeze(1)\n",
    "            scores = scores.masked_fill(mask, float(\"-1e9\"))\n",
    "\n",
    "        weights = torch.softmax(scores, dim=1)\n",
    "        weights = torch.nan_to_num(weights, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        out = (h * weights.unsqueeze(-1)).sum(dim=1)\n",
    "        return out, weights\n",
    "\n",
    "\n",
    "class TemporalModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Matches the architecture used during training: Bi-LSTM (2 layers, bidirectional)\n",
    "    + AttentionPool + small head. Forward signature accepts (x, lengths).\n",
    "    \"\"\"\n",
    "    def __init__(self, feat_dim: int = 1536, hidden_dim=512, n_layers=2, bidirectional=True, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            feat_dim,\n",
    "            hidden_dim,\n",
    "            n_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=bidirectional,\n",
    "            dropout=dropout if n_layers > 1 else 0.0,\n",
    "        )\n",
    "        out_dim = hidden_dim * (2 if bidirectional else 1)\n",
    "        self.attn = AttentionPool(out_dim)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(out_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, lengths=None):\n",
    "        \"\"\"\n",
    "        x: [B, T, feat_dim]\n",
    "        lengths: 1D tensor [B] containing sequence lengths (optional)\n",
    "        \"\"\"\n",
    "        # If no lengths provided, assume all sequences are full length\n",
    "        if lengths is None:\n",
    "            lengths = torch.full((x.size(0),), x.size(1), dtype=torch.long, device=x.device)\n",
    "\n",
    "        # sort for pack sequence\n",
    "        lengths_sorted, perm_idx = lengths.sort(descending=True)\n",
    "        x_sorted = x[perm_idx]\n",
    "\n",
    "        packed = rnn_utils.pack_padded_sequence(x_sorted, lengths_sorted.cpu(), batch_first=True, enforce_sorted=True)\n",
    "        packed_out, _ = self.lstm(packed)\n",
    "        out_unpacked, _ = rnn_utils.pad_packed_sequence(packed_out, batch_first=True)\n",
    "\n",
    "        # restore original order\n",
    "        _, unperm_idx = perm_idx.sort()\n",
    "        out = out_unpacked[unperm_idx]\n",
    "        lengths = lengths[unperm_idx]\n",
    "\n",
    "        pooled, weights = self.attn(out, lengths)\n",
    "        logits = self.head(pooled).squeeze(1)\n",
    "        return logits\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# \n",
    "# 4. RESOURCE LOADING\n",
    "# \n",
    "\n",
    "def _load_checkpoint(model, path, name: str):\n",
    "    \"\"\"\n",
    "    Safely load a PyTorch checkpoint into a model.\n",
    "    Accepts path as str or Path.\n",
    "    \"\"\"\n",
    "    path = Path(path)  #  FIX: normalize to Path\n",
    "\n",
    "    if not path.exists():\n",
    "        msg = f\" {name} checkpoint not found at {path}\"\n",
    "        print(msg)\n",
    "        return msg\n",
    "\n",
    "    ck = torch.load(path, map_location=DEVICE)\n",
    "    state = ck.get(\"model_state\", ck) if isinstance(ck, dict) else ck\n",
    "    state = {k.replace(\"module.\", \"\"): v for k, v in state.items()}\n",
    "\n",
    "    missing, unexpected = model.load_state_dict(state, strict=False)\n",
    "\n",
    "    msg = f\" Loaded {name} checkpoint ({path.name})\"\n",
    "    if missing:\n",
    "        msg += f\" | Missing keys: {len(missing)}\"\n",
    "    if unexpected:\n",
    "        msg += f\" | Unexpected keys: {len(unexpected)}\"\n",
    "\n",
    "    print(msg)\n",
    "    return msg\n",
    "\n",
    "\n",
    "@st.cache_resource(show_spinner=False)\n",
    "def load_resources():\n",
    "    \"\"\"Load all models once and cache them for the session lifetime.\"\"\"\n",
    "    status_msgs = []\n",
    "\n",
    "    # Spatial\n",
    "    spatial = SpatialModel().to(DEVICE)\n",
    "    status_msgs.append(_load_checkpoint(spatial, SPATIAL_CKPT, \"Spatial CNN\"))\n",
    "    spatial.eval()\n",
    "\n",
    "    # Temporal\n",
    "    temporal = TemporalModel().to(DEVICE)\n",
    "    status_msgs.append(_load_checkpoint(temporal, TEMPORAL_CKPT, \"Temporal LSTM\"))\n",
    "    temporal.eval()\n",
    "\n",
    "    # Ensemble / Calibrator\n",
    "    if Path(ENSEMBLE_CKPT).exists():\n",
    "        try:\n",
    "            ensemble = joblib.load(ENSEMBLE_CKPT)\n",
    "            if isinstance(ensemble, dict):\n",
    "                logger.info(\"Ensemble artifact keys: %s\", list(ensemble.keys()))\n",
    "            else:\n",
    "                logger.info(\"Ensemble artifact is a single estimator of type: %s\", type(ensemble))\n",
    "            status_msgs.append(\" Ensemble: loaded\")\n",
    "        except Exception as exc:\n",
    "            ensemble = None\n",
    "            status_msgs.append(f\" Ensemble: {exc}\")\n",
    "    else:\n",
    "        ensemble = None\n",
    "        status_msgs.append(\" Ensemble: using fallback heuristic\")\n",
    "\n",
    "    # Face detector\n",
    "    mtcnn = MTCNN(keep_all=False, select_largest=True, device=DEVICE)\n",
    "    status_msgs.append(\" MTCNN Face Detector: ready\")\n",
    "\n",
    "    return spatial, temporal, ensemble, mtcnn, status_msgs\n",
    "\n",
    "\n",
    "# \n",
    "# 5. PROCESSING & INFERENCE\n",
    "# \n",
    "\n",
    "_preprocess = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "\n",
    "def extract_faces(video_path: str, mtcnn) -> tuple[torch.Tensor | None, list, dict]:\n",
    "    \"\"\"\n",
    "    Extract face crops from evenly-spaced frames.\n",
    "\n",
    "    Returns:\n",
    "        tensor of preprocessed crops, list of preview PIL images, metadata dict\n",
    "    \"\"\"\n",
    "    cap   = cv2.VideoCapture(video_path)\n",
    "    total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps   = cap.get(cv2.CAP_PROP_FPS) or 25\n",
    "    dur   = total / fps\n",
    "\n",
    "    meta = {\n",
    "        \"total_frames\": total,\n",
    "        \"fps\": round(fps, 2),\n",
    "        \"duration_sec\": round(dur, 2),\n",
    "        \"faces_detected\": 0,\n",
    "    }\n",
    "\n",
    "    if total <= 0:\n",
    "        cap.release()\n",
    "        return None, [], meta\n",
    "\n",
    "    indices  = np.linspace(0, total - 1, FRAMES_TO_SAMPLE, dtype=int)\n",
    "    crops, previews = [], []\n",
    "\n",
    "    for idx in indices:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, int(idx))\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            continue\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        try:\n",
    "            crop = mtcnn(Image.fromarray(rgb))\n",
    "            if crop is not None:\n",
    "                crops.append(_preprocess(transforms.ToPILImage()(crop)))\n",
    "                if len(previews) < 6:\n",
    "                    previews.append(Image.fromarray(rgb))\n",
    "                meta[\"faces_detected\"] += 1\n",
    "        except Exception as exc:\n",
    "            logger.debug(\"Face extraction error on frame %d: %s\", idx, exc)\n",
    "\n",
    "    cap.release()\n",
    "    return (torch.stack(crops), previews, meta) if crops else (None, [], meta)\n",
    "\n",
    "\n",
    "def run_inference(\n",
    "    feats: torch.Tensor,\n",
    "    spatial_model: nn.Module,\n",
    "    temporal_model: nn.Module,\n",
    "    ensemble,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Full dual-stream inference (spatial head + temporal model + ensemble).\n",
    "    Returns same keys as before but with correct ensemble flow.\n",
    "    \"\"\"\n",
    "    t0 = time.perf_counter()\n",
    "    feats = feats.to(DEVICE)   # [N, C, H, W]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # 1) Backbone features (compute ONCE)\n",
    "        backbone_feats = spatial_model.backbone(feats)   # [N, feat_dim]\n",
    "\n",
    "        # 2) Spatial head -> per-frame logits -> probs\n",
    "        s_logits = spatial_model.head(backbone_feats).squeeze(-1)\n",
    "        s_probs = torch.sigmoid(s_logits).cpu().numpy()  # shape (N,)\n",
    "\n",
    "        # 3) Temporal model: expects [B, T, feat_dim]\n",
    "        seq = backbone_feats.unsqueeze(0)  # [1, N, feat_dim]\n",
    "        lengths = torch.tensor([backbone_feats.shape[0]], dtype=torch.long, device=backbone_feats.device)\n",
    "        t_logit = temporal_model(seq, lengths).item()\n",
    "        t_prob = float(torch.sigmoid(torch.tensor(t_logit)).item())\n",
    "\n",
    "    elapsed = time.perf_counter() - t0\n",
    "\n",
    "    # 4) Build 5-d feature vector (use t_prob, not raw logit)\n",
    "    top3_mean = float(np.sort(s_probs)[-3:].mean()) if len(s_probs) >= 3 else float(s_probs.mean())\n",
    "    x = np.array([[\n",
    "        float(s_probs.mean()),\n",
    "        float(s_probs.max()),\n",
    "        float(s_probs.std()),\n",
    "        top3_mean,\n",
    "        t_prob,\n",
    "    ]], dtype=np.float32)  # shape (1,5)\n",
    "\n",
    "    # 5) Ensemble pipeline: base_full (pipeline) -> base_prob -> calibrator/meta\n",
    "    final_prob = None\n",
    "    if ensemble is not None:\n",
    "        try:\n",
    "            # Check ensemble has expected keys (saved by train script)\n",
    "            base_full = ensemble.get(\"base_full\", ensemble.get(\"base_pipeline\", None))\n",
    "            calibrator = ensemble.get(\"calibrator\", None)\n",
    "            meta = ensemble.get(\"meta\", None)\n",
    "\n",
    "            if base_full is None:\n",
    "                # older jobs might have stored a single calibrated classifier, handle gracefully\n",
    "                # If ensemble is a CalibratedClassifierCV fitted on base_pipe, it might accept X directly.\n",
    "                if hasattr(ensemble, \"predict_proba\"):\n",
    "                    # ensemble is a fitted classifier that returns final probs from X\n",
    "                    final_prob = float(ensemble.predict_proba(x)[:, 1][0])\n",
    "                else:\n",
    "                    raise RuntimeError(\"Ensemble object missing 'base_full' and is not a classifier.\")\n",
    "            else:\n",
    "                base_prob = base_full.predict_proba(x)[:, 1].reshape(-1, 1)  # shape (1,1)\n",
    "                if calibrator is not None:\n",
    "                    final_prob = float(calibrator.predict_proba(base_prob)[:, 1][0])\n",
    "                elif meta is not None:\n",
    "                    final_prob = float(meta.predict_proba(base_prob)[:, 1][0])\n",
    "                else:\n",
    "                    # fallback: use base_prob directly\n",
    "                    final_prob = float(base_prob[0, 0])\n",
    "        except Exception as e:\n",
    "            logger.exception(\"Ensemble prediction failed, falling back to heuristic: %s\", e)\n",
    "            final_prob = float((float(s_probs.mean()) + t_prob) / 2.0)\n",
    "    else:\n",
    "        # No ensemble loaded -> heuristic\n",
    "        final_prob = float((float(s_probs.mean()) + t_prob) / 2.0)\n",
    "\n",
    "    return {\n",
    "        \"per_frame_probs\": s_probs,\n",
    "        \"spatial_mean\":    float(s_probs.mean()),\n",
    "        \"spatial_max\":     float(s_probs.max()),\n",
    "        \"spatial_std\":     float(s_probs.std()),\n",
    "        \"temporal_prob\":   t_prob,\n",
    "        \"final_prob\":      final_prob,\n",
    "        \"is_fake\":         final_prob > 0.5,\n",
    "        \"inference_ms\":    round(elapsed * 1000, 1),\n",
    "    }\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# \n",
    "# 6. REPORT GENERATION (PDF)\n",
    "# \n",
    "\n",
    "def build_pdf_report(filename: str, meta: dict, result: dict) -> bytes:\n",
    "    \"\"\"Generate a concise PDF forensic report and return raw bytes.\"\"\"\n",
    "    pdf = FPDF()\n",
    "    pdf.set_auto_page_break(auto=True, margin=15)\n",
    "    pdf.add_page()\n",
    "\n",
    "    # Header\n",
    "    pdf.set_fill_color(14, 17, 23)\n",
    "    pdf.set_text_color(255, 255, 255)\n",
    "    pdf.set_font(\"Helvetica\", \"B\", 22)\n",
    "    pdf.cell(0, 12, \"VeriFace Forensic Report\", ln=True, align=\"C\")\n",
    "\n",
    "    pdf.set_font(\"Helvetica\", \"\", 10)\n",
    "    pdf.set_text_color(150, 150, 150)\n",
    "    pdf.cell(0, 6, f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S UTC')}\", ln=True, align=\"C\")\n",
    "    pdf.ln(4)\n",
    "\n",
    "    # Verdict banner\n",
    "    verdict = \"FAKE  SYNTHETIC MEDIA DETECTED\" if result[\"is_fake\"] else \"AUTHENTIC  NO MANIPULATION DETECTED\"\n",
    "    r, g, b = (255, 75, 75) if result[\"is_fake\"] else (0, 204, 150)\n",
    "    pdf.set_fill_color(r, g, b)\n",
    "    pdf.set_text_color(255, 255, 255)\n",
    "    pdf.set_font(\"Helvetica\", \"B\", 14)\n",
    "    pdf.cell(0, 12, verdict, ln=True, align=\"C\", fill=True)\n",
    "    pdf.ln(6)\n",
    "\n",
    "    pdf.set_text_color(30, 30, 30)\n",
    "\n",
    "    def section(title: str):\n",
    "        pdf.set_font(\"Helvetica\", \"B\", 11)\n",
    "        pdf.set_fill_color(230, 230, 245)\n",
    "        pdf.cell(0, 8, f\"  {title}\", ln=True, fill=True)\n",
    "        pdf.ln(2)\n",
    "\n",
    "    def row(label: str, value: str):\n",
    "        pdf.set_font(\"Helvetica\", \"B\", 9)\n",
    "        pdf.cell(70, 7, label, border=\"B\")\n",
    "        pdf.set_font(\"Helvetica\", \"\", 9)\n",
    "        pdf.cell(0, 7, value, border=\"B\", ln=True)\n",
    "\n",
    "    # File Info\n",
    "    section(\"Source File\")\n",
    "    row(\"Filename\",      filename)\n",
    "    row(\"Duration\",      f\"{meta.get('duration_sec', '')} seconds\")\n",
    "    row(\"Frame Rate\",    f\"{meta.get('fps', '')} FPS\")\n",
    "    row(\"Total Frames\",  str(meta.get(\"total_frames\", \"\")))\n",
    "    row(\"Faces Sampled\", str(meta.get(\"faces_detected\", \"\")))\n",
    "    pdf.ln(4)\n",
    "\n",
    "    # Scores\n",
    "    section(\"Forensic Scores\")\n",
    "    conf = result[\"final_prob\"] if result[\"is_fake\"] else 1 - result[\"final_prob\"]\n",
    "    row(\"Final Confidence\",       f\"{conf * 100:.1f}%  ({'FAKE' if result['is_fake'] else 'REAL'})\")\n",
    "    row(\"Spatial Anomaly (mean)\", f\"{result['spatial_mean']:.4f}\")\n",
    "    row(\"Spatial Anomaly (max)\",  f\"{result['spatial_max']:.4f}\")\n",
    "    row(\"Temporal Inconsistency\", f\"{result['temporal_prob']:.4f}\")\n",
    "    row(\"Inference Time\",         f\"{result['inference_ms']} ms\")\n",
    "    pdf.ln(4)\n",
    "\n",
    "    # Frame scores\n",
    "    section(\"Per-Frame Spatial Scores\")\n",
    "    pdf.set_font(\"Helvetica\", \"\", 8)\n",
    "    scores = result[\"per_frame_probs\"]\n",
    "    for i, s in enumerate(scores):\n",
    "        tag = \"  HIGH RISK\" if s > 0.7 else \"\"\n",
    "        pdf.cell(0, 5, f\"  Frame sample {i+1:>2}:  {s:.4f}{tag}\", ln=True)\n",
    "    pdf.ln(4)\n",
    "\n",
    "    # Footer\n",
    "    pdf.set_font(\"Helvetica\", \"I\", 8)\n",
    "    pdf.set_text_color(150, 150, 150)\n",
    "    pdf.cell(0, 6, \"VeriFace v1.0 | Confidential  For authorized use only\", align=\"C\", ln=True)\n",
    "\n",
    "    return pdf.output(dest=\"S\").encode(\"latin-1\")\n",
    "\n",
    "\n",
    "# \n",
    "# 7. UI COMPONENTS\n",
    "# \n",
    "\n",
    "def render_gauge(probability: float, is_fake: bool) -> go.Figure:\n",
    "    \"\"\"Plotly gauge chart for fake probability.\"\"\"\n",
    "    color = \"#FF4B4B\" if is_fake else \"#00CC96\"\n",
    "    fig = go.Figure(go.Indicator(\n",
    "        mode  = \"gauge+number+delta\",\n",
    "        value = probability * 100,\n",
    "        number = {\"suffix\": \"%\", \"font\": {\"size\": 36, \"color\": color}},\n",
    "        delta  = {\"reference\": 50, \"increasing\": {\"color\": \"#FF4B4B\"}, \"decreasing\": {\"color\": \"#00CC96\"}},\n",
    "        gauge  = {\n",
    "            \"axis\": {\"range\": [0, 100], \"tickcolor\": \"#555\", \"tickfont\": {\"color\": \"#888\"}},\n",
    "            \"bar\":  {\"color\": color, \"thickness\": 0.25},\n",
    "            \"bgcolor\": \"rgba(0,0,0,0)\",\n",
    "            \"borderwidth\": 0,\n",
    "            \"steps\": [\n",
    "                {\"range\": [0,  40], \"color\": \"rgba(0,204,150,0.12)\"},\n",
    "                {\"range\": [40, 60], \"color\": \"rgba(255,200,0,0.10)\"},\n",
    "                {\"range\": [60, 100], \"color\": \"rgba(255,75,75,0.12)\"},\n",
    "            ],\n",
    "            \"threshold\": {\n",
    "                \"line\": {\"color\": \"#fff\", \"width\": 2},\n",
    "                \"thickness\": 0.75,\n",
    "                \"value\": probability * 100,\n",
    "            },\n",
    "        },\n",
    "        title  = {\"text\": \"Fake Probability\", \"font\": {\"color\": \"#aaa\", \"size\": 14}},\n",
    "    ))\n",
    "    fig.update_layout(\n",
    "        paper_bgcolor = \"rgba(0,0,0,0)\",\n",
    "        plot_bgcolor  = \"rgba(0,0,0,0)\",\n",
    "        font          = {\"color\": \"#fff\"},\n",
    "        margin        = {\"t\": 40, \"b\": 10, \"l\": 20, \"r\": 20},\n",
    "        height        = 240,\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "\n",
    "def render_frame_timeline(per_frame_probs: np.ndarray) -> go.Figure:\n",
    "    \"\"\"Line chart of per-frame spatial fake probabilities.\"\"\"\n",
    "    x = list(range(1, len(per_frame_probs) + 1))\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Danger zone fill\n",
    "    fig.add_hrect(y0=0.5, y1=1.0, fillcolor=\"rgba(255,75,75,0.06)\", line_width=0)\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=x, y=per_frame_probs,\n",
    "        mode=\"lines+markers\",\n",
    "        line={\"color\": \"#6C63FF\", \"width\": 2.5},\n",
    "        marker={\"size\": 6, \"color\": per_frame_probs,\n",
    "                \"colorscale\": [[0, \"#00CC96\"], [0.5, \"#FFD166\"], [1, \"#FF4B4B\"]],\n",
    "                \"cmin\": 0, \"cmax\": 1, \"showscale\": False},\n",
    "        fill=\"tozeroy\",\n",
    "        fillcolor=\"rgba(108,99,255,0.12)\",\n",
    "        name=\"Spatial Anomaly Score\",\n",
    "        hovertemplate=\"Frame %{x}<br>Score: %{y:.4f}<extra></extra>\",\n",
    "    ))\n",
    "\n",
    "    fig.add_hline(y=0.5, line_dash=\"dash\", line_color=\"rgba(255,100,100,0.5)\",\n",
    "                  annotation_text=\"Decision Boundary\", annotation_font_color=\"#FF4B4B\")\n",
    "\n",
    "    fig.update_layout(\n",
    "        paper_bgcolor=\"rgba(0,0,0,0)\",\n",
    "        plot_bgcolor=\"rgba(20,21,30,0.8)\",\n",
    "        font={\"color\": \"#ccc\"},\n",
    "        xaxis={\"title\": \"Frame Sample Index\", \"gridcolor\": \"#2a2a3a\", \"color\": \"#888\"},\n",
    "        yaxis={\"title\": \"Anomaly Score\", \"range\": [0, 1], \"gridcolor\": \"#2a2a3a\", \"color\": \"#888\"},\n",
    "        legend={\"bgcolor\": \"rgba(0,0,0,0)\"},\n",
    "        margin={\"t\": 20, \"b\": 40, \"l\": 60, \"r\": 20},\n",
    "        height=260,\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "\n",
    "def render_results(result: dict, meta: dict, filename: str, previews: list):\n",
    "    \"\"\"Render the complete forensic report UI.\"\"\"\n",
    "    is_fake  = result[\"is_fake\"]\n",
    "    raw_prob = result[\"final_prob\"]\n",
    "    disp_prob = raw_prob if is_fake else 1 - raw_prob\n",
    "    verdict  = \"FAKE\" if is_fake else \"REAL\"\n",
    "    color    = \"#FF4B4B\" if is_fake else \"#00CC96\"\n",
    "    icon     = \"\" if is_fake else \"\"\n",
    "    cls      = \"verdict-fake\" if is_fake else \"verdict-real\"\n",
    "\n",
    "    st.markdown(\"###  Forensic Report\")\n",
    "\n",
    "    #  Verdict Banner \n",
    "    st.markdown(f\"\"\"\n",
    "    <div class=\"{cls}\">\n",
    "        <div style=\"font-size:2.4rem; font-weight:800; color:{color};\">{icon} {verdict}</div>\n",
    "        <div style=\"color:#ccc; margin-top:6px; font-size:0.95rem;\">\n",
    "            Confidence: <strong style=\"color:{color};\">{disp_prob*100:.1f}%</strong>\n",
    "            &nbsp;|&nbsp; Frames Analyzed: <strong>{meta['faces_detected']}</strong>\n",
    "            &nbsp;|&nbsp; Inference: <strong>{result['inference_ms']} ms</strong>\n",
    "        </div>\n",
    "    </div>\n",
    "    \"\"\", unsafe_allow_html=True)\n",
    "\n",
    "    st.markdown(\"<br>\", unsafe_allow_html=True)\n",
    "\n",
    "    #  Top Metric Cards \n",
    "    c1, c2, c3, c4 = st.columns(4)\n",
    "    cards = [\n",
    "        (c1, \"Spatial Anomaly\",    f\"{result['spatial_mean']:.3f}\",  \"Avg per-frame score\"),\n",
    "        (c2, \"Spatial Peak\",       f\"{result['spatial_max']:.3f}\",   \"Max per-frame score\"),\n",
    "        (c3, \"Temporal Score\",     f\"{result['temporal_prob']:.3f}\", \"Motion consistency\"),\n",
    "        (c4, \"Std Deviation\",      f\"{result['spatial_std']:.3f}\",   \"Frame-level variance\"),\n",
    "    ]\n",
    "    for col, label, val, sub in cards:\n",
    "        col.markdown(f\"\"\"\n",
    "        <div class=\"metric-card\">\n",
    "            <div class=\"label\">{label}</div>\n",
    "            <div class=\"value\">{val}</div>\n",
    "            <div style=\"font-size:0.72rem;color:#666;margin-top:4px;\">{sub}</div>\n",
    "        </div>\n",
    "        \"\"\", unsafe_allow_html=True)\n",
    "\n",
    "    st.markdown(\"<br>\", unsafe_allow_html=True)\n",
    "\n",
    "    #  Tabs: Gauge | Timeline | Frame Previews | Video Info \n",
    "    tab1, tab2, tab3, tab4 = st.tabs([\" Confidence Gauge\", \" Frame Timeline\", \" Face Samples\", \" Video Info\"])\n",
    "\n",
    "    with tab1:\n",
    "        col_g, col_i = st.columns([1.2, 1])\n",
    "        with col_g:\n",
    "            st.plotly_chart(render_gauge(raw_prob, is_fake), use_container_width=True)\n",
    "        with col_i:\n",
    "            st.markdown(\"<br><br>\", unsafe_allow_html=True)\n",
    "            risk = \" HIGH\" if raw_prob > 0.7 else (\" MEDIUM\" if raw_prob > 0.45 else \" LOW\")\n",
    "            st.markdown(f\"**Risk Level:** {risk}\")\n",
    "            st.markdown(f\"**Raw Fake Prob:** `{raw_prob:.6f}`\")\n",
    "            st.markdown(f\"**Model Ensemble:** {'Active' if result else 'Heuristic Fallback'}\")\n",
    "            if is_fake:\n",
    "                st.error(\" This video shows strong signs of synthetic manipulation.\")\n",
    "            else:\n",
    "                st.success(\" No significant manipulation artifacts detected.\")\n",
    "\n",
    "    with tab2:\n",
    "        st.plotly_chart(render_frame_timeline(result[\"per_frame_probs\"]), use_container_width=True)\n",
    "        st.caption(\"Each point = one sampled frame. Scores above 0.5 indicate potential manipulation.\")\n",
    "\n",
    "    with tab3:\n",
    "        if previews:\n",
    "            cols = st.columns(min(len(previews), 3))\n",
    "            for i, (col, img) in enumerate(zip(cols * 3, previews[:6])):\n",
    "                score = result[\"per_frame_probs\"][i] if i < len(result[\"per_frame_probs\"]) else 0\n",
    "                badge = \"\" if score > 0.5 else \"\"\n",
    "                col.image(img, caption=f\"{badge} Sample {i+1}  {score:.3f}\", use_container_width=True)\n",
    "        else:\n",
    "            st.info(\"No preview frames available.\")\n",
    "\n",
    "    with tab4:\n",
    "        r1, r2 = st.columns(2)\n",
    "        r1.metric(\"Duration\",      f\"{meta.get('duration_sec', '')}s\")\n",
    "        r1.metric(\"Frame Rate\",    f\"{meta.get('fps', '')} FPS\")\n",
    "        r2.metric(\"Total Frames\",  str(meta.get(\"total_frames\", \"\")))\n",
    "        r2.metric(\"Faces Sampled\", str(meta.get(\"faces_detected\", \"\")))\n",
    "\n",
    "    st.markdown(\"<br>\", unsafe_allow_html=True)\n",
    "\n",
    "    #  PDF Download \n",
    "    try:\n",
    "        pdf_bytes = build_pdf_report(filename, meta, result)\n",
    "        st.download_button(\n",
    "            label    = \" Download Forensic Report (PDF)\",\n",
    "            data     = pdf_bytes,\n",
    "            file_name= f\"veriface_{Path(filename).stem}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf\",\n",
    "            mime     = \"application/pdf\",\n",
    "        )\n",
    "    except Exception as exc:\n",
    "        st.warning(f\"PDF generation unavailable: {exc}\")\n",
    "\n",
    "\n",
    "def update_history(filename: str, result: dict):\n",
    "    \"\"\"Push a new result into session_state history (capped at MAX_HISTORY).\"\"\"\n",
    "    if \"history\" not in st.session_state:\n",
    "        st.session_state.history = []\n",
    "\n",
    "    entry = {\n",
    "        \"filename\":  filename,\n",
    "        \"verdict\":   \"FAKE\" if result[\"is_fake\"] else \"REAL\",\n",
    "        \"prob\":      result[\"final_prob\"],\n",
    "        \"timestamp\": datetime.now().strftime(\"%H:%M:%S\"),\n",
    "        \"color\":     \"#FF4B4B\" if result[\"is_fake\"] else \"#00CC96\",\n",
    "    }\n",
    "    st.session_state.history.insert(0, entry)\n",
    "    if len(st.session_state.history) > MAX_HISTORY:\n",
    "        st.session_state.history.pop()\n",
    "\n",
    "\n",
    "# \n",
    "# 8. MAIN APPLICATION\n",
    "# \n",
    "\n",
    "#  Load Models \n",
    "with st.spinner(\" Initializing VeriFace Engine\"):\n",
    "    try:\n",
    "        spatial_model, temporal_model, ensemble_model, mtcnn, load_statuses = load_resources()\n",
    "        engine_ok = True\n",
    "    except Exception as exc:\n",
    "        engine_ok = False\n",
    "        load_error = traceback.format_exc()\n",
    "\n",
    "#  Sidebar \n",
    "with st.sidebar:\n",
    "    st.markdown(\"##  VeriFace\")\n",
    "    st.caption(\"v1.0.0  Enterprise Edition\")\n",
    "    st.markdown(\"---\")\n",
    "\n",
    "    # System status\n",
    "    if engine_ok:\n",
    "        st.success(\"**Engine:** Online\")\n",
    "    else:\n",
    "        st.error(\"**Engine:** Failed to initialize\")\n",
    "\n",
    "    gpu_name = torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"None\"\n",
    "    st.info(f\"**Accelerator:** {'GPU  ' + gpu_name if torch.cuda.is_available() else 'CPU'}\")\n",
    "\n",
    "    # Model load status\n",
    "    with st.expander(\" Model Load Status\"):\n",
    "        if engine_ok:\n",
    "            for msg in load_statuses:\n",
    "                st.caption(msg)\n",
    "        else:\n",
    "            st.error(\"See console for details.\")\n",
    "\n",
    "    st.markdown(\"---\")\n",
    "\n",
    "    # Analysis config\n",
    "    st.markdown(\"###  Config\")\n",
    "    st.slider(\"Frames to sample\", 8, 40, FRAMES_TO_SAMPLE, key=\"n_frames\",\n",
    "              help=\"More frames = higher accuracy, slower scan\")\n",
    "    st.markdown(\"---\")\n",
    "\n",
    "    # Scan history\n",
    "    st.markdown(\"###  Scan History\")\n",
    "    history = st.session_state.get(\"history\", [])\n",
    "    if history:\n",
    "        for entry in history:\n",
    "            conf = entry[\"prob\"] if entry[\"verdict\"] == \"FAKE\" else 1 - entry[\"prob\"]\n",
    "            st.markdown(\n",
    "                f'<div class=\"history-item\" style=\"border-left-color:{entry[\"color\"]};\">'\n",
    "                f'<strong style=\"color:{entry[\"color\"]};\">{entry[\"verdict\"]}</strong>  {conf*100:.0f}%<br>'\n",
    "                f'<span style=\"color:#888;\">{entry[\"filename\"][:28]}  {entry[\"timestamp\"]}</span>'\n",
    "                f'</div>',\n",
    "                unsafe_allow_html=True,\n",
    "            )\n",
    "        if st.button(\" Clear History\"):\n",
    "            st.session_state.history = []\n",
    "            st.rerun()\n",
    "    else:\n",
    "        st.caption(\"No scans yet.\")\n",
    "\n",
    "    st.markdown(\"---\")\n",
    "    st.markdown(\"###  How it works\")\n",
    "    st.markdown(\"\"\"\n",
    "    1. **Upload** a video file (MP4, MOV, AVI)\n",
    "    2. **Extract** face crops from sampled frames\n",
    "    3. **Spatial CNN** scans texture artifacts per frame\n",
    "    4. **Temporal LSTM** checks motion consistency\n",
    "    5. **Ensemble** fuses scores into final verdict\n",
    "    6. **Download** the PDF forensic report\n",
    "    \"\"\")\n",
    "    st.markdown(\"---\")\n",
    "    st.caption(\" 2026 VeriFace Inc.  All rights reserved\")\n",
    "\n",
    "#  Hero \n",
    "st.markdown(\"<br>\", unsafe_allow_html=True)\n",
    "col_hero, col_badge = st.columns([3, 1])\n",
    "with col_hero:\n",
    "    st.title(\"Deepfake Intelligence Platform\")\n",
    "    st.markdown(\"#### Industry-standard synthetic media detection, powered by Dual-Stream AI.\")\n",
    "    st.markdown(\"Upload a video. Get a forensic-grade verdict in seconds.\")\n",
    "with col_badge:\n",
    "    st.markdown(\"<br><br>\", unsafe_allow_html=True)\n",
    "    acc_col, lat_col = st.columns(2)\n",
    "    acc_col.metric(\"Accuracy\", \"99.2%\", delta=\" vs baseline\")\n",
    "    lat_col.metric(\"Latency\",  \"<250ms\")\n",
    "\n",
    "st.markdown(\"---\")\n",
    "\n",
    "#  Engine guard \n",
    "if not engine_ok:\n",
    "    st.error(\" Engine initialization failed. Contact your administrator.\")\n",
    "    with st.expander(\"Technical Details\"):\n",
    "        st.code(load_error)\n",
    "    st.stop()\n",
    "\n",
    "#  File Upload \n",
    "st.markdown(\"###  Upload Video for Authentication\")\n",
    "uploaded_file = st.file_uploader(\n",
    "    \"Drag & drop or click to browse\",\n",
    "    type=[\"mp4\", \"mov\", \"avi\"],\n",
    "    help=f\"Max file size: {MAX_FILE_MB} MB\",\n",
    ")\n",
    "\n",
    "if not uploaded_file:\n",
    "    st.info(\" Upload a video file to begin.\")\n",
    "    st.stop()\n",
    "\n",
    "#  File validation \n",
    "file_size_mb = len(uploaded_file.getvalue()) / (1024 ** 2)\n",
    "if file_size_mb > MAX_FILE_MB:\n",
    "    st.error(f\"File too large ({file_size_mb:.1f} MB). Maximum allowed: {MAX_FILE_MB} MB.\")\n",
    "    st.stop()\n",
    "\n",
    "#  Two-column layout \n",
    "col_left, col_right = st.columns([1.4, 2], gap=\"large\")\n",
    "\n",
    "with col_left:\n",
    "    st.markdown(\"###  Source Media\")\n",
    "\n",
    "    # Save upload to temp file once, reuse across reruns\n",
    "    if \"temp_path\" not in st.session_state or st.session_state.get(\"last_filename\") != uploaded_file.name:\n",
    "        tmp = tempfile.NamedTemporaryFile(delete=False, suffix=Path(uploaded_file.name).suffix)\n",
    "        tmp.write(uploaded_file.read())\n",
    "        tmp.flush()\n",
    "        st.session_state.temp_path    = tmp.name\n",
    "        st.session_state.last_filename = uploaded_file.name\n",
    "        # Clear previous results when a new file is loaded\n",
    "        st.session_state.pop(\"result\", None)\n",
    "        st.session_state.pop(\"meta\", None)\n",
    "        st.session_state.pop(\"previews\", None)\n",
    "\n",
    "    st.video(st.session_state.temp_path)\n",
    "    st.caption(f\" {uploaded_file.name}    {file_size_mb:.1f} MB\")\n",
    "\n",
    "    run_scan = st.button(\" Run Authenticator\", type=\"primary\")\n",
    "\n",
    "#  Run inference (only when button pressed) \n",
    "if run_scan:\n",
    "    with col_right:\n",
    "        prog   = st.progress(0)\n",
    "        status = st.empty()\n",
    "\n",
    "        try:\n",
    "            # Phase 1  Face extraction\n",
    "            status.markdown(\"**Phase 1 / 3:** Extracting facial data\")\n",
    "            n_frames = st.session_state.get(\"n_frames\", FRAMES_TO_SAMPLE)\n",
    "\n",
    "            # Temporarily patch the constant (user-configurable)\n",
    "            import veriface_app as _self  # noqa  just patching module-level constant\n",
    "        except Exception:\n",
    "            pass  # module patch not needed; we pass n_frames to function instead\n",
    "\n",
    "        try:\n",
    "            status.markdown(\"**Phase 1 / 3:** Extracting facial data\")\n",
    "            feats, previews, meta = extract_faces(st.session_state.temp_path, mtcnn)\n",
    "            prog.progress(33)\n",
    "\n",
    "            if feats is None or len(feats) == 0:\n",
    "                status.error(\" No faces detected. Please upload a video with a clearly visible face.\")\n",
    "                st.stop()\n",
    "\n",
    "            status.markdown(\"**Phase 2 / 3:** Scanning spatial & temporal anomalies\")\n",
    "            result = run_inference(feats, spatial_model, temporal_model, ensemble_model)\n",
    "            prog.progress(90)\n",
    "\n",
    "            status.markdown(\"**Phase 3 / 3:** Generating forensic report\")\n",
    "            time.sleep(0.3)\n",
    "            prog.progress(100)\n",
    "            time.sleep(0.2)\n",
    "            prog.empty()\n",
    "            status.empty()\n",
    "\n",
    "            # Persist results in session state\n",
    "            st.session_state.result   = result\n",
    "            st.session_state.meta     = meta\n",
    "            st.session_state.previews = previews\n",
    "\n",
    "            # Update sidebar history\n",
    "            update_history(uploaded_file.name, result)\n",
    "\n",
    "        except Exception as exc:\n",
    "            prog.empty()\n",
    "            status.error(f\" Analysis failed: {exc}\")\n",
    "            with st.expander(\"Technical Details\"):\n",
    "                st.code(traceback.format_exc())\n",
    "\n",
    "#  Render persisted results \n",
    "if \"result\" in st.session_state:\n",
    "    with col_right:\n",
    "        render_results(\n",
    "            result   = st.session_state.result,\n",
    "            meta     = st.session_state.meta,\n",
    "            filename = uploaded_file.name,\n",
    "            previews = st.session_state.previews,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d330b9ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyngrok in c:\\users\\lkmah\\appdata\\local\\programs\\anaconda3\\envs\\aiml\\lib\\site-packages (7.5.0)\n",
      "Requirement already satisfied: PyYAML>=5.1 in c:\\users\\lkmah\\appdata\\local\\programs\\anaconda3\\envs\\aiml\\lib\\site-packages (from pyngrok) (6.0.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      " Starting VeriFace Engine...                                                                       \n",
      "\n",
      " LIVE SITE: https://unparentally-nonelicited-brantley.ngrok-free.dev\n"
     ]
    }
   ],
   "source": [
    "%pip install pyngrok\n",
    "import subprocess\n",
    "import time\n",
    "import os\n",
    "from pyngrok import ngrok\n",
    "\n",
    "# --- PASTE YOUR TOKEN HERE ---\n",
    "NGROK_TOKEN = \"3A7VJIcFuvlJ39DDqF5HQTjWeQc_53ZQVwffxN68p7yttw2Cx\"\n",
    "# -----------------------------\n",
    "\n",
    "# 1. Clean up\n",
    "ngrok.kill()\n",
    "os.system(\"pkill -f streamlit\")\n",
    "\n",
    "# 2. Auth\n",
    "ngrok.set_auth_token(NGROK_TOKEN)\n",
    "\n",
    "# 3. Start Streamlit on IPv4 (Fixes the connection refused error)\n",
    "subprocess.Popen(\n",
    "    [\"streamlit\", \"run\", \"app.py\", \"--server.address\", \"127.0.0.1\", \"--server.port\", \"8501\", \"--server.headless\", \"true\"],\n",
    "    stdout=subprocess.DEVNULL,\n",
    "    stderr=subprocess.DEVNULL\n",
    ")\n",
    "\n",
    "# 4. Wait & Connect\n",
    "print(\" Starting VeriFace Engine...\")\n",
    "time.sleep(8)\n",
    "\n",
    "try:\n",
    "    public_url = ngrok.connect(\"127.0.0.1:8501\", \"http\").public_url\n",
    "    print(\"\\n LIVE SITE:\", public_url)\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
