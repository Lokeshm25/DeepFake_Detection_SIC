{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d702bc8d",
   "metadata": {},
   "source": [
    "# 01 - Data Preprocessing (Local)\n",
    "This notebook performs dataset splitting, frame sampling (8 frames/video), and face cropping. It uses helper scripts in src/data/.\n",
    "Be sure to select the conda environment with Torch + CUDA in the kernel.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "381317e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1+cu128 True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__, torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db18ac92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: c:\\Users\\lkmah\\OneDrive\\Desktop\\Lokesh\\VS Code\\DeepFake_Detection_SIC\\notebooks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import json\n",
    "import random\n",
    "import shutil\n",
    "from pprint import pprint\n",
    "\n",
    "PROJECT_ROOT = Path.cwd()  # ensure you open notebook from repo root\n",
    "print(\"Project root:\", PROJECT_ROOT)\n",
    "\n",
    "# Paths (edit if your raw videos live elsewhere)\n",
    "RAW_DATA_DIR = PROJECT_ROOT / \"data_raw\"   # create this and put video subsets inside\n",
    "PREPROC_FRAMES_DIR = PROJECT_ROOT / \"preprocessed\" / \"frames\"\n",
    "PREPROC_FACES_DIR = PROJECT_ROOT / \"preprocessed\" / \"faces\"\n",
    "EMB_DIR = PROJECT_ROOT / \"embeddings\"\n",
    "CKPT_DIR = PROJECT_ROOT / \"checkpoints\"\n",
    "LOG_DIR = PROJECT_ROOT / \"logs\"\n",
    "\n",
    "for p in [PREPROC_FRAMES_DIR, PREPROC_FACES_DIR, EMB_DIR, CKPT_DIR, LOG_DIR]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Example: expected structure under data_raw:\n",
    "# data_raw/dfdc_subset/*.mp4\n",
    "# data_raw/ffpp_c23/*.mp4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08ef4b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found total videos: 0\n",
      "train: 0 val: 0 test_internal: 0 reserved: 0\n",
      "Wrote data_manifest.yaml\n",
      "{'datasets': {'dfdc_subset': {'source': 'C:\\\\Users\\\\lkmah\\\\OneDrive\\\\Desktop\\\\Lokesh\\\\VS '\n",
      "                                        'Code\\\\DeepFake_Detection_SIC\\\\notebooks\\\\data_raw\\\\dfdc_subset',\n",
      "                              'videos': 0},\n",
      "              'ffpp_c23': {'source': 'C:\\\\Users\\\\lkmah\\\\OneDrive\\\\Desktop\\\\Lokesh\\\\VS '\n",
      "                                     'Code\\\\DeepFake_Detection_SIC\\\\notebooks\\\\data_raw\\\\ffpp_c23',\n",
      "                           'videos': 0}},\n",
      " 'splits': {'reserved': 0, 'test_internal': 0, 'train': 0, 'val': 0}}\n"
     ]
    }
   ],
   "source": [
    "# Deterministic split script (similar to your Colab split)\n",
    "import glob, math, hashlib\n",
    "\n",
    "def deterministic_split(video_paths, seed=42, train_frac=0.80, val_frac=0.15, reserve_count=200):\n",
    "    random.seed(seed)\n",
    "    vids = sorted(video_paths)\n",
    "    random.shuffle(vids)\n",
    "    # remove reserved 200 for internal test\n",
    "    if reserve_count > 0:\n",
    "        reserved = vids[-reserve_count:]\n",
    "        vids = vids[:-reserve_count]\n",
    "    else:\n",
    "        reserved = []\n",
    "    n = len(vids)\n",
    "    n_train = int(n * train_frac)\n",
    "    n_val = int(n * val_frac)\n",
    "    train = vids[:n_train]\n",
    "    val = vids[n_train:n_train+n_val]\n",
    "    test_internal = vids[n_train+n_val:]\n",
    "    return train, val, test_internal, reserved\n",
    "\n",
    "# Collect raw videos from data_raw\n",
    "dfdc_videos = list((PROJECT_ROOT / \"data_raw\" / \"dfdc_subset\").glob(\"*.mp4\"))\n",
    "ffpp_videos = list((PROJECT_ROOT / \"data_raw\" / \"ffpp_c23\").glob(\"*.mp4\"))\n",
    "all_videos = dfdc_videos + ffpp_videos\n",
    "print(\"Found total videos:\", len(all_videos))\n",
    "\n",
    "train, val, test_internal, reserved = deterministic_split(all_videos, seed=42, reserve_count=200)\n",
    "print(\"train:\", len(train), \"val:\", len(val), \"test_internal:\", len(test_internal), \"reserved:\", len(reserved))\n",
    "\n",
    "# Save lists\n",
    "(Path(\"data\") ).mkdir(exist_ok=True)\n",
    "def save_list(paths, out_file):\n",
    "    with open(out_file, \"w\") as f:\n",
    "        for p in paths:\n",
    "            f.write(str(p.resolve()) + \"\\n\")\n",
    "\n",
    "save_list(train, \"data/train.txt\")\n",
    "save_list(val, \"data/val.txt\")\n",
    "save_list(test_internal, \"data/test_internal.txt\")\n",
    "save_list(reserved, \"data/reserved_200.txt\")\n",
    "\n",
    "# Update data_manifest.yaml minimally\n",
    "manifest = {\n",
    "    \"datasets\": {\n",
    "        \"dfdc_subset\": {\"source\": str((PROJECT_ROOT / \"data_raw\" / \"dfdc_subset\").resolve()), \"videos\": len(dfdc_videos)},\n",
    "        \"ffpp_c23\": {\"source\": str((PROJECT_ROOT / \"data_raw\" / \"ffpp_c23\").resolve()), \"videos\": len(ffpp_videos)},\n",
    "    },\n",
    "    \"splits\": {\n",
    "        \"train\": len(train),\n",
    "        \"val\": len(val),\n",
    "        \"test_internal\": len(test_internal),\n",
    "        \"reserved\": len(reserved)\n",
    "    }\n",
    "}\n",
    "with open(\"data_manifest.yaml\", \"w\") as f:\n",
    "    yaml.dump(manifest, f)\n",
    "print(\"Wrote data_manifest.yaml\")\n",
    "pprint(manifest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b42ca481",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Missing extract_frames.py in src/data",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m      5\u001b[39m EXTRACT_SCRIPT = PROJECT_ROOT / \u001b[33m\"\u001b[39m\u001b[33msrc\u001b[39m\u001b[33m\"\u001b[39m / \u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m / \u001b[33m\"\u001b[39m\u001b[33mextract_frames.py\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m EXTRACT_SCRIPT.exists(), \u001b[33m\"\u001b[39m\u001b[33mMissing extract_frames.py in src/data\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_extract\u001b[39m(list_file, out_dir, n=\u001b[32m8\u001b[39m):\n\u001b[32m      9\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(list_file) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[31mAssertionError\u001b[39m: Missing extract_frames.py in src/data"
     ]
    }
   ],
   "source": [
    "# Use helper script extract_frames.py for each split. We'll call it programmatically here.\n",
    "from subprocess import run\n",
    "from pathlib import Path\n",
    "\n",
    "EXTRACT_SCRIPT = PROJECT_ROOT / \"src\" / \"data\" / \"extract_frames.py\"\n",
    "assert EXTRACT_SCRIPT.exists(), \"Missing extract_frames.py in src/data\"\n",
    "\n",
    "def run_extract(list_file, out_dir, n=8):\n",
    "    with open(list_file) as f:\n",
    "        vids = [line.strip() for line in f if line.strip()]\n",
    "    print(\"Extracting frames for\", len(vids), \"videos to\", out_dir)\n",
    "    for v in vids:\n",
    "        cmd = [\"python\", str(EXTRACT_SCRIPT), \"--src\", str(Path(v).parent), \"--out\", str(Path(out_dir)/Path(v).stem), \"--n\", str(n), \"--ext\", Path(v).suffix.replace(\".\", \"\")]\n",
    "        # But extract_frames expects folder src; to keep simple call it on each file:\n",
    "        cmd = [\"python\", str(EXTRACT_SCRIPT), \"--src\", str(v), \"--out\", str(Path(out_dir)/Path(v).stem), \"--n\", str(n), \"--ext\", str(v.split(\".\")[-1])]\n",
    "        run(cmd, check=True)\n",
    "\n",
    "# Run for a small subset first to smoke-test\n",
    "run_extract(\"data/train.txt\", PREPROC_FRAMES_DIR / \"train\", n=8)\n",
    "# Optionally run for val/test when smoke-test OK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6d4639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cropping faces from frames using MTCNN\n",
    "CROP_SCRIPT = PROJECT_ROOT / \"src\" / \"data\" / \"face_crop.py\"\n",
    "assert CROP_SCRIPT.exists()\n",
    "# Crop faces for the subset we created in PREPROC_FRAMES_DIR / \"train\"\n",
    "run([\"python\", str(CROP_SCRIPT), \"--frames_root\", str(PREPROC_FRAMES_DIR / \"train\"), \"--out_root\", str(PREPROC_FACES_DIR / \"train\"), \"--size\", \"224\"])\n",
    "# Repeat for val/test when everything ok\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7804aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many faces per video and write small manifest\n",
    "from pathlib import Path\n",
    "faces_root = PREPROC_FACES_DIR / \"train\"\n",
    "video_dirs = [p for p in faces_root.iterdir() if p.is_dir()]\n",
    "summary = {}\n",
    "for v in video_dirs:\n",
    "    count = len(list(v.glob(\"*_face.jpg\")))\n",
    "    summary[v.name] = count\n",
    "print(\"Videos with faces:\", len(video_dirs))\n",
    "# print first 10 entries\n",
    "for k in list(summary.keys())[:10]:\n",
    "    print(k, summary[k])\n",
    "\n",
    "# Save small manifest\n",
    "with open(\"preprocessed/face_manifest_train.txt\",\"w\") as f:\n",
    "    for v in video_dirs:\n",
    "        f.write(f\"{v.name},{len(list(v.glob('*_face.jpg')))}\\n\")\n",
    "print(\"Wrote preprocessed/face_manifest_train.txt\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
