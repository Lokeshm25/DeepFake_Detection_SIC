{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "111ecf41",
   "metadata": {},
   "source": [
    "# 07 - Train Ensemble (Spatial + Temporal)\n",
    "Uses calibrated logistic regression (Platt scaling)\n",
    "\n",
    "Outputs final video-level classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "264d2577",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16a5ab8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Spatial ckpt: c:\\Users\\lkmah\\OneDrive\\Desktop\\Lokesh\\VS Code\\DeepFake_Detection_SIC\\checkpoints\\spatial\\spatial_best_valAUC.pth\n",
      "Temporal ckpt: c:\\Users\\lkmah\\OneDrive\\Desktop\\Lokesh\\VS Code\\DeepFake_Detection_SIC\\checkpoints\\temporal\\temporal_best_valAUC.pth\n"
     ]
    }
   ],
   "source": [
    "# ---------------- CONFIG ----------------\n",
    "ROOT = Path.cwd().parent\n",
    "\n",
    "EMB_ROOT = ROOT / \"embeddings\"                 # embeddings/<split>/<video>.npy\n",
    "LABELS_JSON = ROOT / \"data\" / \"labels.json\"\n",
    "\n",
    "SPATIAL_CKPT = ROOT / \"checkpoints\" / \"spatial\" / \"spatial_best_valAUC.pth\"\n",
    "TEMPORAL_CKPT = ROOT / \"checkpoints\" / \"temporal\" / \"temporal_best_valAUC.pth\"\n",
    "\n",
    "OUT_DIR = ROOT / \"checkpoints\" / \"ensemble\"\n",
    "FEAT_CACHE = ROOT / \"ensemble_features\"\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FEAT_CACHE.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Device:\", DEVICE)\n",
    "print(\"Spatial ckpt:\", SPATIAL_CKPT)\n",
    "print(\"Temporal ckpt:\", TEMPORAL_CKPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46e93667",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(LABELS_JSON, \"r\") as f:\n",
    "    labels_map = json.load(f)\n",
    "\n",
    "def get_label(stem):\n",
    "    if stem in labels_map:\n",
    "        return int(labels_map[stem])\n",
    "    for k, v in labels_map.items():\n",
    "        if stem in k:\n",
    "            return int(v)\n",
    "    raise KeyError(f\"Label not found for {stem}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfa5dd8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spatial head loaded. feat_dim = 1536\n"
     ]
    }
   ],
   "source": [
    "class SpatialHead(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        backbone = timm.create_model(\"efficientnet_b3\", pretrained=False, num_classes=0)\n",
    "        self.feat_dim = backbone.num_features\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(self.feat_dim, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(512, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.head(x).squeeze(1)\n",
    "\n",
    "spatial_head = SpatialHead().to(DEVICE)\n",
    "\n",
    "ck = torch.load(SPATIAL_CKPT, map_location=DEVICE)\n",
    "state = ck.get(\"model_state\", ck)\n",
    "\n",
    "# load only head weights\n",
    "head_state = {k.replace(\"head.\", \"head.\"): v for k, v in state.items() if k.startswith(\"head.\")}\n",
    "spatial_head.load_state_dict(head_state, strict=False)\n",
    "spatial_head.eval()\n",
    "\n",
    "print(\"Spatial head loaded. feat_dim =\", spatial_head.feat_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aff411c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporal model loaded.\n"
     ]
    }
   ],
   "source": [
    "class TemporalModel(nn.Module):\n",
    "    def __init__(self, feat_dim):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            feat_dim, 512, 2,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "            dropout=0.3\n",
    "        )\n",
    "        self.att = nn.Linear(1024, 1)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(1024, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        out, _ = self.lstm(x)\n",
    "        T = out.size(1)\n",
    "        mask = torch.arange(T, device=x.device)[None, :] >= lengths[:, None]\n",
    "        scores = self.att(out).squeeze(-1).masked_fill(mask, -1e9)\n",
    "        w = torch.softmax(scores, dim=1)\n",
    "        pooled = (out * w.unsqueeze(-1)).sum(dim=1)\n",
    "        return self.head(pooled).squeeze(1)\n",
    "\n",
    "# infer feat_dim from embeddings\n",
    "sample = np.load(next((EMB_ROOT / \"train\").glob(\"*.npy\")))\n",
    "FEAT_DIM = sample.shape[1]\n",
    "\n",
    "temporal_model = TemporalModel(FEAT_DIM).to(DEVICE)\n",
    "ck = torch.load(TEMPORAL_CKPT, map_location=DEVICE)\n",
    "temporal_model.load_state_dict(ck[\"model_state\"], strict=False)\n",
    "temporal_model.eval()\n",
    "\n",
    "print(\"Temporal model loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b614cff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spatial_stats_from_embeddings(emb):\n",
    "    emb_t = torch.from_numpy(emb).float().to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        probs = torch.sigmoid(spatial_head(emb_t)).cpu().numpy()\n",
    "\n",
    "    return {\n",
    "        \"mean\": probs.mean(),\n",
    "        \"max\": probs.max(),\n",
    "        \"std\": probs.std(),\n",
    "        \"top3\": np.sort(probs)[-3:].mean() if len(probs) >= 3 else probs.mean()\n",
    "    }\n",
    "\n",
    "def temporal_score_from_embeddings(emb):\n",
    "    x = torch.from_numpy(emb).float().unsqueeze(0).to(DEVICE)\n",
    "    lengths = torch.tensor([emb.shape[0]], device=DEVICE)\n",
    "    with torch.no_grad():\n",
    "        prob = torch.sigmoid(temporal_model(x, lengths)).item()\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc00dd16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building features for train (4066 videos)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4066/4066 [00:06<00:00, 640.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cache: c:\\Users\\lkmah\\OneDrive\\Desktop\\Lokesh\\VS Code\\DeepFake_Detection_SIC\\ensemble_features\\train.npz\n",
      "Building features for val (761 videos)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 761/761 [00:01<00:00, 702.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cache: c:\\Users\\lkmah\\OneDrive\\Desktop\\Lokesh\\VS Code\\DeepFake_Detection_SIC\\ensemble_features\\val.npz\n",
      "Building features for test (255 videos)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 255/255 [00:00<00:00, 671.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cache: c:\\Users\\lkmah\\OneDrive\\Desktop\\Lokesh\\VS Code\\DeepFake_Detection_SIC\\ensemble_features\\test.npz\n",
      "Feature shape: (4066, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def build_features(split, overwrite=False):\n",
    "    cache = FEAT_CACHE / f\"{split}.npz\"\n",
    "    if cache.exists() and not overwrite:\n",
    "        print(f\"Loaded cached features for {split}\")\n",
    "        d = np.load(cache, allow_pickle=True)\n",
    "        return d[\"X\"], d[\"y\"]\n",
    "\n",
    "    X, y = [], []\n",
    "    files = sorted((EMB_ROOT / split).glob(\"*.npy\"))\n",
    "\n",
    "    print(f\"Building features for {split} ({len(files)} videos)\")\n",
    "    for p in tqdm(files):\n",
    "        emb = np.load(p)\n",
    "        if emb.shape[0] == 0:\n",
    "            continue\n",
    "\n",
    "        s = spatial_stats_from_embeddings(emb)\n",
    "        t = temporal_score_from_embeddings(emb)\n",
    "\n",
    "        feat = [\n",
    "            s[\"mean\"], s[\"max\"], s[\"std\"], s[\"top3\"], t\n",
    "        ]\n",
    "\n",
    "        X.append(feat)\n",
    "        y.append(get_label(p.stem))\n",
    "\n",
    "    X = np.array(X, dtype=np.float32)\n",
    "    y = np.array(y, dtype=np.int64)\n",
    "\n",
    "    np.savez(cache, X=X, y=y)\n",
    "    print(\"Saved cache:\", cache)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = build_features(\"train\")\n",
    "X_val, y_val     = build_features(\"val\")\n",
    "X_test, y_test   = build_features(\"test\")\n",
    "\n",
    "print(\"Feature shape:\", X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93085e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble trained.\n"
     ]
    }
   ],
   "source": [
    "base_lr = LogisticRegression(max_iter=1000)\n",
    "ensemble = CalibratedClassifierCV(base_lr, cv=3, method=\"sigmoid\")\n",
    "\n",
    "ensemble.fit(X_train, y_train)\n",
    "print(\"Ensemble trained.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6119298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train AUC: 1.0000\n",
      "Val AUC: 0.9916\n",
      "Test AUC: 0.9900\n"
     ]
    }
   ],
   "source": [
    "def eval_auc(X, y, name):\n",
    "    p = ensemble.predict_proba(X)[:, 1]\n",
    "    auc = roc_auc_score(y, p)\n",
    "    print(f\"{name} AUC: {auc:.4f}\")\n",
    "    return auc\n",
    "\n",
    "train_auc = eval_auc(X_train, y_train, \"Train\")\n",
    "val_auc   = eval_auc(X_val, y_val, \"Val\")\n",
    "test_auc  = eval_auc(X_test, y_test, \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3957d8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ensemble model and report.\n"
     ]
    }
   ],
   "source": [
    "joblib.dump(ensemble, OUT_DIR / \"ensemble_best.pkl\")\n",
    "\n",
    "with open(OUT_DIR / \"ensemble_results.txt\", \"w\") as f:\n",
    "    f.write(f\"Train AUC: {train_auc:.4f}\\n\")\n",
    "    f.write(f\"Val AUC:   {val_auc:.4f}\\n\")\n",
    "    f.write(f\"Test AUC:  {test_auc:.4f}\\n\")\n",
    "\n",
    "print(\"Saved ensemble model and report.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
