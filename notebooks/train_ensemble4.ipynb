{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc2ba6c4",
   "metadata": {},
   "source": [
    "# 07 – Train Ensemble Model (Spatial + Temporal)\n",
    "\n",
    "This notebook trains a **video-level ensemble classifier** that fuses:\n",
    "\n",
    "• Spatial stream (EfficientNet-B3 frame-level predictions / embeddings)  \n",
    "• Temporal stream (LSTM + Attention video-level predictions)\n",
    "\n",
    "The ensemble produces the **final deepfake decision**.\n",
    "\n",
    "✔ Spatial model: already trained  \n",
    "✔ Temporal model: already trained  \n",
    "✔ Frequency stream: skipped (future work)\n",
    "\n",
    "Outputs:\n",
    "- checkpoints/ensemble/ensemble_best_valAUC.pth\n",
    "- Final video-level predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0626b2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbc3aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- USER CONFIG ----------------\n",
    "ROOT = Path.cwd().parent\n",
    "DATA_DIR = ROOT / \"data\"\n",
    "CHECKPOINT_DIR = ROOT / \"checkpoints\" / \"ensemble\"\n",
    "\n",
    "SPATIAL_PRED_DIR = ROOT / \"predictions\" / \"spatial\"     # video-level spatial preds\n",
    "TEMPORAL_PRED_DIR = ROOT / \"predictions\" / \"temporal\"   # video-level temporal preds\n",
    "\n",
    "LABELS_JSON = DATA_DIR / \"labels.json\"\n",
    "\n",
    "NUM_EPOCHS = 15\n",
    "BATCH_SIZE = 64\n",
    "LR = 1e-4\n",
    "WEIGHT_DECAY = 1e-4\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "SEED = 42\n",
    "# ---------------------------------------------\n",
    "\n",
    "CHECKPOINT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(\"Device:\", DEVICE)\n",
    "print(\"Checkpoint dir:\", CHECKPOINT_DIR)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037bcaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=SEED):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(SEED)\n",
    "\n",
    "with open(LABELS_JSON, \"r\") as f:\n",
    "    labels_map = json.load(f)\n",
    "\n",
    "def get_label(stem):\n",
    "    if stem in labels_map:\n",
    "        return int(labels_map[stem])\n",
    "    for k, v in labels_map.items():\n",
    "        if stem in k:\n",
    "            return int(v)\n",
    "    raise KeyError(f\"Label not found for {stem}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1f91c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsembleDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Loads:\n",
    "    - spatial prediction (sigmoid score)\n",
    "    - temporal prediction (sigmoid score)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, split):\n",
    "        self.spatial_dir = SPATIAL_PRED_DIR / split\n",
    "        self.temporal_dir = TEMPORAL_PRED_DIR / split\n",
    "\n",
    "        self.items = sorted(\n",
    "            set(p.stem for p in self.spatial_dir.glob(\"*.npy\"))\n",
    "            & set(p.stem for p in self.temporal_dir.glob(\"*.npy\"))\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        stem = self.items[idx]\n",
    "\n",
    "        spatial_score = np.load(self.spatial_dir / f\"{stem}.npy\").item()\n",
    "        temporal_score = np.load(self.temporal_dir / f\"{stem}.npy\").item()\n",
    "\n",
    "        x = torch.tensor([spatial_score, temporal_score], dtype=torch.float32)\n",
    "        y = torch.tensor(get_label(stem), dtype=torch.float32)\n",
    "\n",
    "        return x, y, stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1c8187",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = EnsembleDataset(\"train\")\n",
    "val_ds   = EnsembleDataset(\"val\")\n",
    "test_ds  = EnsembleDataset(\"test\")\n",
    "\n",
    "print(\"Train videos:\", len(train_ds))\n",
    "print(\"Val videos:\", len(val_ds))\n",
    "print(\"Test videos:\", len(test_ds))\n",
    "\n",
    "x, y, s = train_ds[0]\n",
    "print(\"Sample features:\", x, \"Label:\", y, \"Stem:\", s)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds, batch_size=BATCH_SIZE, shuffle=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_ds, batch_size=BATCH_SIZE, shuffle=False\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_ds, batch_size=BATCH_SIZE, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf376607",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsembleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(2, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x).squeeze(1)\n",
    "    \n",
    "\n",
    "model = EnsembleModel().to(DEVICE)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a53fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(\n",
    "    model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY\n",
    ")\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=\"max\", factor=0.5, patience=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df21b4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_auc = 0.0\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    t0 = time.time()\n",
    "    model.train()\n",
    "\n",
    "    all_preds, all_labels = [], []\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for x, y, _ in tqdm(train_loader, desc=f\"Epoch {epoch}\"):\n",
    "        x = x.to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * x.size(0)\n",
    "        all_preds.append(torch.sigmoid(logits).detach().cpu())\n",
    "        all_labels.append(y.cpu())\n",
    "\n",
    "    all_preds = torch.cat(all_preds).numpy()\n",
    "    all_labels = torch.cat(all_labels).numpy()\n",
    "\n",
    "    train_auc = roc_auc_score(all_labels, all_preds)\n",
    "    train_loss = running_loss / len(train_ds)\n",
    "\n",
    "    model.eval()\n",
    "    val_preds, val_labels = [], []\n",
    "    val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y, _ in val_loader:\n",
    "            x = x.to(DEVICE)\n",
    "            y = y.to(DEVICE)\n",
    "\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "\n",
    "            val_loss += loss.item() * x.size(0)\n",
    "            val_preds.append(torch.sigmoid(logits).cpu())\n",
    "            val_labels.append(y.cpu())\n",
    "\n",
    "    val_preds = torch.cat(val_preds).numpy()\n",
    "    val_labels = torch.cat(val_labels).numpy()\n",
    "\n",
    "    val_auc = roc_auc_score(val_labels, val_preds)\n",
    "    val_loss /= len(val_ds)\n",
    "\n",
    "    scheduler.step(val_auc)\n",
    "\n",
    "    if val_auc > best_val_auc:\n",
    "        best_val_auc = val_auc\n",
    "        torch.save(\n",
    "            {\"model_state\": model.state_dict(), \"val_auc\": val_auc},\n",
    "            CHECKPOINT_DIR / \"ensemble_best_valAUC.pth\"\n",
    "        )\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch} | \"\n",
    "        f\"train_loss={train_loss:.4f} train_auc={train_auc:.4f} | \"\n",
    "        f\"val_loss={val_loss:.4f} val_auc={val_auc:.4f} | \"\n",
    "        f\"time={time.time()-t0:.1f}s\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21830ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ck = torch.load(CHECKPOINT_DIR / \"ensemble_best_valAUC.pth\", map_location=DEVICE)\n",
    "model.load_state_dict(ck[\"model_state\"])\n",
    "model.eval()\n",
    "\n",
    "test_preds, test_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y, _ in test_loader:\n",
    "        x = x.to(DEVICE)\n",
    "        logits = model(x)\n",
    "        test_preds.append(torch.sigmoid(logits).cpu())\n",
    "        test_labels.append(y)\n",
    "\n",
    "test_preds = torch.cat(test_preds).numpy()\n",
    "test_labels = torch.cat(test_labels).numpy()\n",
    "\n",
    "print(\"Ensemble Test AUC:\", roc_auc_score(test_labels, test_preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
