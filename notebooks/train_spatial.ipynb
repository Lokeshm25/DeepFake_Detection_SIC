{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b98ca418",
   "metadata": {},
   "source": [
    "# 04 - Train spatial EfficientNet-B3 (frame-level classifier)\n",
    "Trains EfficientNet-B3 on frame images (face-cropped). Saves per-epoch checkpoints and best model (best val AUC).\n",
    "- Uses mixed precision (autocast + GradScaler)\n",
    "- Resumable from checkpoint\n",
    "- Deterministic-ish with seed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e61fb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config & imports\n",
    "import os\n",
    "from pathlib import Path\n",
    "import random\n",
    "import json\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "import timm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# ---------------- USER CONFIG (edit if you want) ----------------\n",
    "ROOT = Path.cwd().parent\n",
    "FRAMES_ROOT = ROOT / \"preprocessed\" / \"frames\"   # expects <split>/<video_stem>/frame_*.jpg\n",
    "LABELS_JSON = ROOT / \"data\" / \"labels.json\"\n",
    "CHECKPOINT_DIR = ROOT / \"checkpoints\" / \"spatial\"\n",
    "LOG_DIR = ROOT / \"logs\"\n",
    "NUM_EPOCHS = 12\n",
    "BATCH_SIZE = 32\n",
    "LR = 1e-4               # starting learning rate\n",
    "WEIGHT_DECAY = 1e-4\n",
    "NUM_WORKERS = 4\n",
    "IMG_SIZE = 224\n",
    "SEED = 42\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "PRINT_FREQ = 50\n",
    "# ----------------------------------------------------------------\n",
    "\n",
    "for p in [CHECKPOINT_DIR, LOG_DIR]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Device:\", DEVICE)\n",
    "print(\"Frames root:\", FRAMES_ROOT)\n",
    "print(\"Labels file:\", LABELS_JSON)\n",
    "print(\"Checkpoint dir:\", CHECKPOINT_DIR)\n",
    "print(f\"Epochs={NUM_EPOCHS} batch_size={BATCH_SIZE} lr={LR} wd={WEIGHT_DECAY}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27738d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility (best-effort)\n",
    "def set_seed(seed=SEED):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(SEED)\n",
    "\n",
    "# Load labels.json (mapping video_stem -> 0/1)\n",
    "with open(LABELS_JSON, \"r\") as f:\n",
    "    labels_map = json.load(f)\n",
    "\n",
    "# helper to get label from a video folder stem robustly\n",
    "def get_label_by_stem(stem):\n",
    "    # direct lookup\n",
    "    if stem in labels_map:\n",
    "        return int(labels_map[stem])\n",
    "    # fallback: if labels keys have suffixes like 'stem__dfdc' try startswith\n",
    "    candidates = [v for k,v in labels_map.items() if k.startswith(stem)]\n",
    "    if len(candidates) == 1:\n",
    "        return int(candidates[0])\n",
    "    # last fallback: try any key where stem contained\n",
    "    for k,v in labels_map.items():\n",
    "        if stem in k:\n",
    "            return int(v)\n",
    "    # if not found, raise to catch dataset issues\n",
    "    raise KeyError(f\"Label for stem '{stem}' not found in labels.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3779a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "class FrameDataset(Dataset):\n",
    "    \"\"\"\n",
    "    frames_root/<split>/<video_stem>/frame_00.jpg ...\n",
    "    Each frame is a training sample; label = labels_map[video_stem]\n",
    "    \"\"\"\n",
    "    def __init__(self, split, transform=None):\n",
    "        self.root = FRAMES_ROOT / split\n",
    "        self.transform = transform\n",
    "        # build list of (image_path, label)\n",
    "        items = []\n",
    "        if not self.root.exists():\n",
    "            raise RuntimeError(f\"Frames directory not found: {self.root}\")\n",
    "        # iterate video folders\n",
    "        for video_folder in sorted(self.root.iterdir()):\n",
    "            if not video_folder.is_dir():\n",
    "                continue\n",
    "            stem = video_folder.name\n",
    "            try:\n",
    "                label = get_label_by_stem(stem)\n",
    "            except KeyError:\n",
    "                # skip if not found (shouldn't happen if labels.json correct)\n",
    "                continue\n",
    "            # collect frame images inside folder\n",
    "            frames = sorted(list(video_folder.glob(\"frame_*.jpg\")))\n",
    "            for f in frames:\n",
    "                items.append((str(f), int(label), stem))\n",
    "        self.items = items\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        p, label, stem = self.items[idx]\n",
    "        img = Image.open(p).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, torch.tensor(label, dtype=torch.float32), stem\n",
    "\n",
    "# transforms (train & val)\n",
    "train_tfms = T.Compose([\n",
    "    T.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "    T.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.05, hue=0.02),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
    "])\n",
    "\n",
    "val_tfms = T.Compose([\n",
    "    T.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
    "])\n",
    "\n",
    "# quick debug: create datasets (but don't load full data here)\n",
    "# ds_train = FrameDataset(\"train\", transform=train_tfms)\n",
    "# print(\"Train samples:\", len(ds_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1cfebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatialModel(nn.Module):\n",
    "    def __init__(self, backbone_name=\"efficientnet_b3\", pretrained=True, head_hidden=512, dropout=0.4):\n",
    "        super().__init__()\n",
    "        # timm model with num_classes=0 returns feature vector\n",
    "        self.backbone = timm.create_model(backbone_name, pretrained=pretrained, num_classes=0)\n",
    "        feat_dim = self.backbone.num_features\n",
    "        print(\"Backbone feature dimension:\", feat_dim)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(feat_dim, head_hidden),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(head_hidden, 1)  # logits\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        feats = self.backbone(x)   # [B, feat_dim]\n",
    "        logits = self.head(feats).squeeze(1)\n",
    "        return logits\n",
    "\n",
    "# instantiate\n",
    "model = SpatialModel(pretrained=True).to(DEVICE)\n",
    "print(\"Model created. Backbone feat dim:\", model.backbone.num_features)\n",
    "\n",
    "# optimizer, scheduler, loss\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2)\n",
    "\n",
    "# Compute class imbalance weight (optional but recommended)\n",
    "pos_count = sum(v for v in labels_map.values())\n",
    "neg_count = len(labels_map) - pos_count\n",
    "pos_weight = torch.tensor([neg_count / max(pos_count, 1)], device=DEVICE)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "#device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "scaler = GradScaler()\n",
    "print(f\"Pos samples: {pos_count}, Neg samples: {neg_count}, Pos weight: {pos_weight.item():.4f}\")\n",
    "print(\"Scaler: \", scaler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1159547",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def save_checkpoint(state, fname):\n",
    "    # copy model weights to CPU to reduce CUDA memory pressure and make file portable\n",
    "    cpu_state = state.copy()\n",
    "    cpu_state[\"model_state\"] = {k: v.cpu() for k, v in state[\"model_state\"].items()}\n",
    "    # optimizer state may contain tensors â€” move them to CPU as well (if present)\n",
    "    if \"optimizer_state\" in state and state[\"optimizer_state\"] is not None:\n",
    "        opt_state = state[\"optimizer_state\"]\n",
    "        # shallow copy\n",
    "        cpu_opt_state = {}\n",
    "        cpu_opt_state['state'] = {}\n",
    "        cpu_opt_state['param_groups'] = opt_state.get('param_groups', [])\n",
    "        for k, v in opt_state.get('state', {}).items():\n",
    "            cpu_opt_state['state'][k] = {sk: sv.cpu() if isinstance(sv, torch.Tensor) else sv\n",
    "                                         for sk, sv in v.items()}\n",
    "        cpu_state[\"optimizer_state\"] = cpu_opt_state\n",
    "    torch.save(cpu_state, fname)\n",
    "\n",
    "def compute_auc(y_true, y_scores):\n",
    "    try:\n",
    "        return roc_auc_score(y_true, y_scores)\n",
    "    except Exception:\n",
    "        return float('nan')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f78d0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# DataLoaders\n",
    "train_ds = FrameDataset(\"train\", transform=train_tfms)\n",
    "val_ds = FrameDataset(\"val\", transform=val_tfms)\n",
    "\n",
    "pin_memory = torch.cuda.is_available()\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=pin_memory, persistent_workers=(NUM_WORKERS > 0))\n",
    "val_loader   = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=pin_memory, persistent_workers=(NUM_WORKERS > 0))\n",
    "\n",
    "print(\"Done\")\n",
    "\n",
    "# =======================\n",
    "# Diagnostic A\n",
    "# =======================\n",
    "\n",
    "print(\"Testing single batch with num_workers=0...\")\n",
    "\n",
    "debug_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,      # IMPORTANT\n",
    "    pin_memory=False\n",
    ")\n",
    "\n",
    "try:\n",
    "    batch = next(iter(debug_loader))\n",
    "    imgs, labels, stems = batch\n",
    "    print(\"Batch loaded successfully!\")\n",
    "    print(\"Image shape:\", imgs.shape)\n",
    "    print(\"Labels shape:\", labels.shape)\n",
    "except Exception as e:\n",
    "    print(\"Error while loading batch:\", e)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60faacd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoaders\n",
    "train_ds = FrameDataset(\"train\", transform=train_tfms)\n",
    "val_ds = FrameDataset(\"val\", transform=val_tfms)\n",
    "\n",
    "pin_memory = torch.cuda.is_available()\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=0,      # IMPORTANT: set to 0 to avoid multiprocessing issues\n",
    "    pin_memory=pin_memory,\n",
    "    persistent_workers=False    # IMPORTANT: disable\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,      # IMPORTANT: set to 0 to avoid multiprocessing issues\n",
    "    pin_memory=pin_memory,\n",
    "    persistent_workers=False\n",
    ")\n",
    "\n",
    "best_val_auc = 0.0\n",
    "start_epoch = 0\n",
    "\n",
    "# Resume logic: load last checkpoint if exists (optional)\n",
    "last_ckpt = CHECKPOINT_DIR / \"spatial_last.pth\"\n",
    "if last_ckpt.exists():\n",
    "    print(\"Found last checkpoint, resuming:\", last_ckpt)\n",
    "    ck = torch.load(last_ckpt, map_location=DEVICE)\n",
    "    model.load_state_dict(ck[\"model_state\"])\n",
    "    optimizer.load_state_dict(ck[\"optimizer_state\"])\n",
    "    # ensure optimizer state tensors are on the current device\n",
    "    if torch.cuda.is_available():\n",
    "        for state in optimizer.state.values():\n",
    "            for k, v in list(state.items()):\n",
    "                if isinstance(v, torch.Tensor):\n",
    "                    state[k] = v.to(DEVICE)\n",
    "    start_epoch = ck.get(\"epoch\", 0) + 1\n",
    "    best_val_auc = ck.get(\"best_val_auc\", 0.0)\n",
    "    print(\"Resumed from epoch\", start_epoch, \"best_val_auc\", best_val_auc)\n",
    "\n",
    "# training loop\n",
    "for epoch in range(start_epoch, NUM_EPOCHS):\n",
    "    t0 = time.time()\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch}\", unit=\"batch\", disable=False)\n",
    "    for i, (imgs, labels, _) in enumerate(pbar):\n",
    "        imgs = imgs.to(DEVICE, non_blocking=True)\n",
    "        labels = labels.to(DEVICE, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with autocast(enabled=(DEVICE.type==\"cuda\")):\n",
    "            logits = model(imgs)\n",
    "            loss = criterion(logits, labels)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        running_loss += loss.item() * imgs.size(0)\n",
    "        preds = torch.sigmoid(logits).detach()\n",
    "        all_preds.append(preds)\n",
    "        all_labels.append(labels.detach())\n",
    "\n",
    "        if (i+1) % PRINT_FREQ == 0:\n",
    "            pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "\n",
    "    if len(all_preds) > 0:\n",
    "        all_preds = torch.cat(all_preds).cpu().numpy()\n",
    "        all_labels = torch.cat(all_labels).cpu().numpy()\n",
    "    else:\n",
    "        all_preds = np.array([])\n",
    "        all_labels = np.array([])\n",
    "    \n",
    "    train_loss = running_loss / len(train_ds)\n",
    "    train_auc = compute_auc(all_labels, all_preds)\n",
    "\n",
    "    # validation\n",
    "    model.eval()\n",
    "    val_preds = []\n",
    "    val_labels = []\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        vbar = tqdm(val_loader, desc=f\"Val {epoch}\", unit=\"batch\", disable=False)\n",
    "        for imgs, labels, _ in vbar:\n",
    "            imgs = imgs.to(DEVICE, non_blocking=True)\n",
    "            labels = labels.to(DEVICE, non_blocking=True)\n",
    "            with autocast(enabled=(DEVICE.type==\"cuda\")):\n",
    "                logits = model(imgs)\n",
    "                loss = criterion(logits, labels)\n",
    "            val_loss += loss.item() * imgs.size(0)\n",
    "            val_preds.append(torch.sigmoid(logits).detach())\n",
    "            val_labels.append(labels.detach())\n",
    "            vbar.set_postfix({'val_loss': f'{loss.item():.4f}'})\n",
    "\n",
    "    if len(val_preds) > 0:\n",
    "        val_preds = torch.cat(val_preds).cpu().numpy()\n",
    "        val_labels = torch.cat(val_labels).cpu().numpy()\n",
    "    else:\n",
    "        val_preds = np.array([])\n",
    "        val_labels = np.array([])\n",
    "\n",
    "    val_loss = val_loss / len(val_ds)\n",
    "    val_auc = compute_auc(val_labels, val_preds)\n",
    "\n",
    "    # scheduler step (ReduceLROnPlateau)\n",
    "    scheduler.step(val_auc)\n",
    "\n",
    "    # save checkpoints\n",
    "    ckpt = {\n",
    "        \"epoch\": epoch,\n",
    "        \"model_state\": model.state_dict(),\n",
    "        \"optimizer_state\": optimizer.state_dict(),\n",
    "        \"best_val_auc\": best_val_auc,\n",
    "        \"val_auc\": val_auc\n",
    "    }\n",
    "    last_path = CHECKPOINT_DIR / \"spatial_last.pth\"\n",
    "    save_checkpoint(ckpt, last_path)\n",
    "\n",
    "    if val_auc > best_val_auc:\n",
    "        best_val_auc = val_auc\n",
    "        best_path = CHECKPOINT_DIR / \"spatial_best_valAUC.pth\"\n",
    "        save_checkpoint(ckpt, best_path)\n",
    "        print(f\"Saved new best model at epoch {epoch} val_auc={val_auc:.4f}\")\n",
    "\n",
    "    # also save epoch checkpoint (optional)\n",
    "    epoch_path = CHECKPOINT_DIR / f\"spatial_epoch_{epoch}.pth\"\n",
    "    save_checkpoint(ckpt, epoch_path)\n",
    "\n",
    "    print(f\"Epoch {epoch} done. train_loss={train_loss:.4f} train_auc={train_auc:.4f} val_loss={val_loss:.4f} val_auc={val_auc:.4f} time={(time.time()-t0):.1f}s\")\n",
    "    # flush logs if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3e97e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick test evaluation if you want (uses trained best model)\n",
    "best_model_path = CHECKPOINT_DIR / \"spatial_best_valAUC.pth\"\n",
    "if best_model_path.exists():\n",
    "    ck = torch.load(best_model_path, map_location=DEVICE)\n",
    "    model.load_state_dict(ck[\"model_state\"])\n",
    "    print(\"Loaded best model with stored best_val_auc:\", ck.get(\"best_val_auc\"))\n",
    "    # compute metrics on test split (frame-level)\n",
    "    test_ds = FrameDataset(\"test\", transform=val_tfms)\n",
    "    # use same pin_memory logic as training/validation\n",
    "    test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                             num_workers=NUM_WORKERS, pin_memory=pin_memory,\n",
    "                             persistent_workers=(NUM_WORKERS > 0))\n",
    "    model.eval()\n",
    "    test_preds = []\n",
    "    test_labels = []\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels, _ in test_loader:\n",
    "            imgs = imgs.to(DEVICE, non_blocking=True)\n",
    "            labels = labels.to(DEVICE, non_blocking=True)\n",
    "            with autocast(enabled=(DEVICE.type == \"cuda\")):\n",
    "                logits = model(imgs)\n",
    "            test_preds.append(torch.sigmoid(logits).detach())\n",
    "            test_labels.append(labels.detach())\n",
    "    # aggregate once\n",
    "    test_preds = torch.cat(test_preds).cpu().numpy()\n",
    "    test_labels = torch.cat(test_labels).cpu().numpy()\n",
    "    test_auc = roc_auc_score(test_labels, test_preds)\n",
    "    print(\"Test frame-level AUC:\", test_auc)\n",
    "else:\n",
    "    print(\"No best checkpoint found yet at\", best_model_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
