{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88c466e4",
   "metadata": {},
   "source": [
    "# 06 - Train temporal model (LSTM + attention) on embeddings\n",
    "Trains a video-level LSTM aggregator using per-frame embeddings produced by the spatial model.\n",
    "Saves checkpoints: checkpoints/temporal/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24b6e9c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Emb root: c:\\Users\\lkmah\\OneDrive\\Desktop\\Lokesh\\VS Code\\DeepFake_Detection_SIC\\embeddings\n",
      "Checkpoint dir: c:\\Users\\lkmah\\OneDrive\\Desktop\\Lokesh\\VS Code\\DeepFake_Detection_SIC\\checkpoints\\temporal\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json, time\n",
    "import random\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "#from torch.cuda.amp import autocast, GradScaler\n",
    "# AMP disabled for temporal model (FP32 is more stable)\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# ------------- USER CONFIG -------------\n",
    "ROOT = Path.cwd().parent\n",
    "EMB_ROOT = ROOT / \"embeddings\"             # embeddings/<split>/<video_stem>.npy\n",
    "LABELS_JSON = ROOT / \"data\" / \"labels.json\"\n",
    "CHECKPOINT_DIR = ROOT / \"checkpoints\" / \"temporal\"\n",
    "NUM_EPOCHS = 25\n",
    "BATCH_SIZE = 16            # number of videos per batch\n",
    "LR = 1e-4\n",
    "WEIGHT_DECAY = 1e-4\n",
    "NUM_WORKERS = 0            # keep 0 in notebooks; increase on robust machines\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "PRINT_FREQ = 20\n",
    "LSTM_HIDDEN = 512\n",
    "LSTM_LAYERS = 2\n",
    "DROPOUT = 0.3\n",
    "ATTENTION = True           # use attention pooling over LSTM outputs\n",
    "BIDIRECTIONAL = True\n",
    "# ---------------------------------------\n",
    "\n",
    "BAD_EMB_LOG = CHECKPOINT_DIR / \"bad_embeddings.txt\"\n",
    "if BAD_EMB_LOG.exists():\n",
    "    BAD_EMB_LOG.unlink()\n",
    "\n",
    "CHECKPOINT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(\"Device:\", DEVICE)\n",
    "print(\"Emb root:\", EMB_ROOT)\n",
    "print(\"Checkpoint dir:\", CHECKPOINT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31c2caed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available(): torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "with open(LABELS_JSON, \"r\") as f:\n",
    "    labels_map = json.load(f)\n",
    "\n",
    "def get_label_from_stem(stem):\n",
    "    if stem in labels_map:\n",
    "        return int(labels_map[stem])\n",
    "    for k,v in labels_map.items():\n",
    "        if stem in k:\n",
    "            return int(v)\n",
    "    raise KeyError(f\"Label for {stem} not found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "659e02d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoEmbeddingDataset(Dataset):\n",
    "    def __init__(self, split):\n",
    "        self.root = EMB_ROOT / split\n",
    "        if not self.root.exists():\n",
    "            raise RuntimeError(f\"No embeddings for split: {split}\")\n",
    "        self.items = sorted([p for p in self.root.glob(\"*.npy\")])\n",
    "        # optional: filter if empty\n",
    "        self.items = [p for p in self.items if np.load(p).shape[0] > 0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        p = self.items[idx]\n",
    "        stem = p.stem\n",
    "\n",
    "        try:\n",
    "            arr = np.load(p)\n",
    "        except Exception as e:\n",
    "            with open(BAD_EMB_LOG, \"a\") as f:\n",
    "                f.write(f\"[LOAD ERROR] {p} | {e}\\n\")\n",
    "            raise\n",
    "\n",
    "        if arr.ndim != 2 or arr.shape[0] == 0:\n",
    "            with open(BAD_EMB_LOG, \"a\") as f:\n",
    "                f.write(f\"[EMPTY] {p} | shape={arr.shape}\\n\")\n",
    "            raise ValueError(f\"Empty embedding: {p}\")\n",
    "\n",
    "        if np.isnan(arr).any() or np.isinf(arr).any():\n",
    "            with open(BAD_EMB_LOG, \"a\") as f:\n",
    "                f.write(\n",
    "                    f\"[NaN/Inf] {p} | \"\n",
    "                    f\"shape={arr.shape} \"\n",
    "                    f\"min={np.nanmin(arr)} \"\n",
    "                    f\"max={np.nanmax(arr)} \"\n",
    "                    f\"mean={np.nanmean(arr)}\\n\"\n",
    "                )\n",
    "            raise ValueError(f\"NaN/Inf in embedding: {p}\")\n",
    "\n",
    "        emb = torch.from_numpy(arr.astype(np.float32))\n",
    "        label = get_label_from_stem(stem)\n",
    "        return emb, torch.tensor(label, dtype=torch.float32), stem\n",
    "\n",
    "# quick sanity\n",
    "# ds = VideoEmbeddingDataset(\"train\")\n",
    "# print(\"Train videos:\", len(ds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b1f7007",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    batch: list of (emb [T,feat], label, stem)\n",
    "    Pads sequences to longest T in batch (simple zero padding).\n",
    "    Returns tensors: seqs [B, Tmax, feat], lengths [B], labels [B]\n",
    "    \"\"\"\n",
    "    seqs, labels, stems = zip(*batch)\n",
    "    lengths = [s.shape[0] for s in seqs]\n",
    "    maxlen = max(lengths)\n",
    "    feat_dim = seqs[0].shape[1]\n",
    "    out = torch.zeros(len(seqs), maxlen, feat_dim, dtype=torch.float32)\n",
    "    for i, s in enumerate(seqs):\n",
    "        out[i, :s.shape[0], :] = s\n",
    "    labels = torch.stack(labels)\n",
    "    return out, torch.tensor(lengths, dtype=torch.long), labels, list(stems)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a690bb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionPool(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.att = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, h, lengths):\n",
    "        B, T, _ = h.shape\n",
    "\n",
    "        # never allow zero length\n",
    "        lengths = torch.clamp(lengths, min=1)\n",
    "\n",
    "        scores = self.att(h).squeeze(-1)  # [B, T]\n",
    "\n",
    "        mask = torch.arange(T, device=h.device).unsqueeze(0) >= lengths.unsqueeze(1)\n",
    "        scores = scores.masked_fill(mask, -1e9)\n",
    "\n",
    "        weights = torch.softmax(scores, dim=1)\n",
    "\n",
    "        # ABSOLUTE safety net\n",
    "        weights = torch.nan_to_num(weights, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "        out = (h * weights.unsqueeze(-1)).sum(dim=1)\n",
    "        return out, weights\n",
    "\n",
    "class TemporalModel(nn.Module):\n",
    "    def __init__(self, feat_dim):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            feat_dim, LSTM_HIDDEN, LSTM_LAYERS,\n",
    "            batch_first=True,\n",
    "            bidirectional=BIDIRECTIONAL,\n",
    "            dropout=DROPOUT if LSTM_LAYERS > 1 else 0\n",
    "        )\n",
    "        out_dim = LSTM_HIDDEN * (2 if BIDIRECTIONAL else 1)\n",
    "        self.attn = AttentionPool(out_dim)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(out_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        # x: [B, T, feat], lengths: [B] (LongTensor)\n",
    "        # Handle case all lengths equal -> no need to pack (but pack still works).\n",
    "        if lengths.numel() == 0:\n",
    "            raise ValueError(\"Empty lengths tensor in TemporalModel.forward\")\n",
    "\n",
    "        # sort by lengths (descending)\n",
    "        lengths_sorted, perm_idx = lengths.sort(descending=True)\n",
    "        x_sorted = x[perm_idx]\n",
    "\n",
    "        # pack (pack expects CPU lengths)\n",
    "        packed = rnn_utils.pack_padded_sequence(x_sorted, lengths_sorted.cpu(), batch_first=True, enforce_sorted=True)\n",
    "        packed_out, _ = self.lstm(packed)\n",
    "        out_unpacked, _ = rnn_utils.pad_packed_sequence(packed_out, batch_first=True)  # [B_sorted, Tmax_sorted, H_out]\n",
    "\n",
    "        # unsort back to original order\n",
    "        _, unperm_idx = perm_idx.sort()\n",
    "        out = out_unpacked[unperm_idx]\n",
    "        lengths = lengths[unperm_idx]\n",
    "\n",
    "        pooled, att_weights = self.attn(out, lengths)\n",
    "        logits = self.head(pooled).squeeze(1)\n",
    "\n",
    "        # restore att_weights to original order too\n",
    "        if att_weights is not None:\n",
    "            att_weights = att_weights[unperm_idx]\n",
    "\n",
    "        return logits, att_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62959e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_auc(y_true, y_pred):\n",
    "    if np.isnan(y_pred).any():\n",
    "        print(\"⚠ NaNs detected in predictions — skipping AUC\")\n",
    "        return float(\"nan\")\n",
    "    try:\n",
    "        return roc_auc_score(y_true, y_pred)\n",
    "    except Exception as e:\n",
    "        print(\"AUC error:\", e)\n",
    "        return float(\"nan\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a30cb368",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, fname):\n",
    "    # copy model weights to CPU to reduce CUDA memory pressure and make file portable\n",
    "    cpu_state = state.copy()\n",
    "    cpu_state[\"model_state\"] = {k: v.cpu() for k, v in state[\"model_state\"].items()}\n",
    "    # optimizer state may contain tensors — move them to CPU as well (if present)\n",
    "    if \"optimizer_state\" in state and state[\"optimizer_state\"] is not None:\n",
    "        opt_state = state[\"optimizer_state\"]\n",
    "        # shallow copy\n",
    "        cpu_opt_state = {}\n",
    "        cpu_opt_state['state'] = {}\n",
    "        cpu_opt_state['param_groups'] = opt_state.get('param_groups', [])\n",
    "        for k, v in opt_state.get('state', {}).items():\n",
    "            cpu_opt_state['state'][k] = {sk: sv.cpu() if isinstance(sv, torch.Tensor) else sv\n",
    "                                         for sk, sv in v.items()}\n",
    "        cpu_state[\"optimizer_state\"] = cpu_opt_state\n",
    "    torch.save(cpu_state, fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9efd0bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feat dim: 1536 Train videos: 4066\n",
      "TemporalModel(\n",
      "  (lstm): LSTM(1536, 512, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)\n",
      "  (attn): AttentionPool(\n",
      "    (att): Linear(in_features=1024, out_features=1, bias=True)\n",
      "  )\n",
      "  (head): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=256, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Build one dataset to read feat_dim\n",
    "train_ds = VideoEmbeddingDataset(\"train\")\n",
    "val_ds = VideoEmbeddingDataset(\"val\")\n",
    "# sanity check \n",
    "if len(train_ds) == 0:\n",
    "    raise RuntimeError(\"No train embeddings found. Run extract_embeddings first.\")\n",
    "\n",
    "sample_emb = np.load(train_ds.items[0])\n",
    "FEAT_DIM = int(sample_emb.shape[1])\n",
    "print(\"Feat dim:\", FEAT_DIM, \"Train videos:\", len(train_ds))\n",
    "\n",
    "pin_memory = torch.cuda.is_available()\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS,\n",
    "                        collate_fn=collate_fn, pin_memory=pin_memory, persistent_workers=(NUM_WORKERS > 0))\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS,\n",
    "                        collate_fn=collate_fn, pin_memory=pin_memory, persistent_workers=(NUM_WORKERS > 0))\n",
    "\n",
    "model = TemporalModel(feat_dim=FEAT_DIM).to(DEVICE)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"max\", factor=0.5, patience=2)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f1bc69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick sanity test\n",
    "# import torch\n",
    "# feat_dim = FEAT_DIM  # from earlier\n",
    "# model_test = TemporalModel(feat_dim=feat_dim).to(DEVICE)\n",
    "# B, T = 4, 8\n",
    "# dummy = torch.randn(B, T, feat_dim).to(DEVICE)\n",
    "# lengths = torch.tensor([8,6,5,7], dtype=torch.long).to(DEVICE)\n",
    "# with torch.no_grad():\n",
    "#     logits, att = model_test(dummy, lengths)\n",
    "# print(\"logits.shape:\", logits.shape, \"att shape:\", None if att is None else att.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cb28dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 255/255 [00:03<00:00, 80.66batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in preds: False\n",
      "NaNs in labels: False\n",
      "Pred min/max: 1.6622769e-06 0.999997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:00<00:00, 230.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved new best model at epoch 0 val_auc=0.9944\n",
      "Epoch 0 done. train_loss=0.0369 train_auc=0.9999 val_loss=0.1647 val_auc=0.9944 time=3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 255/255 [00:02<00:00, 88.70batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in preds: False\n",
      "NaNs in labels: False\n",
      "Pred min/max: 6.219851e-07 0.9999994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:00<00:00, 227.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved new best model at epoch 1 val_auc=0.9945\n",
      "Epoch 1 done. train_loss=0.0029 train_auc=1.0000 val_loss=0.1918 val_auc=0.9945 time=3.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 255/255 [00:02<00:00, 86.04batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in preds: False\n",
      "NaNs in labels: False\n",
      "Pred min/max: 3.5436005e-07 0.99999976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:00<00:00, 226.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 done. train_loss=0.0036 train_auc=1.0000 val_loss=0.1762 val_auc=0.9943 time=3.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 255/255 [00:02<00:00, 88.28batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in preds: False\n",
      "NaNs in labels: False\n",
      "Pred min/max: 9.946188e-08 0.9999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:00<00:00, 238.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 done. train_loss=0.0012 train_auc=1.0000 val_loss=0.2556 val_auc=0.9942 time=3.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 255/255 [00:02<00:00, 87.50batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in preds: False\n",
      "NaNs in labels: False\n",
      "Pred min/max: 7.178688e-08 0.9999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:00<00:00, 223.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 done. train_loss=0.0031 train_auc=1.0000 val_loss=0.1750 val_auc=0.9942 time=3.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 255/255 [00:02<00:00, 86.16batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in preds: False\n",
      "NaNs in labels: False\n",
      "Pred min/max: 4.0579252e-07 0.99999964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:00<00:00, 210.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 done. train_loss=0.0017 train_auc=1.0000 val_loss=0.2094 val_auc=0.9943 time=3.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 255/255 [00:03<00:00, 84.21batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in preds: False\n",
      "NaNs in labels: False\n",
      "Pred min/max: 1.562776e-07 0.9999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:00<00:00, 223.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 done. train_loss=0.0010 train_auc=1.0000 val_loss=0.2388 val_auc=0.9944 time=3.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 255/255 [00:02<00:00, 85.20batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in preds: False\n",
      "NaNs in labels: False\n",
      "Pred min/max: 1.350048e-08 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:00<00:00, 225.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 done. train_loss=0.0017 train_auc=1.0000 val_loss=0.2183 val_auc=0.9944 time=3.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 255/255 [00:03<00:00, 83.91batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in preds: False\n",
      "NaNs in labels: False\n",
      "Pred min/max: 5.2334407e-08 0.9999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:00<00:00, 229.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 done. train_loss=0.0011 train_auc=1.0000 val_loss=0.2372 val_auc=0.9944 time=3.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 255/255 [00:02<00:00, 85.53batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in preds: False\n",
      "NaNs in labels: False\n",
      "Pred min/max: 2.3164771e-08 0.9999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:00<00:00, 227.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 done. train_loss=0.0008 train_auc=1.0000 val_loss=0.2525 val_auc=0.9944 time=3.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 255/255 [00:03<00:00, 84.46batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in preds: False\n",
      "NaNs in labels: False\n",
      "Pred min/max: 1.8666995e-08 0.9999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:00<00:00, 227.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 done. train_loss=0.0007 train_auc=1.0000 val_loss=0.2650 val_auc=0.9944 time=3.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 255/255 [00:03<00:00, 84.69batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in preds: False\n",
      "NaNs in labels: False\n",
      "Pred min/max: 1.5976385e-08 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:00<00:00, 232.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 done. train_loss=0.0006 train_auc=1.0000 val_loss=0.2697 val_auc=0.9944 time=3.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 255/255 [00:02<00:00, 85.35batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in preds: False\n",
      "NaNs in labels: False\n",
      "Pred min/max: 1.2679311e-08 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:00<00:00, 202.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 done. train_loss=0.0006 train_auc=1.0000 val_loss=0.2731 val_auc=0.9944 time=3.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 255/255 [00:03<00:00, 78.93batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in preds: False\n",
      "NaNs in labels: False\n",
      "Pred min/max: 1.7801202e-08 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:00<00:00, 215.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 done. train_loss=0.0006 train_auc=1.0000 val_loss=0.2788 val_auc=0.9944 time=3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 255/255 [00:03<00:00, 84.70batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in preds: False\n",
      "NaNs in labels: False\n",
      "Pred min/max: 9.472233e-09 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:00<00:00, 224.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 done. train_loss=0.0005 train_auc=1.0000 val_loss=0.2816 val_auc=0.9944 time=3.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 255/255 [00:03<00:00, 82.65batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in preds: False\n",
      "NaNs in labels: False\n",
      "Pred min/max: 1.4027222e-08 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:00<00:00, 222.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 done. train_loss=0.0005 train_auc=1.0000 val_loss=0.2859 val_auc=0.9944 time=3.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 255/255 [00:03<00:00, 81.72batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in preds: False\n",
      "NaNs in labels: False\n",
      "Pred min/max: 1.0025991e-08 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:00<00:00, 217.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 done. train_loss=0.0005 train_auc=1.0000 val_loss=0.2895 val_auc=0.9944 time=3.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 255/255 [00:03<00:00, 84.06batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in preds: False\n",
      "NaNs in labels: False\n",
      "Pred min/max: 1.32518885e-08 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:00<00:00, 206.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 done. train_loss=0.0005 train_auc=1.0000 val_loss=0.2913 val_auc=0.9944 time=3.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 255/255 [00:03<00:00, 82.09batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in preds: False\n",
      "NaNs in labels: False\n",
      "Pred min/max: 1.4221974e-08 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:00<00:00, 199.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 done. train_loss=0.0005 train_auc=1.0000 val_loss=0.2926 val_auc=0.9944 time=3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 255/255 [00:03<00:00, 80.71batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in preds: False\n",
      "NaNs in labels: False\n",
      "Pred min/max: 1.3673618e-08 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:00<00:00, 188.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 done. train_loss=0.0005 train_auc=1.0000 val_loss=0.2943 val_auc=0.9944 time=3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 255/255 [00:03<00:00, 83.02batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in preds: False\n",
      "NaNs in labels: False\n",
      "Pred min/max: 1.1235046e-08 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:00<00:00, 201.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 done. train_loss=0.0005 train_auc=1.0000 val_loss=0.2953 val_auc=0.9944 time=3.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 255/255 [00:03<00:00, 84.04batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in preds: False\n",
      "NaNs in labels: False\n",
      "Pred min/max: 1.2008399e-08 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:00<00:00, 146.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 done. train_loss=0.0005 train_auc=1.0000 val_loss=0.2968 val_auc=0.9944 time=3.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 255/255 [00:03<00:00, 84.49batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in preds: False\n",
      "NaNs in labels: False\n",
      "Pred min/max: 1.5468105e-08 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:00<00:00, 217.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 done. train_loss=0.0005 train_auc=1.0000 val_loss=0.2977 val_auc=0.9944 time=3.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 255/255 [00:03<00:00, 84.20batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in preds: False\n",
      "NaNs in labels: False\n",
      "Pred min/max: 1.4891004e-08 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:00<00:00, 214.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 done. train_loss=0.0005 train_auc=1.0000 val_loss=0.2982 val_auc=0.9944 time=3.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 255/255 [00:03<00:00, 82.69batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in preds: False\n",
      "NaNs in labels: False\n",
      "Pred min/max: 1.29379965e-08 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:00<00:00, 200.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 done. train_loss=0.0004 train_auc=1.0000 val_loss=0.2990 val_auc=0.9944 time=3.6s\n"
     ]
    }
   ],
   "source": [
    "best_val_auc = 0.0\n",
    "start_epoch = 0\n",
    "last_ckpt = CHECKPOINT_DIR / \"temporal_last.pth\"\n",
    "if last_ckpt.exists():\n",
    "    ck = torch.load(last_ckpt, map_location=DEVICE)\n",
    "    model.load_state_dict(ck[\"model_state\"])\n",
    "    optimizer.load_state_dict(ck[\"optimizer_state\"])\n",
    "    start_epoch = ck.get(\"epoch\", 0) + 1\n",
    "    best_val_auc = ck.get(\"best_val_auc\", 0.0)\n",
    "    print(\"Resumed temporal from\", start_epoch, \"best\", best_val_auc)\n",
    "\n",
    "\n",
    "for epoch in range(start_epoch, NUM_EPOCHS):\n",
    "    t0 = time.time()\n",
    "    model.train()\n",
    "    all_preds, all_labels = [], []\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for seqs, lengths, labels, stems in tqdm(train_loader, desc=f\"Epoch {epoch}\", unit=\"batch\", disable=False):\n",
    "        seqs = seqs.to(DEVICE)\n",
    "        lengths = lengths.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits, _ = model(seqs, lengths)\n",
    "\n",
    "        if torch.isnan(logits).any():\n",
    "            with open(BAD_EMB_LOG, \"a\") as f:\n",
    "                f.write(f\"[NaN LOGITS] Epoch={epoch} | stems={stems}\\n\")\n",
    "            print(\"NaN logits detected for batch stems:\", stems)\n",
    "            break\n",
    "        \n",
    "        loss = criterion(logits, labels)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # (optional but STRONGLY recommended)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * seqs.size(0)\n",
    "        all_preds.append(torch.sigmoid(logits).detach().cpu())\n",
    "        all_labels.append(labels.detach().cpu())\n",
    "\n",
    "    all_preds = torch.cat(all_preds).numpy()\n",
    "    all_labels = torch.cat(all_labels).numpy()\n",
    "\n",
    "    print(\"NaNs in preds:\", np.isnan(all_preds).any())\n",
    "    print(\"NaNs in labels:\", np.isnan(all_labels).any())\n",
    "    print(\"Pred min/max:\", np.nanmin(all_preds), np.nanmax(all_preds))\n",
    "    train_auc = safe_auc(all_labels, all_preds)\n",
    "    #train_auc = roc_auc_score(all_labels, all_preds)\n",
    "    train_loss = running_loss / len(train_ds)\n",
    "\n",
    "    # validation\n",
    "    model.eval()\n",
    "    val_preds, val_labels = [], []\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for seqs, lengths, labels, stems in tqdm(val_loader):\n",
    "            seqs = seqs.to(DEVICE); lengths = lengths.to(DEVICE); labels = labels.to(DEVICE)\n",
    "\n",
    "            logits, _ = model(seqs, lengths)\n",
    "            loss = criterion(logits, labels)\n",
    "            val_loss += loss.item() * seqs.size(0)\n",
    "            val_preds.append(torch.sigmoid(logits).cpu())\n",
    "            val_labels.append(labels.cpu())\n",
    "\n",
    "    val_preds = torch.cat(val_preds).numpy()\n",
    "    val_labels = torch.cat(val_labels).numpy()\n",
    "    val_auc = safe_auc(val_labels, val_preds)\n",
    "    #val_auc = roc_auc_score(val_labels, val_preds)\n",
    "    val_loss = val_loss / len(val_loader.dataset)\n",
    "\n",
    "    scheduler.step(val_auc)\n",
    "\n",
    "    ck = {\n",
    "        \"epoch\": epoch,\n",
    "        \"model_state\": model.state_dict(),\n",
    "        \"optimizer_state\": optimizer.state_dict(),\n",
    "        \"best_val_auc\": best_val_auc,\n",
    "        \"val_auc\": val_auc,\n",
    "        \"scheduler_state\": scheduler.state_dict()  # optional\n",
    "    }\n",
    "\n",
    "    last_path = CHECKPOINT_DIR / \"temporal_last.pth\"\n",
    "    save_checkpoint(ck, last_path)\n",
    "\n",
    "    if val_auc > best_val_auc:\n",
    "        best_val_auc = val_auc\n",
    "        best_path = CHECKPOINT_DIR / \"temporal_best_valAUC.pth\"\n",
    "        save_checkpoint(ck, best_path)\n",
    "        print(f\"Saved new best model at epoch {epoch} val_auc={val_auc:.4f}\")\n",
    "\n",
    "    # also save epoch checkpoint (optional)\n",
    "    epoch_path = CHECKPOINT_DIR / f\"temporal_epoch_{epoch}.pth\"\n",
    "    save_checkpoint(ck, epoch_path)\n",
    "\n",
    "    print(f\"Epoch {epoch} done. train_loss={train_loss:.4f} train_auc={train_auc:.4f} val_loss={val_loss:.4f} val_auc={val_auc:.4f} time={(time.time()-t0):.1f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "830296c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded best temporal model with val_auc: 0.9943908256371856\n",
      "Test AUC: 0.9900270869244028\n"
     ]
    }
   ],
   "source": [
    "# After training: evaluate on test split (video-level)\n",
    "best = CHECKPOINT_DIR / \"temporal_best_valAUC.pth\"\n",
    "if best.exists():\n",
    "    ck = torch.load(best, map_location=DEVICE)\n",
    "    model.load_state_dict(ck[\"model_state\"])\n",
    "    print(\"Loaded best temporal model with val_auc:\", ck.get(\"best_val_auc\"))\n",
    "    # test dataset and loader\n",
    "    test_loader = DataLoader(VideoEmbeddingDataset(\"test\"), batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "    model.eval()\n",
    "    t_preds, t_labels, stems_all = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for seqs, lengths, labels, stems in test_loader:\n",
    "            seqs = seqs.to(DEVICE); lengths = lengths.to(DEVICE)\n",
    "            \n",
    "            logits, _ = model(seqs, lengths)\n",
    "            t_preds.append(torch.sigmoid(logits).cpu())\n",
    "            t_labels.append(labels)\n",
    "            stems_all.extend(stems)\n",
    "    t_preds = torch.cat(t_preds).numpy()\n",
    "    t_labels = torch.cat(t_labels).numpy()\n",
    "    print(\"Test AUC:\", roc_auc_score(t_labels, t_preds))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
